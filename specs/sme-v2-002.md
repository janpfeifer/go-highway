SME FMOPA Optimization Plan

Three items: multi-tile FMOPA, incremental transpose (applied everywhere), wire up SME nn dispatch.

Item 1: Multi-Tile FMOPA Kernel

Write new C kernels using all 4 ZA tiles (ZA0-ZA3) in a 2x2 arrangement to process 32x32 output blocks, then transpile with GOAT. Gives 4 FMOPAs from 4 loads per K iteration.

2x2 tile layout (f32, 32x32 output block):
                cols 0-15    cols 16-31
rows 0-15:      ZA0          ZA2
rows 16-31:     ZA1          ZA3

Per K iteration: load a0, a1 (2 A cols) + b0, b1 (2 B rows), then 4 FMOPAs. Ratio: 1.0 FMOPA/load (vs 0.5 for single-tile).

Files

New: hwy/contrib/matmul/c/multitile_fmopa_arm64.c
- multitile_fmopa_at_f32: 2x2 tiles, 48x48 cache blocking
  - C kernel assumes M is multiple of 16 (Go handles padding)
  - Within each cache block's i-loop: process 32-row chunks with 4-tile, fall back to single-tile for 16-row remainder — all within one __arm_streaming session
  - Same approach for N: 32-col chunks with 4-tile, 16-col remainder with single-tile
- multitile_fmopa_at_f64: 2x2 with 16x16 output blocks (8-wide per tile), same remainder strategy

New: hwy/contrib/matmul/asm/multitile_fmopa_wrappers.go
- MultiTileMatMulFMOPAF32(at, b, c []float32, m, n, k int) + F64 variant
- //go:generate go tool goat directive + SMEGuard

Modify: hwy/contrib/matmul/z_matmul_arm64.go
- New multiTileBlockedMatMulFMOPA / multiTileBlockedMatMulFMOPA64
- Go wrapper: uses existing M-padding (pad to 16, from unstaged changes), then calls multi-tile kernel
- Wire into BlockedMatMulFloat32 / BlockedMatMulFloat64

---
Item 2: Incremental Transpose (Applied Everywhere)

FMOPA needs contiguous column vectors, so transpose is unavoidable. But instead of large upfront allocations, transpose in strips fused into the blocking loop.

Matmul KLast path (z_matmul_arm64.go)

Current matmulKLastFMOPA allocates O(KM) + O(KN) buffers. Change to:
1. Transpose A [M,K] → AT [K,M] upfront (keep — reused across all j-blocks)
2. Allocate btStrip buffer [K, 48] from sync.Pool (was [K, N])
3. Loop over j in 48-column blocks:
  - Transpose2DStrided(b, j, min(j+48, n), k, 48, btStrip) — transpose one strip of B
  - Call FMOPA kernel with AT, btStrip, c[..., j:j+48], m, min(48, n-j), k
4. Same for f64 variant

The existing blocked FMOPA kernel already handles arbitrary N (tiles over 16-wide columns), so we can call it with n=48 (or n=remainder) sub-blocks.

SDPA SME path (z_nn_arm64.go)

sdpa_fmopa_f32 expects Q in [headDim, seqLen] and KT in [headDim, kvLen]. Apply same incremental strategy:
- Q transpose: single upfront transpose (Q is reused in the Q@K^T and the O accumulation)
- K transpose: incremental strip transpose is possible but headDim is typically small (64-128), so a full upfront transpose of K [kvLen, headDim] → KT [headDim, kvLen] is already cache-friendly. Use upfront for K.

QKVDense SME path (z_nn_arm64.go)

qkvdense_fmopa_f32 expects xt [inFeatures, batchSize] and wqkv [inFeatures, totalOut]. Apply:
- x transpose: upfront (batchSize is typically small)
- wQKV transpose: incremental by (qDim+2*kvDim)-column strips if totalOut is large. But wQKV is [totalOut, inFeatures] and totalOut is typically 256-1024, so upfront is fine.

Net change: Incremental B transpose for matmul KLast (biggest buffer), upfront transposes for SDPA and QKVDense (smaller buffers where incremental gains are minimal).

Files

Modify: hwy/contrib/matmul/z_matmul_arm64.go
- Rewrite matmulKLastFMOPA / matmulKLastFMOPA64 with incremental B strip transpose
- Reduce btBuf pool from [KN] to [K48]

---
Item 3: Wire Up SME nn Dispatch

SDPA

Dispatch sig: (q, k, v, mask, scores, output, seqLen, kvLen, headDim, scale) — K is [kvLen, headDim]
SME sig: (q_t, kt, v, mask, output, seqLen, kvLen, headDim, scale) — QT is [headDim, seqLen], KT is [headDim, kvLen]

Adapter sdpaSMEF32:
1. Check alignment (seqLen, kvLen, headDim multiples of 16) and size >= minDimForSDPASME (32); fall back to NEON otherwise
2. Transpose Q [seqLen, headDim] → QT [headDim, seqLen] (sync.Pool temp)
3. Transpose K [kvLen, headDim] → KT [headDim, kvLen] (sync.Pool temp)
4. Call asm.SDPAFMOPAF32(qt, kt, v, mask, output, seqLen, kvLen, headDim, scale)
5. Ignore scores parameter (Flash Attention doesn't need scratch)

Same for F64 (alignment check 8 instead of 16).

QKVDense

Dispatch sig: (x, wQKV, biasQ, biasK, biasV, q, k, v, batchSize, inFeatures, qDim, kvDim)
SME sig: (xt, wqkv, biasQ, biasK, biasV, q, k, v, batchSize, inFeatures, qDim, kvDim) — transposed inputs

Adapter qkvdenseSMEF32:
1. Check alignment (batchSize, totalOut multiples of 16) and >= 32; fall back to NEON otherwise
2. Transpose x [batchSize, inFeatures] → xt [inFeatures, batchSize]
3. Transpose wQKV [totalOut, inFeatures] → wqkv [inFeatures, totalOut]
4. Call asm.QKVDenseFMOPAF32(xt, wqkv, biasQ, biasK, biasV, q, k, v, ...)

Same for F64.

SDPACausal

No SME causal SDPA exists. Stays on NEON.

Files

Modify: hwy/contrib/nn/z_nn_arm64.go
- Add sdpaSMEF32, sdpaSMEF64, qkvdenseSMEF32, qkvdenseSMEF64
- Add import "github.com/ajroetker/go-highway/hwy/contrib/matmul" for Transpose2D
- Update init() to check hwy.HasSME() and override dispatch vars

---
Execution Order

1. Item 3 (wire up SME nn) — lowest risk, existing tested assembly
2. Item 1 (multi-tile FMOPA) — need to verify GOAT handles multi-tile encodings
3. Item 2 (incremental transpose for matmul KLast) — builds on verified FMOPA kernel

Verification

# After each item:
GOEXPERIMENT=simd go test ./hwy/contrib/nn/...
GOEXPERIMENT=simd go test ./hwy/contrib/matmul/...

# Benchmarks:
GOEXPERIMENT=simd go test -bench=BenchmarkSDPA -benchmem ./hwy/contrib/nn/...
GOEXPERIMENT=simd go test -bench=BenchmarkQKVDense -benchmem ./hwy/contrib/nn/...
GOEXPERIMENT=simd go test -bench=BenchmarkBlockedMatMul -benchmem ./hwy/contrib/matmul/...
GOEXPERIMENT=simd go test -bench=BenchmarkMatMulKLast -benchmem ./hwy/contrib/matmul/...

# For item 1, verify GOAT output:
# Inspect .s file for fmopa za1.s / za2.s / za3.s encodings
