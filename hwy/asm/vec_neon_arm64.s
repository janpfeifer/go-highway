//go:build !noasm && arm64
// Code generated by GoAT. DO NOT EDIT.
// versions:
// 	clang   21.1.8
// 	objdump 2.45.1
// flags: -march=armv8-a+simd+fp -O3
// source: ../c/vec_neon_arm64.c

TEXT ·add_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e21d400          // fadd.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sub_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea1d400          // fsub.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·mul_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e21dc00          // fmul.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·div_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e21fc00          // fdiv.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·fma_f32x4(SB), $0-64
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD c_0+32(FP), R9
	MOVD c_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	WORD $0x4e20cc22          // fmla.4s	v2, v1, v0
	WORD $0x4ea21c40          // mov.16b	v0, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+48(FP)
	MOVD R10, result_8+56(FP)
	RET

TEXT ·fms_f32x4(SB), $0-64
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD c_0+32(FP), R9
	MOVD c_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	WORD $0x4ea0cc22          // fmls.4s	v2, v1, v0
	WORD $0x4ea21c40          // mov.16b	v0, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+48(FP)
	MOVD R10, result_8+56(FP)
	RET

TEXT ·min_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea1f400          // fmin.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e21f400          // fmax.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·abs_f32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ea0f800          // fabs.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·neg_f32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ea0f800          // fneg.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·sqrt_f32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ea1f800          // fsqrt.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·recip_f32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ea1d800          // frecpe.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·rsqrt_f32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ea1d800          // frsqrte.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·hsum_f32x4(SB), $0-20
	MOVD  v_0+0(FP), R9
	MOVD  v_8+8(FP), R10
	VMOV  R9, V0.D[0]
	VMOV  R10, V0.D[1]
	WORD  $0x6e20d400       // faddp.4s	v0, v0, v0
	WORD  $0x7e30d800       // faddp.2s	s0, v0
	FMOVS F0, result+16(FP)
	RET

TEXT ·hmin_f32x4(SB), $0-20
	MOVD  v_0+0(FP), R9
	MOVD  v_8+8(FP), R10
	VMOV  R9, V0.D[0]
	VMOV  R10, V0.D[1]
	WORD  $0x6eb0f800       // fminv.4s	s0, v0
	FMOVS F0, result+16(FP)
	RET

TEXT ·hmax_f32x4(SB), $0-20
	MOVD  v_0+0(FP), R9
	MOVD  v_8+8(FP), R10
	VMOV  R9, V0.D[0]
	VMOV  R10, V0.D[1]
	WORD  $0x6e30f800       // fmaxv.4s	s0, v0
	FMOVS F0, result+16(FP)
	RET

TEXT ·dot_f32x4(SB), $0-36
	MOVD  a_0+0(FP), R9
	MOVD  a_8+8(FP), R10
	VMOV  R9, V0.D[0]
	VMOV  R10, V0.D[1]
	MOVD  b_0+16(FP), R9
	MOVD  b_8+24(FP), R10
	VMOV  R9, V1.D[0]
	VMOV  R10, V1.D[1]
	WORD  $0x6e21dc00       // fmul.4s	v0, v0, v1
	WORD  $0x6e20d400       // faddp.4s	v0, v0, v0
	WORD  $0x7e30d800       // faddp.2s	s0, v0
	FMOVS F0, result+32(FP)
	RET

TEXT ·eq_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e21e400          // fcmeq.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·ne_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e21e400          // fcmeq.4s	v0, v0, v1
	WORD $0x6e205800          // mvn.16b	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·lt_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea0e420          // fcmgt.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·le_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e20e420          // fcmge.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·gt_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea1e400          // fcmgt.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·ge_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e21e400          // fcmge.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·and_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_f32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sel_f32x4(SB), $0-64
	MOVD mask_0+0(FP), R9
	MOVD mask_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD yes_0+16(FP), R9
	MOVD yes_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD no_0+32(FP), R9
	MOVD no_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	WORD $0x6e621c20          // bsl.16b	v0, v1, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+48(FP)
	MOVD R10, result_8+56(FP)
	RET

TEXT ·add_f64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e61d400          // fadd.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sub_f64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ee1d400          // fsub.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·mul_f64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e61dc00          // fmul.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·div_f64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e61fc00          // fdiv.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·fma_f64x2(SB), $0-64
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD c_0+32(FP), R9
	MOVD c_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	WORD $0x4e60cc22          // fmla.2d	v2, v1, v0
	WORD $0x4ea21c40          // mov.16b	v0, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+48(FP)
	MOVD R10, result_8+56(FP)
	RET

TEXT ·min_f64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ee1f400          // fmin.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_f64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e61f400          // fmax.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·abs_f64x2(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ee0f800          // fabs.2d	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·neg_f64x2(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ee0f800          // fneg.2d	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·sqrt_f64x2(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ee1f800          // fsqrt.2d	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·rsqrt_f64x2(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ee1d800          // frsqrte.2d	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·hsum_f64x2(SB), $0-24
	MOVD  v_0+0(FP), R9
	MOVD  v_8+8(FP), R10
	VMOV  R9, V0.D[0]
	VMOV  R10, V0.D[1]
	WORD  $0x7e70d800       // faddp.2d	d0, v0
	FMOVD F0, result+16(FP)
	RET

TEXT ·dot_f64x2(SB), $0-40
	MOVD  a_0+0(FP), R9
	MOVD  a_8+8(FP), R10
	VMOV  R9, V0.D[0]
	VMOV  R10, V0.D[1]
	MOVD  b_0+16(FP), R9
	MOVD  b_8+24(FP), R10
	VMOV  R9, V1.D[0]
	VMOV  R10, V1.D[1]
	WORD  $0x6e61dc00       // fmul.2d	v0, v0, v1
	WORD  $0x7e70d800       // faddp.2d	d0, v0
	FMOVD F0, result+32(FP)
	RET

TEXT ·add_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea08420          // add.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sub_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea18400          // sub.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·mul_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea09c20          // mul.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·min_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea16c00          // smin.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea16400          // smax.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·abs_i32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ea0b800          // abs.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·neg_i32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6ea0b800          // neg.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·and_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·not_i32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6e205800          // mvn.16b	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·andnot_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e611c00          // bic.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·eq_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea18c00          // cmeq.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·lt_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea03420          // cmgt.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·gt_i32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea13400          // cmgt.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sel_i32x4(SB), $0-64
	MOVD mask_0+0(FP), R9
	MOVD mask_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD yes_0+16(FP), R9
	MOVD yes_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD no_0+32(FP), R9
	MOVD no_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	WORD $0x6e621c20          // bsl.16b	v0, v1, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+48(FP)
	MOVD R10, result_8+56(FP)
	RET

TEXT ·hsum_i32x4(SB), $0-24
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4eb1b800       // addv.4s	s0, v0
	WORD $0x4e042c00       // smov.s	x0, v0[0]
	MOVD R0, result+16(FP)
	RET

TEXT ·add_i64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ee08420          // add.2d	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sub_i64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee18400          // sub.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·and_i64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_i64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_i64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·eq_i64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee18c00          // cmeq.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·add_f32x2(SB), $0-24
	MOVD a+0(FP), R9
	VMOV R9, V0.D[0]
	MOVD b+8(FP), R9
	VMOV R9, V1.D[0]
	WORD $0x0e21d400       // fadd.2s	v0, v0, v1
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·sub_f32x2(SB), $0-24
	MOVD a+0(FP), R9
	VMOV R9, V0.D[0]
	MOVD b+8(FP), R9
	VMOV R9, V1.D[0]
	WORD $0x0ea1d400       // fsub.2s	v0, v0, v1
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·mul_f32x2(SB), $0-24
	MOVD a+0(FP), R9
	VMOV R9, V0.D[0]
	MOVD b+8(FP), R9
	VMOV R9, V1.D[0]
	WORD $0x2e21dc00       // fmul.2s	v0, v0, v1
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·div_f32x2(SB), $0-24
	MOVD a+0(FP), R9
	VMOV R9, V0.D[0]
	MOVD b+8(FP), R9
	VMOV R9, V1.D[0]
	WORD $0x2e21fc00       // fdiv.2s	v0, v0, v1
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·min_f32x2(SB), $0-24
	MOVD a+0(FP), R9
	VMOV R9, V0.D[0]
	MOVD b+8(FP), R9
	VMOV R9, V1.D[0]
	WORD $0x0ea1f400       // fmin.2s	v0, v0, v1
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·max_f32x2(SB), $0-24
	MOVD a+0(FP), R9
	VMOV R9, V0.D[0]
	MOVD b+8(FP), R9
	VMOV R9, V1.D[0]
	WORD $0x0e21f400       // fmax.2s	v0, v0, v1
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·hsum_f32x2(SB), $0-12
	MOVD  v+0(FP), R9
	VMOV  R9, V0.D[0]
	WORD  $0x7e30d800      // faddp.2s	s0, v0
	FMOVS F0, result+8(FP)
	RET

TEXT ·dot_f32x2(SB), $0-20
	MOVD  a+0(FP), R9
	VMOV  R9, V0.D[0]
	MOVD  b+8(FP), R9
	VMOV  R9, V1.D[0]
	WORD  $0x2e21dc00       // fmul.2s	v0, v0, v1
	WORD  $0x7e30d800       // faddp.2s	s0, v0
	FMOVS F0, result+16(FP)
	RET

TEXT ·counttrue_i32x4(SB), $0-24
	MOVD mask_0+0(FP), R9
	MOVD mask_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f210400       // ushr.4s	v0, v0, #31
	WORD $0x4eb1b800       // addv.4s	s0, v0
	WORD $0x1e260000       // fmov	w0, s0
	MOVD R0, result+16(FP)
	RET

TEXT ·alltrue_i32x4(SB), $0-24
	MOVD mask_0+0(FP), R9
	MOVD mask_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6eb1a800       // uminv.4s	s0, v0
	WORD $0x1e260008       // fmov	w8, s0
	WORD $0x7100011f       // cmp	w8, #0
	WORD $0x1a9f07e0       // cset	w0, ne
	MOVD R0, result+16(FP)
	RET

TEXT ·anytrue_i32x4(SB), $0-24
	MOVD mask_0+0(FP), R9
	MOVD mask_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6eb0a800       // umaxv.4s	s0, v0
	WORD $0x1e260008       // fmov	w8, s0
	WORD $0x7100011f       // cmp	w8, #0
	WORD $0x1a9f07e0       // cset	w0, ne
	MOVD R0, result+16(FP)
	RET

TEXT ·cvt_f32x4_i32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ea1b800          // fcvtzs.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·cvt_i32x4_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4e21d800          // scvtf.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·cvt_f32x2_f64x2(SB), $0-24
	MOVD v+0(FP), R9
	VMOV R9, V0.D[0]
	WORD $0x0e617800          // fcvtl	v0.2d, v0.2s
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+8(FP)
	MOVD R10, result_8+16(FP)
	RET

TEXT ·cvt_f64x2_f32x2(SB), $0-24
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x0e616800       // fcvtn	v0.2s, v0.2d
	VMOV V0.D[0], R9
	MOVD R9, result+16(FP)
	RET

TEXT ·round_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4e218800          // frintn.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·floor_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4e219800          // frintm.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·ceil_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ea18800          // frintp.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·trunc_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4ea19800          // frintz.4s	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·lt_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e203420          // cmhi.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·gt_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e213400          // cmhi.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·le_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e203c20          // cmhs.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·ge_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e213c00          // cmhs.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·eq_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e218c00          // cmeq.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·min_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e216c00          // umin.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e216400          // umax.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·adds_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e210c00          // uqadd.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·subs_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e212c00          // uqsub.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·and_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_u8x16(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·not_u8x16(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6e205800          // mvn.16b	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·lt_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e603420          // cmhi.8h	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·gt_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e613400          // cmhi.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·le_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e603c20          // cmhs.8h	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·ge_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e613c00          // cmhs.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·eq_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e618c00          // cmeq.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·min_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e616c00          // umin.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e616400          // umax.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·adds_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e610c00          // uqadd.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·subs_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e612c00          // uqsub.8h	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·and_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_u16x8(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·not_u16x8(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6e205800          // mvn.16b	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·add_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea08420          // add.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sub_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea18400          // sub.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·mul_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea09c20          // mul.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·lt_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea03420          // cmhi.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·gt_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea13400          // cmhi.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·le_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea03c20          // cmhs.4s	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·ge_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea13c00          // cmhs.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·eq_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea18c00          // cmeq.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·min_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea16c00          // umin.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea16400          // umax.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·adds_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea10c00          // uqadd.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·subs_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ea12c00          // uqsub.4s	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·and_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·not_u32x4(SB), $0-32
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6e205800          // mvn.16b	v0, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·andnot_u32x4(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e611c00          // bic.16b	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·hsum_u32x4(SB), $0-24
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x4eb1b800       // addv.4s	s0, v0
	WORD $0x1e260000       // fmov	w0, s0
	MOVD R0, result+16(FP)
	RET

TEXT ·add_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ee08420          // add.2d	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sub_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee18400          // sub.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·lt_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee03420          // cmhi.2d	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·gt_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee13400          // cmhi.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·le_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee03c20          // cmhs.2d	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·ge_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee13c00          // cmhs.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·eq_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee18c00          // cmeq.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·min_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee03422          // cmhi.2d	v2, v1, v0
	WORD $0x6ee21c20          // bif.16b	v0, v1, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·max_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee13402          // cmhi.2d	v2, v0, v1
	WORD $0x6ee21c20          // bif.16b	v0, v1, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·adds_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee10c00          // uqadd.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·subs_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6ee12c00          // uqsub.2d	v0, v0, v1
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·and_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4e201c20          // and.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·or_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x4ea01c20          // orr.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·xor_u64x2(SB), $0-48
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	WORD $0x6e201c20          // eor.16b	v0, v1, v0
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+32(FP)
	MOVD R10, result_8+40(FP)
	RET

TEXT ·sel_u64x2(SB), $0-64
	MOVD mask_0+0(FP), R9
	MOVD mask_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD yes_0+16(FP), R9
	MOVD yes_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD no_0+32(FP), R9
	MOVD no_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	WORD $0x6e621c20          // bsl.16b	v0, v1, v2
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+48(FP)
	MOVD R10, result_8+56(FP)
	RET

TEXT ·slide_up_1_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e006020          // ext.16b	v0, v1, v0, #12
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_2_f32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e004020          // ext.16b	v0, v1, v0, #8
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_1_f64x2(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e004020          // ext.16b	v0, v1, v0, #8
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_1_i32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e006020          // ext.16b	v0, v1, v0, #12
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_2_i32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e004020          // ext.16b	v0, v1, v0, #8
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_1_i64x2(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e004020          // ext.16b	v0, v1, v0, #8
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_1_u32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e006020          // ext.16b	v0, v1, v0, #12
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_2_u32x4(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e004020          // ext.16b	v0, v1, v0, #8
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·slide_up_1_u64x2(SB), $0-32
	MOVD v_0+0(FP), R9
	MOVD v_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	WORD $0x6f00e401          // movi.2d	v1, #0000000000000000
	WORD $0x6e004020          // ext.16b	v0, v1, v0, #8
	VMOV V0.D[0], R9
	VMOV V0.D[1], R10
	MOVD R9, result_0+16(FP)
	MOVD R10, result_8+24(FP)
	RET

TEXT ·add_f32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4e21d400       // fadd.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·sub_f32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ea1d400       // fsub.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·mul_f32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x6e21dc00       // fmul.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·div_f32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x6e21fc00       // fdiv.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·min_f32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ea1f400       // fmin.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·max_f32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4e21f400       // fmax.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·muladd_f32x4_acc(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD acc+32(FP), R0
	WORD $0x3dc00002     // ldr	q2, [x0]
	WORD $0x4e20cc22     // fmla.4s	v2, v1, v0
	WORD $0x3d800002     // str	q2, [x0]
	RET

TEXT ·muladd_f32x4_ip(SB), $0-56
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD c_0+32(FP), R9
	MOVD c_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	MOVD result+48(FP), R0
	WORD $0x4e20cc22       // fmla.4s	v2, v1, v0
	WORD $0x3d800002       // str	q2, [x0]
	RET

TEXT ·add_f64x2_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4e61d400       // fadd.2d	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·sub_f64x2_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ee1d400       // fsub.2d	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·mul_f64x2_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x6e61dc00       // fmul.2d	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·div_f64x2_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x6e61fc00       // fdiv.2d	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·min_f64x2_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ee1f400       // fmin.2d	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·max_f64x2_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4e61f400       // fmax.2d	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·muladd_f64x2_acc(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD acc+32(FP), R0
	WORD $0x3dc00002     // ldr	q2, [x0]
	WORD $0x4e60cc22     // fmla.2d	v2, v1, v0
	WORD $0x3d800002     // str	q2, [x0]
	RET

TEXT ·muladd_f64x2_ip(SB), $0-56
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD c_0+32(FP), R9
	MOVD c_8+40(FP), R10
	VMOV R9, V2.D[0]
	VMOV R10, V2.D[1]
	MOVD result+48(FP), R0
	WORD $0x4e60cc22       // fmla.2d	v2, v1, v0
	WORD $0x3d800002       // str	q2, [x0]
	RET

TEXT ·add_i32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ea08420       // add.4s	v0, v1, v0
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·sub_i32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x6ea18400       // sub.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·mul_i32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ea09c20       // mul.4s	v0, v1, v0
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·min_i32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ea16c00       // smin.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·max_i32x4_ip(SB), $0-40
	MOVD a_0+0(FP), R9
	MOVD a_8+8(FP), R10
	VMOV R9, V0.D[0]
	VMOV R10, V0.D[1]
	MOVD b_0+16(FP), R9
	MOVD b_8+24(FP), R10
	VMOV R9, V1.D[0]
	VMOV R10, V1.D[1]
	MOVD result+32(FP), R0
	WORD $0x4ea16400       // smax.4s	v0, v0, v1
	WORD $0x3d800000       // str	q0, [x0]
	RET

TEXT ·load4_f32x4(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402800     // ld1.4s	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_f64x2(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402c00     // ld1.2d	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_i32x4(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402800     // ld1.4s	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_i64x2(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402c00     // ld1.2d	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_u32x4(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402800     // ld1.4s	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_u64x2(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402c00     // ld1.2d	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_u8x16(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402000     // ld1.16b	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET

TEXT ·load4_u16x8(SB), $0-40
	MOVD ptr+0(FP), R0
	MOVD out0+8(FP), R1
	MOVD out1+16(FP), R2
	MOVD out2+24(FP), R3
	MOVD out3+32(FP), R4
	WORD $0x4c402400     // ld1.8h	{ v0, v1, v2, v3 }, [x0]
	WORD $0x3d800020     // str	q0, [x1]
	WORD $0x3d800041     // str	q1, [x2]
	WORD $0x3d800062     // str	q2, [x3]
	WORD $0x3d800083     // str	q3, [x4]
	RET
