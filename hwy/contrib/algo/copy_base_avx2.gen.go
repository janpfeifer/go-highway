// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package algo

import (
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
)

func BaseCopyIf_avx2(src []float32, dst []float32, pred func(archsimd.Float32x8) archsimd.Mask32x8) int {
	n := len(src)
	dstLen := len(dst)
	if n == 0 || dstLen == 0 {
		return 0
	}
	lanes := 8
	dstIdx := 0
	i := 0
	for ; i+lanes <= n && dstIdx < dstLen; i += lanes {
		v := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&src[i])))
		mask := pred(v)
		remaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_F32x8(v, mask, dst[dstIdx:]), remaining)
		dstIdx += count
		if dstIdx >= dstLen {
			break
		}
	}
	if remaining := n - i; remaining > 0 && dstIdx < dstLen {
		buf := [8]float32{}
		copy(buf[:], src[i:i+remaining])
		v := archsimd.LoadFloat32x8Slice(buf[:])
		mask := pred(v)
		tailMask := hwy.FirstN_AVX2_F32x8(remaining)
		mask = mask.And(tailMask)
		dstRemaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_F32x8(v, mask, dst[dstIdx:]), dstRemaining)
		dstIdx += count
	}
	return dstIdx
}

func BaseCopyIf_avx2_Float64(src []float64, dst []float64, pred func(archsimd.Float64x4) archsimd.Mask64x4) int {
	n := len(src)
	dstLen := len(dst)
	if n == 0 || dstLen == 0 {
		return 0
	}
	lanes := 4
	dstIdx := 0
	i := 0
	for ; i+lanes <= n && dstIdx < dstLen; i += lanes {
		v := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&src[i])))
		mask := pred(v)
		remaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_F64x4(v, mask, dst[dstIdx:]), remaining)
		dstIdx += count
		if dstIdx >= dstLen {
			break
		}
	}
	if remaining := n - i; remaining > 0 && dstIdx < dstLen {
		buf := [4]float64{}
		copy(buf[:], src[i:i+remaining])
		v := archsimd.LoadFloat64x4Slice(buf[:])
		mask := pred(v)
		tailMask := hwy.FirstN_AVX2_F64x4(remaining)
		mask = mask.And(tailMask)
		dstRemaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_F64x4(v, mask, dst[dstIdx:]), dstRemaining)
		dstIdx += count
	}
	return dstIdx
}

func BaseCopyIf_avx2_Int32(src []int32, dst []int32, pred func(archsimd.Int32x8) archsimd.Mask32x8) int {
	n := len(src)
	dstLen := len(dst)
	if n == 0 || dstLen == 0 {
		return 0
	}
	lanes := 8
	dstIdx := 0
	i := 0
	for ; i+lanes <= n && dstIdx < dstLen; i += lanes {
		v := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&src[i])))
		mask := pred(v)
		remaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_I32x8(v, mask, dst[dstIdx:]), remaining)
		dstIdx += count
		if dstIdx >= dstLen {
			break
		}
	}
	if remaining := n - i; remaining > 0 && dstIdx < dstLen {
		buf := [8]int32{}
		copy(buf[:], src[i:i+remaining])
		v := archsimd.LoadInt32x8Slice(buf[:])
		mask := pred(v)
		tailMask := hwy.FirstN_AVX2_I32x8(remaining)
		mask = mask.And(tailMask)
		dstRemaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_I32x8(v, mask, dst[dstIdx:]), dstRemaining)
		dstIdx += count
	}
	return dstIdx
}

func BaseCopyIf_avx2_Int64(src []int64, dst []int64, pred func(archsimd.Int64x4) archsimd.Mask64x4) int {
	n := len(src)
	dstLen := len(dst)
	if n == 0 || dstLen == 0 {
		return 0
	}
	lanes := 4
	dstIdx := 0
	i := 0
	for ; i+lanes <= n && dstIdx < dstLen; i += lanes {
		v := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&src[i])))
		mask := pred(v)
		remaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_I64x4(v, mask, dst[dstIdx:]), remaining)
		dstIdx += count
		if dstIdx >= dstLen {
			break
		}
	}
	if remaining := n - i; remaining > 0 && dstIdx < dstLen {
		buf := [4]int64{}
		copy(buf[:], src[i:i+remaining])
		v := archsimd.LoadInt64x4Slice(buf[:])
		mask := pred(v)
		tailMask := hwy.FirstN_AVX2_I64x4(remaining)
		mask = mask.And(tailMask)
		dstRemaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_I64x4(v, mask, dst[dstIdx:]), dstRemaining)
		dstIdx += count
	}
	return dstIdx
}

func BaseCopyIf_avx2_Uint32(src []uint32, dst []uint32, pred func(archsimd.Uint32x8) archsimd.Mask32x8) int {
	n := len(src)
	dstLen := len(dst)
	if n == 0 || dstLen == 0 {
		return 0
	}
	lanes := 8
	dstIdx := 0
	i := 0
	for ; i+lanes <= n && dstIdx < dstLen; i += lanes {
		v := archsimd.LoadUint32x8((*[8]uint32)(unsafe.Pointer(&src[i])))
		mask := pred(v)
		remaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_Uint32x8(v, mask, dst[dstIdx:]), remaining)
		dstIdx += count
		if dstIdx >= dstLen {
			break
		}
	}
	if remaining := n - i; remaining > 0 && dstIdx < dstLen {
		buf := [8]uint32{}
		copy(buf[:], src[i:i+remaining])
		v := archsimd.LoadUint32x8Slice(buf[:])
		mask := pred(v)
		tailMask := hwy.FirstN_AVX2_Uint32x8(remaining)
		mask = mask.And(tailMask)
		dstRemaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_Uint32x8(v, mask, dst[dstIdx:]), dstRemaining)
		dstIdx += count
	}
	return dstIdx
}

func BaseCopyIf_avx2_Uint64(src []uint64, dst []uint64, pred func(archsimd.Uint64x4) archsimd.Mask64x4) int {
	n := len(src)
	dstLen := len(dst)
	if n == 0 || dstLen == 0 {
		return 0
	}
	lanes := 4
	dstIdx := 0
	i := 0
	for ; i+lanes <= n && dstIdx < dstLen; i += lanes {
		v := archsimd.LoadUint64x4((*[4]uint64)(unsafe.Pointer(&src[i])))
		mask := pred(v)
		remaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_Uint64x4(v, mask, dst[dstIdx:]), remaining)
		dstIdx += count
		if dstIdx >= dstLen {
			break
		}
	}
	if remaining := n - i; remaining > 0 && dstIdx < dstLen {
		buf := [4]uint64{}
		copy(buf[:], src[i:i+remaining])
		v := archsimd.LoadUint64x4Slice(buf[:])
		mask := pred(v)
		tailMask := hwy.FirstN_AVX2_Uint64x4(remaining)
		mask = mask.And(tailMask)
		dstRemaining := dstLen - dstIdx
		count := min(hwy.CompressStore_AVX2_Uint64x4(v, mask, dst[dstIdx:]), dstRemaining)
		dstIdx += count
	}
	return dstIdx
}
