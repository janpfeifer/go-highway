// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

package loss

import (
	stdmath "math"
)

func BaseCutCrossEntropy_fallback(hiddenStates []float32, embeddings []float32, labels []int32, numPositions int, hiddenDim int, vocabSize int) float32 {
	if numPositions == 0 || hiddenDim == 0 || vocabSize == 0 {
		return 0
	}
	if len(hiddenStates) < numPositions*hiddenDim || len(embeddings) < vocabSize*hiddenDim || len(labels) < numPositions {
		return 0
	}
	totalLoss := float64(0)
	validCount := 0
	for pos := 0; pos < numPositions; pos++ {
		label := labels[pos]
		if label < 0 || int(label) >= vocabSize {
			continue
		}
		hsOffset := pos * hiddenDim
		labelLogit := simdDotProduct(hiddenStates[hsOffset:hsOffset+hiddenDim], embeddings[int(label)*hiddenDim:(int(label)+1)*hiddenDim], hiddenDim)
		lse := streamingLogsumexp(hiddenStates[hsOffset:hsOffset+hiddenDim], embeddings, hiddenDim, vocabSize)
		loss := lse - float64(labelLogit)
		totalLoss += loss
		validCount++
	}
	if validCount == 0 {
		return 0
	}
	return float32(totalLoss / float64(validCount))
}

func BaseCutCrossEntropyGrad_fallback(hiddenStates []float32, embeddings []float32, labels []int32, gradOutput []float32, numPositions int, hiddenDim int, vocabSize int) {
	if numPositions == 0 || hiddenDim == 0 || vocabSize == 0 {
		return
	}
	validCount := 0
	for i := 0; i < numPositions; i++ {
		if labels[i] >= 0 && int(labels[i]) < vocabSize {
			validCount++
		}
	}
	if validCount == 0 {
		return
	}
	invN := float32(1.0 / float64(validCount))
	for pos := 0; pos < numPositions; pos++ {
		label := labels[pos]
		gradBase := pos * hiddenDim
		if label < 0 || int(label) >= vocabSize {
			for d := 0; d < hiddenDim; d++ {
				gradOutput[gradBase+d] = 0
			}
			continue
		}
		hsOffset := pos * hiddenDim
		firstDotAcc := float32(0)
		var fi int
		for fi = 0; fi < hiddenDim; fi++ {
			va := hiddenStates[hsOffset+fi]
			vb := embeddings[fi]
			firstDotAcc = va*vb + firstDotAcc
		}
		firstDotSum := firstDotAcc
		for ; fi < hiddenDim; fi++ {
			firstDotSum += hiddenStates[hsOffset+fi] * embeddings[fi]
		}
		currentMax := float64(firstDotSum)
		sumExp := float64(1.0)
		for v := 1; v < vocabSize; v++ {
			embOff := v * hiddenDim
			dotAcc := float32(0)
			var di int
			for di = 0; di < hiddenDim; di++ {
				va := hiddenStates[hsOffset+di]
				vb := embeddings[embOff+di]
				dotAcc = va*vb + dotAcc
			}
			dotSum := dotAcc
			for ; di < hiddenDim; di++ {
				dotSum += hiddenStates[hsOffset+di] * embeddings[embOff+di]
			}
			logit := float64(dotSum)
			if logit > currentMax {
				sumExp = sumExp*stdmath.Exp(currentMax-logit) + 1.0
				currentMax = logit
			} else {
				sumExp += stdmath.Exp(logit - currentMax)
			}
		}
		lse := currentMax + stdmath.Log(sumExp)
		labelEmbOffset := int(label) * hiddenDim
		var d int
		for d = 0; d < hiddenDim; d++ {
			e := embeddings[labelEmbOffset+d]
			neg := -e
			scaled := neg * float32(invN)
			gradOutput[gradBase+d] = scaled
		}
		for ; d < hiddenDim; d++ {
			gradOutput[gradBase+d] = -embeddings[labelEmbOffset+d] * invN
		}
		for v := 0; v < vocabSize; v++ {
			embOffset := v * hiddenDim
			dotAcc := float32(0)
			var di int
			for di = 0; di < hiddenDim; di++ {
				va := hiddenStates[hsOffset+di]
				vb := embeddings[embOffset+di]
				dotAcc = va*vb + dotAcc
			}
			dotSum := dotAcc
			for ; di < hiddenDim; di++ {
				dotSum += hiddenStates[hsOffset+di] * embeddings[embOffset+di]
			}
			logit := float64(dotSum)
			softmaxWeight := float32(stdmath.Exp(logit-lse)) * invN
			vWeight := float32(softmaxWeight)
			var dd int
			for dd = 0; dd < hiddenDim; dd++ {
				g := gradOutput[gradBase+dd]
				e := embeddings[embOffset+dd]
				g = vWeight*e + g
				gradOutput[gradBase+dd] = g
			}
			for ; dd < hiddenDim; dd++ {
				gradOutput[gradBase+dd] += softmaxWeight * embeddings[embOffset+dd]
			}
		}
	}
}

func BaseCutCrossEntropyWithLogits_fallback(hiddenStates []float32, embeddings []float32, labels []int32, perPositionLoss []float32, correctLogits []float32, numPositions int, hiddenDim int, vocabSize int) float32 {
	if numPositions == 0 || hiddenDim == 0 || vocabSize == 0 {
		return 0
	}
	if len(hiddenStates) < numPositions*hiddenDim || len(embeddings) < vocabSize*hiddenDim || len(labels) < numPositions || len(perPositionLoss) < numPositions || len(correctLogits) < numPositions {
		return 0
	}
	totalLoss := float64(0)
	validCount := 0
	for pos := 0; pos < numPositions; pos++ {
		label := labels[pos]
		if label < 0 || int(label) >= vocabSize {
			perPositionLoss[pos] = 0
			correctLogits[pos] = 0
			continue
		}
		hsOffset := pos * hiddenDim
		labelLogit := simdDotProduct(hiddenStates[hsOffset:hsOffset+hiddenDim], embeddings[int(label)*hiddenDim:(int(label)+1)*hiddenDim], hiddenDim)
		correctLogits[pos] = labelLogit
		lse := streamingLogsumexp(hiddenStates[hsOffset:hsOffset+hiddenDim], embeddings, hiddenDim, vocabSize)
		loss := float32(lse - float64(labelLogit))
		perPositionLoss[pos] = loss
		totalLoss += float64(loss)
		validCount++
	}
	if validCount == 0 {
		return 0
	}
	return float32(totalLoss / float64(validCount))
}
