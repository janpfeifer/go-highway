// Code generated by hwygen. DO NOT EDIT.
//go:build arm64

package math

import (
	"github.com/ajroetker/go-highway/hwy/asm"
)

// Hoisted constants - pre-broadcasted at package init time
var (
	BaseSinVec_NEON_c1_f32           = asm.BroadcastFloat32x4(float32(trigC1_f32))
	BaseSinVec_NEON_s2_f64           = asm.BroadcastFloat64x2(float64(trigS2_f64))
	BaseCosVec_NEON_c2_f32           = asm.BroadcastFloat32x4(float32(trigC2_f32))
	BaseSigmoidVec_NEON_satLo_f32    = asm.BroadcastFloat32x4(float32(-20.0))
	BaseLogVec_NEON_c5_f64           = asm.BroadcastFloat64x2(float64(logC5_f64))
	BaseSinVec_NEON_s1_f32           = asm.BroadcastFloat32x4(float32(trigS1_f32))
	BaseCosVec_NEON_s3_f32           = asm.BroadcastFloat32x4(float32(trigS3_f32))
	BaseSinhVec_NEON_one_f64         = asm.BroadcastFloat64x2(float64(sinhOne_f64))
	BaseCoshVec_NEON_c2_f32          = asm.BroadcastFloat32x4(float32(0.5))
	BaseAtanhVec_NEON_one_f32        = asm.BroadcastFloat32x4(float32(1.0))
	BaseErfVec_NEON_one_f32          = asm.BroadcastFloat32x4(float32(erfOne_f32))
	BaseSinhVec_NEON_c3_f64          = asm.BroadcastFloat64x2(float64(sinhC3_f64))
	BaseCoshVec_NEON_c6_f32          = asm.BroadcastFloat32x4(float32(0.001388888888888889))
	BaseAcoshVec_NEON_one_f32        = asm.BroadcastFloat32x4(float32(1.0))
	BaseAtanhVec_NEON_half_f32       = asm.BroadcastFloat32x4(float32(0.5))
	BaseLogVec_NEON_c2_f32           = asm.BroadcastFloat32x4(float32(logC2_f32))
	BaseLogVec_NEON_c4_f32           = asm.BroadcastFloat32x4(float32(logC4_f32))
	BaseExpVec_NEON_ln2Lo_f64        = asm.BroadcastFloat64x2(float64(expLn2Lo_f64))
	BaseTanhVec_NEON_one_f32         = asm.BroadcastFloat32x4(float32(tanhOne_f32))
	BaseSigmoidVec_NEON_zero_f32     = asm.BroadcastFloat32x4(float32(0.0))
	BaseExpVec_NEON_c3_f32           = asm.BroadcastFloat32x4(float32(expC3_f32))
	BaseTanhVec_NEON_threshold_f32   = asm.BroadcastFloat32x4(float32(tanhClamp_f32))
	BaseCosVec_NEON_s4_f32           = asm.BroadcastFloat32x4(float32(trigS4_f32))
	BaseCosVec_NEON_intThree_i32_f32 = asm.BroadcastInt32x4(3)
	BaseCosVec_NEON_intThree_i32_f64 = asm.BroadcastInt32x2(3)
	BaseLog2Vec_NEON_log2E_f64       = asm.BroadcastFloat64x2(float64(log2E_f64))
	BaseSinhVec_NEON_one_f32         = asm.BroadcastFloat32x4(float32(sinhOne_f32))
	BaseExpVec_NEON_c5_f32           = asm.BroadcastFloat32x4(float32(expC5_f32))
	BaseExpVec_NEON_c2_f64           = asm.BroadcastFloat64x2(float64(expC2_f64))
	BaseSigmoidVec_NEON_one_f64      = asm.BroadcastFloat64x2(float64(sigmoidOne_f64))
	BaseLogVec_NEON_one_f64          = asm.BroadcastFloat64x2(float64(logOne_f64))
	BaseCosVec_NEON_c3_f64           = asm.BroadcastFloat64x2(float64(trigC3_f64))
	BaseLog2Vec_NEON_log2E_f32       = asm.BroadcastFloat32x4(float32(log2E_f32))
	BaseSinhVec_NEON_c7_f32          = asm.BroadcastFloat32x4(float32(sinhC7_f32))
	BaseSinhVec_NEON_c5_f64          = asm.BroadcastFloat64x2(float64(sinhC5_f64))
	BaseExpVec_NEON_zero_f32         = asm.BroadcastFloat32x4(float32(expZero_f32))
	BaseLogVec_NEON_negInf_f32       = asm.BroadcastFloat32x4(float32(-1e38))
	BaseLogVec_NEON_c2_f64           = asm.BroadcastFloat64x2(float64(logC2_f64))
	BaseErfVec_NEON_p_f32            = asm.BroadcastFloat32x4(float32(erfP_f32))
	BaseAtanhVec_NEON_zero_f32       = asm.BroadcastFloat32x4(float32(0.0))
	BaseExpVec_NEON_c4_f32           = asm.BroadcastFloat32x4(float32(expC4_f32))
	BaseExpVec_NEON_c1_f32           = asm.BroadcastFloat32x4(float32(expC1_f32))
	BaseSinVec_NEON_c2_f64           = asm.BroadcastFloat64x2(float64(trigC2_f64))
	BaseCoshVec_NEON_c4_f32          = asm.BroadcastFloat32x4(float32(0.041666666666666664))
	BaseAtanhVec_NEON_zero_f64       = asm.BroadcastFloat64x2(float64(0.0))
	BaseExpVec_NEON_c5_f64           = asm.BroadcastFloat64x2(float64(expC5_f64))
	BaseCosVec_NEON_one_f32          = asm.BroadcastFloat32x4(float32(trigOne_f32))
	BaseErfVec_NEON_a5_f64           = asm.BroadcastFloat64x2(float64(erfA5_f64))
	BaseExpVec_NEON_c1_f64           = asm.BroadcastFloat64x2(float64(expC1_f64))
	BaseLogVec_NEON_two_f64          = asm.BroadcastFloat64x2(float64(logTwo_f64))
	BaseLogVec_NEON_zero_f64         = asm.BroadcastFloat64x2(float64(0.0))
	BaseSinVec_NEON_c2_f32           = asm.BroadcastFloat32x4(float32(trigC2_f32))
	BaseCosVec_NEON_s2_f32           = asm.BroadcastFloat32x4(float32(trigS2_f32))
	BaseCosVec_NEON_c4_f32           = asm.BroadcastFloat32x4(float32(trigC4_f32))
	BaseExpVec_NEON_c2_f32           = asm.BroadcastFloat32x4(float32(expC2_f32))
	BaseExpVec_NEON_zero_f64         = asm.BroadcastFloat64x2(float64(expZero_f64))
	BaseLogVec_NEON_c1_f64           = asm.BroadcastFloat64x2(float64(logC1_f64))
	BaseLogVec_NEON_c4_f64           = asm.BroadcastFloat64x2(float64(logC4_f64))
	BaseSinVec_NEON_intOne_i32_f64   = asm.BroadcastInt32x2(1)
	BaseCosVec_NEON_intOne_i32_f32   = asm.BroadcastInt32x4(1)
	BaseCoshVec_NEON_c4_f64          = asm.BroadcastFloat64x2(float64(0.041666666666666664))
	BaseCosVec_NEON_c1_f32           = asm.BroadcastFloat32x4(float32(trigC1_f32))
	BaseExpVec_NEON_c6_f32           = asm.BroadcastFloat32x4(float32(expC6_f32))
	BaseExpVec_NEON_c4_f64           = asm.BroadcastFloat64x2(float64(expC4_f64))
	BaseSigmoidVec_NEON_satHi_f32    = asm.BroadcastFloat32x4(float32(20.0))
	BaseLogVec_NEON_zero_f32         = asm.BroadcastFloat32x4(float32(0.0))
	BaseCoshVec_NEON_c2_f64          = asm.BroadcastFloat64x2(float64(0.5))
	BaseSigmoidVec_NEON_satLo_f64    = asm.BroadcastFloat64x2(float64(-20.0))
	BaseLogVec_NEON_negInf_f64       = asm.BroadcastFloat64x2(float64(-1e38))
	BaseTanhVec_NEON_threshold_f64   = asm.BroadcastFloat64x2(float64(tanhClamp_f64))
	BaseExpVec_NEON_ln2Lo_f32        = asm.BroadcastFloat32x4(float32(expLn2Lo_f32))
	BaseExpVec_NEON_ln2Hi_f64        = asm.BroadcastFloat64x2(float64(expLn2Hi_f64))
	BaseExpVec_NEON_underflow_f64    = asm.BroadcastFloat64x2(float64(expUnderflow_f64))
	BaseCosVec_NEON_one_f64          = asm.BroadcastFloat64x2(float64(trigOne_f64))
	BaseErfVec_NEON_a4_f32           = asm.BroadcastFloat32x4(float32(erfA4_f32))
	BaseSinVec_NEON_intTwo_i32_f64   = asm.BroadcastInt32x2(2)
	BaseSinVec_NEON_s4_f64           = asm.BroadcastFloat64x2(float64(trigS4_f64))
	BaseCosVec_NEON_twoOverPi_f32    = asm.BroadcastFloat32x4(float32(trig2OverPi_f32))
	BaseAsinhVec_NEON_one_f64        = asm.BroadcastFloat64x2(float64(1.0))
	BaseExpVec_NEON_c6_f64           = asm.BroadcastFloat64x2(float64(expC6_f64))
	BaseTanhVec_NEON_negOne_f64      = asm.BroadcastFloat64x2(float64(tanhNegOne_f64))
	BaseLogVec_NEON_ln2Lo_f64        = asm.BroadcastFloat64x2(float64(logLn2Lo_f64))
	BaseCosVec_NEON_intTwo_i32_f32   = asm.BroadcastInt32x4(2)
	BaseErfVec_NEON_a3_f64           = asm.BroadcastFloat64x2(float64(erfA3_f64))
	BaseCoshVec_NEON_one_f64         = asm.BroadcastFloat64x2(float64(1.0))
	BaseSinVec_NEON_c1_f64           = asm.BroadcastFloat64x2(float64(trigC1_f64))
	BaseSinVec_NEON_piOver2Lo_f64    = asm.BroadcastFloat64x2(float64(trigPiOver2Lo_f64))
	BaseCosVec_NEON_piOver2Hi_f32    = asm.BroadcastFloat32x4(float32(trigPiOver2Hi_f32))
	BaseCosVec_NEON_s1_f32           = asm.BroadcastFloat32x4(float32(trigS1_f32))
	BaseCosVec_NEON_s1_f64           = asm.BroadcastFloat64x2(float64(trigS1_f64))
	BaseErfVec_NEON_p_f64            = asm.BroadcastFloat64x2(float64(erfP_f64))
	BaseSigmoidVec_NEON_satHi_f64    = asm.BroadcastFloat64x2(float64(20.0))
	BaseCosVec_NEON_c1_f64           = asm.BroadcastFloat64x2(float64(trigC1_f64))
	BaseErfVec_NEON_zero_f32         = asm.BroadcastFloat32x4(float32(erfZero_f32))
	BaseSinhVec_NEON_c3_f32          = asm.BroadcastFloat32x4(float32(sinhC3_f32))
	BaseCosVec_NEON_piOver2Hi_f64    = asm.BroadcastFloat64x2(float64(trigPiOver2Hi_f64))
	BaseCosVec_NEON_s3_f64           = asm.BroadcastFloat64x2(float64(trigS3_f64))
	BaseCoshVec_NEON_one_f32         = asm.BroadcastFloat32x4(float32(1.0))
	BaseAcoshVec_NEON_one_f64        = asm.BroadcastFloat64x2(float64(1.0))
	BaseAcoshVec_NEON_zero_f64       = asm.BroadcastFloat64x2(float64(0.0))
	BaseExpVec_NEON_overflow_f64     = asm.BroadcastFloat64x2(float64(expOverflow_f64))
	BaseExpVec_NEON_invLn2_f64       = asm.BroadcastFloat64x2(float64(expInvLn2_f64))
	BaseCosVec_NEON_twoOverPi_f64    = asm.BroadcastFloat64x2(float64(trig2OverPi_f64))
	BaseErfVec_NEON_a2_f64           = asm.BroadcastFloat64x2(float64(erfA2_f64))
	BaseCoshVec_NEON_c6_f64          = asm.BroadcastFloat64x2(float64(0.001388888888888889))
	BaseAcoshVec_NEON_zero_f32       = asm.BroadcastFloat32x4(float32(0.0))
	BaseLogVec_NEON_ln2Hi_f32        = asm.BroadcastFloat32x4(float32(logLn2Hi_f32))
	BaseSinVec_NEON_c3_f32           = asm.BroadcastFloat32x4(float32(trigC3_f32))
	BaseErfVec_NEON_zero_f64         = asm.BroadcastFloat64x2(float64(erfZero_f64))
	BaseSinhVec_NEON_c7_f64          = asm.BroadcastFloat64x2(float64(sinhC7_f64))
	BaseAtanhVec_NEON_one_f64        = asm.BroadcastFloat64x2(float64(1.0))
	BaseSinVec_NEON_intThree_i32_f32 = asm.BroadcastInt32x4(3)
	BaseSinVec_NEON_intThree_i32_f64 = asm.BroadcastInt32x2(3)
	BaseCosVec_NEON_piOver2Lo_f32    = asm.BroadcastFloat32x4(float32(trigPiOver2Lo_f32))
	BaseTanhVec_NEON_two_f32         = asm.BroadcastFloat32x4(float32(2.0))
	BaseSinVec_NEON_twoOverPi_f32    = asm.BroadcastFloat32x4(float32(trig2OverPi_f32))
	BaseSinVec_NEON_s3_f32           = asm.BroadcastFloat32x4(float32(trigS3_f32))
	BaseSinVec_NEON_s1_f64           = asm.BroadcastFloat64x2(float64(trigS1_f64))
	BaseSinVec_NEON_one_f64          = asm.BroadcastFloat64x2(float64(trigOne_f64))
	BaseLogVec_NEON_c3_f32           = asm.BroadcastFloat32x4(float32(logC3_f32))
	BaseCosVec_NEON_c3_f32           = asm.BroadcastFloat32x4(float32(trigC3_f32))
	BaseLogVec_NEON_nan_f64          = asm.BroadcastFloat64x2(float64(0.0))
	BaseSinVec_NEON_piOver2Hi_f32    = asm.BroadcastFloat32x4(float32(trigPiOver2Hi_f32))
	BaseSinVec_NEON_s2_f32           = asm.BroadcastFloat32x4(float32(trigS2_f32))
	BaseCosVec_NEON_c4_f64           = asm.BroadcastFloat64x2(float64(trigC4_f64))
	BaseCosVec_NEON_piOver2Lo_f64    = asm.BroadcastFloat64x2(float64(trigPiOver2Lo_f64))
	BaseErfVec_NEON_a1_f32           = asm.BroadcastFloat32x4(float32(erfA1_f32))
	BaseAsinhVec_NEON_one_f32        = asm.BroadcastFloat32x4(float32(1.0))
	BaseExpVec_NEON_one_f64          = asm.BroadcastFloat64x2(float64(expOne_f64))
	BaseLogVec_NEON_ln2Lo_f32        = asm.BroadcastFloat32x4(float32(logLn2Lo_f32))
	BaseLogVec_NEON_two_f32          = asm.BroadcastFloat32x4(float32(logTwo_f32))
	BaseLogVec_NEON_ln2Hi_f64        = asm.BroadcastFloat64x2(float64(logLn2Hi_f64))
	BaseSinVec_NEON_s3_f64           = asm.BroadcastFloat64x2(float64(trigS3_f64))
	BaseSinVec_NEON_s4_f32           = asm.BroadcastFloat32x4(float32(trigS4_f32))
	BaseSinVec_NEON_intOne_i32_f32   = asm.BroadcastInt32x4(1)
	BaseSinVec_NEON_piOver2Hi_f64    = asm.BroadcastFloat64x2(float64(trigPiOver2Hi_f64))
	BaseCosVec_NEON_intOne_i32_f64   = asm.BroadcastInt32x2(1)
	BaseErfVec_NEON_a2_f32           = asm.BroadcastFloat32x4(float32(erfA2_f32))
	BaseErfVec_NEON_a4_f64           = asm.BroadcastFloat64x2(float64(erfA4_f64))
	BaseExpVec_NEON_c3_f64           = asm.BroadcastFloat64x2(float64(expC3_f64))
	BaseTanhVec_NEON_two_f64         = asm.BroadcastFloat64x2(float64(2.0))
	BaseSinVec_NEON_one_f32          = asm.BroadcastFloat32x4(float32(trigOne_f32))
	BaseSinVec_NEON_twoOverPi_f64    = asm.BroadcastFloat64x2(float64(trig2OverPi_f64))
	BaseExpVec_NEON_one_f32          = asm.BroadcastFloat32x4(float32(expOne_f32))
	BaseSinVec_NEON_c3_f64           = asm.BroadcastFloat64x2(float64(trigC3_f64))
	BaseCosVec_NEON_c2_f64           = asm.BroadcastFloat64x2(float64(trigC2_f64))
	BaseCosVec_NEON_s4_f64           = asm.BroadcastFloat64x2(float64(trigS4_f64))
	BaseExp2Vec_NEON_ln2_f64         = asm.BroadcastFloat64x2(float64(ln2_f64))
	BaseAtanhVec_NEON_half_f64       = asm.BroadcastFloat64x2(float64(0.5))
	BaseSinVec_NEON_piOver2Lo_f32    = asm.BroadcastFloat32x4(float32(trigPiOver2Lo_f32))
	BaseTanhVec_NEON_negOne_f32      = asm.BroadcastFloat32x4(float32(tanhNegOne_f32))
	BaseLogVec_NEON_nan_f32          = asm.BroadcastFloat32x4(float32(0.0))
	BaseLogVec_NEON_c1_f32           = asm.BroadcastFloat32x4(float32(logC1_f32))
	BaseExpVec_NEON_invLn2_f32       = asm.BroadcastFloat32x4(float32(expInvLn2_f32))
	BaseCosVec_NEON_s2_f64           = asm.BroadcastFloat64x2(float64(trigS2_f64))
	BaseErfVec_NEON_a5_f32           = asm.BroadcastFloat32x4(float32(erfA5_f32))
	BaseLog10Vec_NEON_log10E_f32     = asm.BroadcastFloat32x4(float32(log10E_f32))
	BaseSigmoidVec_NEON_zero_f64     = asm.BroadcastFloat64x2(float64(0.0))
	BaseTanhVec_NEON_one_f64         = asm.BroadcastFloat64x2(float64(tanhOne_f64))
	BaseSinVec_NEON_intTwo_i32_f32   = asm.BroadcastInt32x4(2)
	BaseSinVec_NEON_c4_f64           = asm.BroadcastFloat64x2(float64(trigC4_f64))
	BaseErfVec_NEON_a3_f32           = asm.BroadcastFloat32x4(float32(erfA3_f32))
	BaseSinhVec_NEON_c5_f32          = asm.BroadcastFloat32x4(float32(sinhC5_f32))
	BaseExpVec_NEON_overflow_f32     = asm.BroadcastFloat32x4(float32(expOverflow_f32))
	BaseLogVec_NEON_c5_f32           = asm.BroadcastFloat32x4(float32(logC5_f32))
	BaseSinVec_NEON_c4_f32           = asm.BroadcastFloat32x4(float32(trigC4_f32))
	BaseCosVec_NEON_intTwo_i32_f64   = asm.BroadcastInt32x2(2)
	BaseErfVec_NEON_a1_f64           = asm.BroadcastFloat64x2(float64(erfA1_f64))
	BaseErfVec_NEON_one_f64          = asm.BroadcastFloat64x2(float64(erfOne_f64))
	BaseLog10Vec_NEON_log10E_f64     = asm.BroadcastFloat64x2(float64(log10E_f64))
	BaseExp2Vec_NEON_ln2_f32         = asm.BroadcastFloat32x4(float32(ln2_f32))
	BaseSigmoidVec_NEON_one_f32      = asm.BroadcastFloat32x4(float32(sigmoidOne_f32))
	BaseExpVec_NEON_underflow_f32    = asm.BroadcastFloat32x4(float32(expUnderflow_f32))
	BaseExpVec_NEON_ln2Hi_f32        = asm.BroadcastFloat32x4(float32(expLn2Hi_f32))
	BaseLogVec_NEON_one_f32          = asm.BroadcastFloat32x4(float32(logOne_f32))
	BaseLogVec_NEON_c3_f64           = asm.BroadcastFloat64x2(float64(logC3_f64))
)

func BaseExpVec_neon(x asm.Float32x4) asm.Float32x4 {
	overflow := BaseExpVec_NEON_overflow_f32
	underflow := BaseExpVec_NEON_underflow_f32
	one := BaseExpVec_NEON_one_f32
	zero := BaseExpVec_NEON_zero_f32
	inf := asm.BroadcastFloat32x4(float32(expOverflow_f32 * 2))
	invLn2 := BaseExpVec_NEON_invLn2_f32
	ln2Hi := BaseExpVec_NEON_ln2Hi_f32
	ln2Lo := BaseExpVec_NEON_ln2Lo_f32
	c1 := BaseExpVec_NEON_c1_f32
	c2 := BaseExpVec_NEON_c2_f32
	c3 := BaseExpVec_NEON_c3_f32
	c4 := BaseExpVec_NEON_c4_f32
	c5 := BaseExpVec_NEON_c5_f32
	c6 := BaseExpVec_NEON_c6_f32
	overflowMask := x.Greater(overflow)
	underflowMask := x.Less(underflow)
	kFloat := x.Mul(invLn2).RoundToEven()
	r := x.Sub(kFloat.Mul(ln2Hi))
	r = r.Sub(kFloat.Mul(ln2Lo))
	p := c6.MulAdd(r, c5)
	p = p.MulAdd(r, c4)
	p = p.MulAdd(r, c3)
	p = p.MulAdd(r, c2)
	p = p.MulAdd(r, c1)
	p = p.MulAdd(r, one)
	kInt := kFloat.ConvertToInt32()
	scale := kInt.Pow2Float32()
	result := p.Mul(scale)
	result = inf.Merge(result, overflowMask)
	result = zero.Merge(result, underflowMask)
	return result
}

func BaseExpVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	overflow := BaseExpVec_NEON_overflow_f64
	underflow := BaseExpVec_NEON_underflow_f64
	one := BaseExpVec_NEON_one_f64
	zero := BaseExpVec_NEON_zero_f64
	inf := asm.BroadcastFloat64x2(float64(expOverflow_f64 * 2))
	invLn2 := BaseExpVec_NEON_invLn2_f64
	ln2Hi := BaseExpVec_NEON_ln2Hi_f64
	ln2Lo := BaseExpVec_NEON_ln2Lo_f64
	c1 := BaseExpVec_NEON_c1_f64
	c2 := BaseExpVec_NEON_c2_f64
	c3 := BaseExpVec_NEON_c3_f64
	c4 := BaseExpVec_NEON_c4_f64
	c5 := BaseExpVec_NEON_c5_f64
	c6 := BaseExpVec_NEON_c6_f64
	overflowMask := x.Greater(overflow)
	underflowMask := x.Less(underflow)
	kFloat := x.Mul(invLn2).RoundToEven()
	r := x.Sub(kFloat.Mul(ln2Hi))
	r = r.Sub(kFloat.Mul(ln2Lo))
	p := c6.MulAdd(r, c5)
	p = p.MulAdd(r, c4)
	p = p.MulAdd(r, c3)
	p = p.MulAdd(r, c2)
	p = p.MulAdd(r, c1)
	p = p.MulAdd(r, one)
	kInt := kFloat.ConvertToInt32()
	scale := kInt.Pow2Float64()
	result := p.Mul(scale)
	result = inf.Merge(result, overflowMask)
	result = zero.Merge(result, underflowMask)
	return result
}

func BaseSigmoidVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseSigmoidVec_NEON_one_f32
	zero := BaseSigmoidVec_NEON_zero_f32
	satHi := BaseSigmoidVec_NEON_satHi_f32
	satLo := BaseSigmoidVec_NEON_satLo_f32
	clampedX := x.Min(satHi).Max(satLo)
	negX := asm.BroadcastFloat32x4(0).Sub(clampedX)
	expNegX := BaseExpVec_neon(negX)
	result := one.Div(one.Add(expNegX))
	result = one.Merge(result, x.Greater(satHi))
	result = zero.Merge(result, x.Less(satLo))
	return result
}

func BaseSigmoidVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseSigmoidVec_NEON_one_f64
	zero := BaseSigmoidVec_NEON_zero_f64
	satHi := BaseSigmoidVec_NEON_satHi_f64
	satLo := BaseSigmoidVec_NEON_satLo_f64
	clampedX := x.Min(satHi).Max(satLo)
	negX := asm.BroadcastFloat64x2(0).Sub(clampedX)
	expNegX := BaseExpVec_neon_Float64(negX)
	result := one.Div(one.Add(expNegX))
	result = one.Merge(result, x.Greater(satHi))
	result = zero.Merge(result, x.Less(satLo))
	return result
}

func BaseTanhVec_neon(x asm.Float32x4) asm.Float32x4 {
	two := BaseTanhVec_NEON_two_f32
	one := BaseTanhVec_NEON_one_f32
	negOne := BaseTanhVec_NEON_negOne_f32
	threshold := BaseTanhVec_NEON_threshold_f32
	negThreshold := asm.BroadcastFloat32x4(0).Sub(threshold)
	twoX := two.Mul(x)
	sigTwoX := BaseSigmoidVec_neon(twoX)
	result := two.Mul(sigTwoX).Sub(one)
	result = one.Merge(result, x.Greater(threshold))
	result = negOne.Merge(result, x.Less(negThreshold))
	return result
}

func BaseTanhVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	two := BaseTanhVec_NEON_two_f64
	one := BaseTanhVec_NEON_one_f64
	negOne := BaseTanhVec_NEON_negOne_f64
	threshold := BaseTanhVec_NEON_threshold_f64
	negThreshold := asm.BroadcastFloat64x2(0).Sub(threshold)
	twoX := two.Mul(x)
	sigTwoX := BaseSigmoidVec_neon_Float64(twoX)
	result := two.Mul(sigTwoX).Sub(one)
	result = one.Merge(result, x.Greater(threshold))
	result = negOne.Merge(result, x.Less(negThreshold))
	return result
}

func BaseLogVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseLogVec_NEON_one_f32
	two := BaseLogVec_NEON_two_f32
	zero := BaseLogVec_NEON_zero_f32
	ln2Hi := BaseLogVec_NEON_ln2Hi_f32
	ln2Lo := BaseLogVec_NEON_ln2Lo_f32
	negInf := BaseLogVec_NEON_negInf_f32
	nan := BaseLogVec_NEON_nan_f32
	c1 := BaseLogVec_NEON_c1_f32
	c2 := BaseLogVec_NEON_c2_f32
	c3 := BaseLogVec_NEON_c3_f32
	c4 := BaseLogVec_NEON_c4_f32
	c5 := BaseLogVec_NEON_c5_f32
	zeroMask := x.Equal(zero)
	negMask := x.Less(zero)
	oneMask := x.Equal(one)
	e := x.AsInt32x4().ShiftAllRight(23).And(asm.BroadcastInt32x4(255)).Sub(asm.BroadcastInt32x4(127)).ConvertToFloat32()
	m := x.AsInt32x4().And(asm.BroadcastInt32x4(8388607)).Or(asm.BroadcastInt32x4(1065353216)).AsFloat32x4()
	mLarge := m.Greater(asm.BroadcastFloat32x4(float32(1.414)))
	mAdjusted := m.Mul(asm.BroadcastFloat32x4(float32(0.5))).Merge(m, mLarge)
	eData := func() []float32 {
		var _simd_tmp [4]float32
		e.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	eFloatData := make([]float32, len(eData))
	for i, v := range eData {
		eFloatData[i] = float32(v)
	}
	eFloat := asm.LoadFloat32x4Slice(eFloatData)
	eAdjusted := eFloat.Add(one).Merge(eFloat, mLarge)
	mMinus1 := mAdjusted.Sub(one)
	mPlus1 := mAdjusted.Add(one)
	y := mMinus1.Div(mPlus1)
	y2 := y.Mul(y)
	poly := c5.MulAdd(y2, c4)
	poly = poly.MulAdd(y2, c3)
	poly = poly.MulAdd(y2, c2)
	poly = poly.MulAdd(y2, c1)
	logM := two.Mul(y).Mul(poly)
	result := eAdjusted.MulAdd(ln2Hi, logM).Add(eAdjusted.Mul(ln2Lo))
	result = negInf.Merge(result, zeroMask)
	result = nan.Merge(result, negMask)
	result = zero.Merge(result, oneMask)
	return result
}

func BaseLogVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseLogVec_NEON_one_f64
	two := BaseLogVec_NEON_two_f64
	zero := BaseLogVec_NEON_zero_f64
	ln2Hi := BaseLogVec_NEON_ln2Hi_f64
	ln2Lo := BaseLogVec_NEON_ln2Lo_f64
	negInf := BaseLogVec_NEON_negInf_f64
	nan := BaseLogVec_NEON_nan_f64
	c1 := BaseLogVec_NEON_c1_f64
	c2 := BaseLogVec_NEON_c2_f64
	c3 := BaseLogVec_NEON_c3_f64
	c4 := BaseLogVec_NEON_c4_f64
	c5 := BaseLogVec_NEON_c5_f64
	zeroMask := x.Equal(zero)
	negMask := x.Less(zero)
	oneMask := x.Equal(one)
	e := x.AsInt64x2().ShiftAllRight(52).And(asm.BroadcastInt64x2(2047)).Sub(asm.BroadcastInt64x2(1023)).ConvertToFloat64()
	m := x.AsInt64x2().And(asm.BroadcastInt64x2(4503599627370495)).Or(asm.BroadcastInt64x2(4607182418800017408)).AsFloat64x2()
	mLarge := m.Greater(asm.BroadcastFloat64x2(float64(1.414)))
	mAdjusted := m.Mul(asm.BroadcastFloat64x2(float64(0.5))).Merge(m, mLarge)
	eData := func() []float64 {
		var _simd_tmp [2]float64
		e.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	eFloatData := make([]float64, len(eData))
	for i, v := range eData {
		eFloatData[i] = float64(v)
	}
	eFloat := asm.LoadFloat64x2Slice(eFloatData)
	eAdjusted := eFloat.Add(one).Merge(eFloat, mLarge)
	mMinus1 := mAdjusted.Sub(one)
	mPlus1 := mAdjusted.Add(one)
	y := mMinus1.Div(mPlus1)
	y2 := y.Mul(y)
	poly := c5.MulAdd(y2, c4)
	poly = poly.MulAdd(y2, c3)
	poly = poly.MulAdd(y2, c2)
	poly = poly.MulAdd(y2, c1)
	logM := two.Mul(y).Mul(poly)
	result := eAdjusted.MulAdd(ln2Hi, logM).Add(eAdjusted.Mul(ln2Lo))
	result = negInf.Merge(result, zeroMask)
	result = nan.Merge(result, negMask)
	result = zero.Merge(result, oneMask)
	return result
}

func BaseSinVec_neon(x asm.Float32x4) asm.Float32x4 {
	twoOverPi := BaseSinVec_NEON_twoOverPi_f32
	piOver2Hi := BaseSinVec_NEON_piOver2Hi_f32
	piOver2Lo := BaseSinVec_NEON_piOver2Lo_f32
	one := BaseSinVec_NEON_one_f32
	s1 := BaseSinVec_NEON_s1_f32
	s2 := BaseSinVec_NEON_s2_f32
	s3 := BaseSinVec_NEON_s3_f32
	s4 := BaseSinVec_NEON_s4_f32
	c1 := BaseSinVec_NEON_c1_f32
	c2 := BaseSinVec_NEON_c2_f32
	c3 := BaseSinVec_NEON_c3_f32
	c4 := BaseSinVec_NEON_c4_f32
	intOne := BaseSinVec_NEON_intOne_i32_f32
	intTwo := BaseSinVec_NEON_intTwo_i32_f32
	intThree := BaseSinVec_NEON_intThree_i32_f32
	kFloat := x.Mul(twoOverPi).RoundToEven()
	kInt := kFloat.ConvertToInt32()
	r := x.Sub(kFloat.Mul(piOver2Hi))
	r = r.Sub(kFloat.Mul(piOver2Lo))
	r2 := r.Mul(r)
	sinPoly := s4.MulAdd(r2, s3)
	sinPoly = sinPoly.MulAdd(r2, s2)
	sinPoly = sinPoly.MulAdd(r2, s1)
	sinPoly = sinPoly.MulAdd(r2, one)
	sinR := r.Mul(sinPoly)
	cosPoly := c4.MulAdd(r2, c3)
	cosPoly = cosPoly.MulAdd(r2, c2)
	cosPoly = cosPoly.MulAdd(r2, c1)
	cosR := cosPoly.MulAdd(r2, one)
	octant := kInt.And(intThree)
	useCosMask := octant.And(intOne).Equal(intOne)
	negateMask := octant.And(intTwo).Equal(intTwo)
	sinRData := func() []float32 {
		var _simd_tmp [4]float32
		sinR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	cosRData := func() []float32 {
		var _simd_tmp [4]float32
		cosR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	resultData := make([]float32, len(sinRData))
	for i := range sinRData {
		if func() bool {
			_vOne := asm.BroadcastInt32x4(1)
			_vZero := asm.BroadcastInt32x4(0)
			_vMasked := _vOne.Merge(_vZero, useCosMask)
			var _simd_mask_tmp [4]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = cosRData[i]
		} else {
			resultData[i] = sinRData[i]
		}
	}
	result := asm.LoadFloat32x4Slice(resultData)
	negResult := asm.BroadcastFloat32x4(0).Sub(result)
	negResultData := func() []float32 {
		var _simd_tmp [4]float32
		negResult.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	for i := range resultData {
		if func() bool {
			_vOne := asm.BroadcastInt32x4(1)
			_vZero := asm.BroadcastInt32x4(0)
			_vMasked := _vOne.Merge(_vZero, negateMask)
			var _simd_mask_tmp [4]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = negResultData[i]
		}
	}
	return asm.LoadFloat32x4Slice(resultData)
}

func BaseSinVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	twoOverPi := BaseSinVec_NEON_twoOverPi_f64
	piOver2Hi := BaseSinVec_NEON_piOver2Hi_f64
	piOver2Lo := BaseSinVec_NEON_piOver2Lo_f64
	one := BaseSinVec_NEON_one_f64
	s1 := BaseSinVec_NEON_s1_f64
	s2 := BaseSinVec_NEON_s2_f64
	s3 := BaseSinVec_NEON_s3_f64
	s4 := BaseSinVec_NEON_s4_f64
	c1 := BaseSinVec_NEON_c1_f64
	c2 := BaseSinVec_NEON_c2_f64
	c3 := BaseSinVec_NEON_c3_f64
	c4 := BaseSinVec_NEON_c4_f64
	intOne := BaseSinVec_NEON_intOne_i32_f64
	intTwo := BaseSinVec_NEON_intTwo_i32_f64
	intThree := BaseSinVec_NEON_intThree_i32_f64
	kFloat := x.Mul(twoOverPi).RoundToEven()
	kInt := kFloat.ConvertToInt32()
	r := x.Sub(kFloat.Mul(piOver2Hi))
	r = r.Sub(kFloat.Mul(piOver2Lo))
	r2 := r.Mul(r)
	sinPoly := s4.MulAdd(r2, s3)
	sinPoly = sinPoly.MulAdd(r2, s2)
	sinPoly = sinPoly.MulAdd(r2, s1)
	sinPoly = sinPoly.MulAdd(r2, one)
	sinR := r.Mul(sinPoly)
	cosPoly := c4.MulAdd(r2, c3)
	cosPoly = cosPoly.MulAdd(r2, c2)
	cosPoly = cosPoly.MulAdd(r2, c1)
	cosR := cosPoly.MulAdd(r2, one)
	octant := kInt.And(intThree)
	useCosMask := octant.And(intOne).Equal(intOne)
	negateMask := octant.And(intTwo).Equal(intTwo)
	sinRData := func() []float64 {
		var _simd_tmp [2]float64
		sinR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	cosRData := func() []float64 {
		var _simd_tmp [2]float64
		cosR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	resultData := make([]float64, len(sinRData))
	for i := range sinRData {
		if func() bool {
			_vOne := asm.BroadcastInt32x2(1)
			_vZero := asm.BroadcastInt32x2(0)
			_vMasked := _vOne.Merge(_vZero, useCosMask)
			var _simd_mask_tmp [2]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = cosRData[i]
		} else {
			resultData[i] = sinRData[i]
		}
	}
	result := asm.LoadFloat64x2Slice(resultData)
	negResult := asm.BroadcastFloat64x2(0).Sub(result)
	negResultData := func() []float64 {
		var _simd_tmp [2]float64
		negResult.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	for i := range resultData {
		if func() bool {
			_vOne := asm.BroadcastInt32x2(1)
			_vZero := asm.BroadcastInt32x2(0)
			_vMasked := _vOne.Merge(_vZero, negateMask)
			var _simd_mask_tmp [2]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = negResultData[i]
		}
	}
	return asm.LoadFloat64x2Slice(resultData)
}

func BaseCosVec_neon(x asm.Float32x4) asm.Float32x4 {
	twoOverPi := BaseCosVec_NEON_twoOverPi_f32
	piOver2Hi := BaseCosVec_NEON_piOver2Hi_f32
	piOver2Lo := BaseCosVec_NEON_piOver2Lo_f32
	one := BaseCosVec_NEON_one_f32
	s1 := BaseCosVec_NEON_s1_f32
	s2 := BaseCosVec_NEON_s2_f32
	s3 := BaseCosVec_NEON_s3_f32
	s4 := BaseCosVec_NEON_s4_f32
	c1 := BaseCosVec_NEON_c1_f32
	c2 := BaseCosVec_NEON_c2_f32
	c3 := BaseCosVec_NEON_c3_f32
	c4 := BaseCosVec_NEON_c4_f32
	intOne := BaseCosVec_NEON_intOne_i32_f32
	intTwo := BaseCosVec_NEON_intTwo_i32_f32
	intThree := BaseCosVec_NEON_intThree_i32_f32
	kFloat := x.Mul(twoOverPi).RoundToEven()
	kInt := kFloat.ConvertToInt32()
	r := x.Sub(kFloat.Mul(piOver2Hi))
	r = r.Sub(kFloat.Mul(piOver2Lo))
	r2 := r.Mul(r)
	sinPoly := s4.MulAdd(r2, s3)
	sinPoly = sinPoly.MulAdd(r2, s2)
	sinPoly = sinPoly.MulAdd(r2, s1)
	sinPoly = sinPoly.MulAdd(r2, one)
	sinR := r.Mul(sinPoly)
	cosPoly := c4.MulAdd(r2, c3)
	cosPoly = cosPoly.MulAdd(r2, c2)
	cosPoly = cosPoly.MulAdd(r2, c1)
	cosR := cosPoly.MulAdd(r2, one)
	cosOctant := kInt.Add(intOne).And(intThree)
	useCosMask := cosOctant.And(intOne).Equal(intOne)
	negateMask := cosOctant.And(intTwo).Equal(intTwo)
	sinRData := func() []float32 {
		var _simd_tmp [4]float32
		sinR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	cosRData := func() []float32 {
		var _simd_tmp [4]float32
		cosR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	resultData := make([]float32, len(sinRData))
	for i := range sinRData {
		if func() bool {
			_vOne := asm.BroadcastInt32x4(1)
			_vZero := asm.BroadcastInt32x4(0)
			_vMasked := _vOne.Merge(_vZero, useCosMask)
			var _simd_mask_tmp [4]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = cosRData[i]
		} else {
			resultData[i] = sinRData[i]
		}
	}
	result := asm.LoadFloat32x4Slice(resultData)
	negResult := asm.BroadcastFloat32x4(0).Sub(result)
	negResultData := func() []float32 {
		var _simd_tmp [4]float32
		negResult.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	for i := range resultData {
		if func() bool {
			_vOne := asm.BroadcastInt32x4(1)
			_vZero := asm.BroadcastInt32x4(0)
			_vMasked := _vOne.Merge(_vZero, negateMask)
			var _simd_mask_tmp [4]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = negResultData[i]
		}
	}
	return asm.LoadFloat32x4Slice(resultData)
}

func BaseCosVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	twoOverPi := BaseCosVec_NEON_twoOverPi_f64
	piOver2Hi := BaseCosVec_NEON_piOver2Hi_f64
	piOver2Lo := BaseCosVec_NEON_piOver2Lo_f64
	one := BaseCosVec_NEON_one_f64
	s1 := BaseCosVec_NEON_s1_f64
	s2 := BaseCosVec_NEON_s2_f64
	s3 := BaseCosVec_NEON_s3_f64
	s4 := BaseCosVec_NEON_s4_f64
	c1 := BaseCosVec_NEON_c1_f64
	c2 := BaseCosVec_NEON_c2_f64
	c3 := BaseCosVec_NEON_c3_f64
	c4 := BaseCosVec_NEON_c4_f64
	intOne := BaseCosVec_NEON_intOne_i32_f64
	intTwo := BaseCosVec_NEON_intTwo_i32_f64
	intThree := BaseCosVec_NEON_intThree_i32_f64
	kFloat := x.Mul(twoOverPi).RoundToEven()
	kInt := kFloat.ConvertToInt32()
	r := x.Sub(kFloat.Mul(piOver2Hi))
	r = r.Sub(kFloat.Mul(piOver2Lo))
	r2 := r.Mul(r)
	sinPoly := s4.MulAdd(r2, s3)
	sinPoly = sinPoly.MulAdd(r2, s2)
	sinPoly = sinPoly.MulAdd(r2, s1)
	sinPoly = sinPoly.MulAdd(r2, one)
	sinR := r.Mul(sinPoly)
	cosPoly := c4.MulAdd(r2, c3)
	cosPoly = cosPoly.MulAdd(r2, c2)
	cosPoly = cosPoly.MulAdd(r2, c1)
	cosR := cosPoly.MulAdd(r2, one)
	cosOctant := kInt.Add(intOne).And(intThree)
	useCosMask := cosOctant.And(intOne).Equal(intOne)
	negateMask := cosOctant.And(intTwo).Equal(intTwo)
	sinRData := func() []float64 {
		var _simd_tmp [2]float64
		sinR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	cosRData := func() []float64 {
		var _simd_tmp [2]float64
		cosR.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	resultData := make([]float64, len(sinRData))
	for i := range sinRData {
		if func() bool {
			_vOne := asm.BroadcastInt32x2(1)
			_vZero := asm.BroadcastInt32x2(0)
			_vMasked := _vOne.Merge(_vZero, useCosMask)
			var _simd_mask_tmp [2]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = cosRData[i]
		} else {
			resultData[i] = sinRData[i]
		}
	}
	result := asm.LoadFloat64x2Slice(resultData)
	negResult := asm.BroadcastFloat64x2(0).Sub(result)
	negResultData := func() []float64 {
		var _simd_tmp [2]float64
		negResult.StoreSlice(_simd_tmp[:])
		return _simd_tmp[:]
	}()
	for i := range resultData {
		if func() bool {
			_vOne := asm.BroadcastInt32x2(1)
			_vZero := asm.BroadcastInt32x2(0)
			_vMasked := _vOne.Merge(_vZero, negateMask)
			var _simd_mask_tmp [2]int32
			_vMasked.StoreSlice(_simd_mask_tmp[:])
			return _simd_mask_tmp[i] != 0
		}() {
			resultData[i] = negResultData[i]
		}
	}
	return asm.LoadFloat64x2Slice(resultData)
}

func BaseErfVec_neon(x asm.Float32x4) asm.Float32x4 {
	a1 := BaseErfVec_NEON_a1_f32
	a2 := BaseErfVec_NEON_a2_f32
	a3 := BaseErfVec_NEON_a3_f32
	a4 := BaseErfVec_NEON_a4_f32
	a5 := BaseErfVec_NEON_a5_f32
	p := BaseErfVec_NEON_p_f32
	one := BaseErfVec_NEON_one_f32
	zero := BaseErfVec_NEON_zero_f32
	absX := x.Abs()
	signMask := x.Less(zero)
	t := one.Div(one.Add(p.Mul(absX)))
	poly := a5.MulAdd(t, a4)
	poly = poly.MulAdd(t, a3)
	poly = poly.MulAdd(t, a2)
	poly = poly.MulAdd(t, a1)
	poly = poly.Mul(t)
	x2 := absX.Mul(absX)
	negX2 := asm.BroadcastFloat32x4(0).Sub(x2)
	expNegX2 := BaseExpVec_neon(negX2)
	erfAbs := one.Sub(poly.Mul(expNegX2))
	erfAbs = erfAbs.Min(one).Max(zero)
	negErfAbs := asm.BroadcastFloat32x4(0).Sub(erfAbs)
	result := negErfAbs.Merge(erfAbs, signMask)
	return result
}

func BaseErfVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	a1 := BaseErfVec_NEON_a1_f64
	a2 := BaseErfVec_NEON_a2_f64
	a3 := BaseErfVec_NEON_a3_f64
	a4 := BaseErfVec_NEON_a4_f64
	a5 := BaseErfVec_NEON_a5_f64
	p := BaseErfVec_NEON_p_f64
	one := BaseErfVec_NEON_one_f64
	zero := BaseErfVec_NEON_zero_f64
	absX := x.Abs()
	signMask := x.Less(zero)
	t := one.Div(one.Add(p.Mul(absX)))
	poly := a5.MulAdd(t, a4)
	poly = poly.MulAdd(t, a3)
	poly = poly.MulAdd(t, a2)
	poly = poly.MulAdd(t, a1)
	poly = poly.Mul(t)
	x2 := absX.Mul(absX)
	negX2 := asm.BroadcastFloat64x2(0).Sub(x2)
	expNegX2 := BaseExpVec_neon_Float64(negX2)
	erfAbs := one.Sub(poly.Mul(expNegX2))
	erfAbs = erfAbs.Min(one).Max(zero)
	negErfAbs := asm.BroadcastFloat64x2(0).Sub(erfAbs)
	result := negErfAbs.Merge(erfAbs, signMask)
	return result
}

func BaseLog2Vec_neon(x asm.Float32x4) asm.Float32x4 {
	log2E := BaseLog2Vec_NEON_log2E_f32
	lnX := BaseLogVec_neon(x)
	return lnX.Mul(log2E)
}

func BaseLog2Vec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	log2E := BaseLog2Vec_NEON_log2E_f64
	lnX := BaseLogVec_neon_Float64(x)
	return lnX.Mul(log2E)
}

func BaseLog10Vec_neon(x asm.Float32x4) asm.Float32x4 {
	log10E := BaseLog10Vec_NEON_log10E_f32
	lnX := BaseLogVec_neon(x)
	return lnX.Mul(log10E)
}

func BaseLog10Vec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	log10E := BaseLog10Vec_NEON_log10E_f64
	lnX := BaseLogVec_neon_Float64(x)
	return lnX.Mul(log10E)
}

func BaseExp2Vec_neon(x asm.Float32x4) asm.Float32x4 {
	ln2 := BaseExp2Vec_NEON_ln2_f32
	xLn2 := x.Mul(ln2)
	return BaseExpVec_neon(xLn2)
}

func BaseExp2Vec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	ln2 := BaseExp2Vec_NEON_ln2_f64
	xLn2 := x.Mul(ln2)
	return BaseExpVec_neon_Float64(xLn2)
}

func BaseSinhVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseSinhVec_NEON_one_f32
	c3 := BaseSinhVec_NEON_c3_f32
	c5 := BaseSinhVec_NEON_c5_f32
	c7 := BaseSinhVec_NEON_c7_f32
	x2 := x.Mul(x)
	poly := c7.MulAdd(x2, c5)
	poly = poly.MulAdd(x2, c3)
	poly = poly.MulAdd(x2, one)
	return x.Mul(poly)
}

func BaseSinhVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseSinhVec_NEON_one_f64
	c3 := BaseSinhVec_NEON_c3_f64
	c5 := BaseSinhVec_NEON_c5_f64
	c7 := BaseSinhVec_NEON_c7_f64
	x2 := x.Mul(x)
	poly := c7.MulAdd(x2, c5)
	poly = poly.MulAdd(x2, c3)
	poly = poly.MulAdd(x2, one)
	return x.Mul(poly)
}

func BaseCoshVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseCoshVec_NEON_one_f32
	c2 := BaseCoshVec_NEON_c2_f32
	c4 := BaseCoshVec_NEON_c4_f32
	c6 := BaseCoshVec_NEON_c6_f32
	x2 := x.Mul(x)
	poly := c6.MulAdd(x2, c4)
	poly = poly.MulAdd(x2, c2)
	return poly.MulAdd(x2, one)
}

func BaseCoshVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseCoshVec_NEON_one_f64
	c2 := BaseCoshVec_NEON_c2_f64
	c4 := BaseCoshVec_NEON_c4_f64
	c6 := BaseCoshVec_NEON_c6_f64
	x2 := x.Mul(x)
	poly := c6.MulAdd(x2, c4)
	poly = poly.MulAdd(x2, c2)
	return poly.MulAdd(x2, one)
}

func BaseAsinhVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseAsinhVec_NEON_one_f32
	x2 := x.Mul(x)
	x2Plus1 := x2.Add(one)
	sqrtPart := x2Plus1.Sqrt()
	arg := x.Add(sqrtPart)
	return BaseLogVec_neon(arg)
}

func BaseAsinhVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseAsinhVec_NEON_one_f64
	x2 := x.Mul(x)
	x2Plus1 := x2.Add(one)
	sqrtPart := x2Plus1.Sqrt()
	arg := x.Add(sqrtPart)
	return BaseLogVec_neon_Float64(arg)
}

func BaseAcoshVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseAcoshVec_NEON_one_f32
	zero := BaseAcoshVec_NEON_zero_f32
	x2 := x.Mul(x)
	x2Minus1 := x2.Sub(one)
	sqrtPart := x2Minus1.Sqrt()
	arg := x.Add(sqrtPart)
	result := BaseLogVec_neon(arg)
	oneMask := x.Equal(one)
	result = zero.Merge(result, oneMask)
	return result
}

func BaseAcoshVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseAcoshVec_NEON_one_f64
	zero := BaseAcoshVec_NEON_zero_f64
	x2 := x.Mul(x)
	x2Minus1 := x2.Sub(one)
	sqrtPart := x2Minus1.Sqrt()
	arg := x.Add(sqrtPart)
	result := BaseLogVec_neon_Float64(arg)
	oneMask := x.Equal(one)
	result = zero.Merge(result, oneMask)
	return result
}

func BaseAtanhVec_neon(x asm.Float32x4) asm.Float32x4 {
	one := BaseAtanhVec_NEON_one_f32
	half := BaseAtanhVec_NEON_half_f32
	zero := BaseAtanhVec_NEON_zero_f32
	onePlusX := one.Add(x)
	oneMinusX := one.Sub(x)
	ratio := onePlusX.Div(oneMinusX)
	logRatio := BaseLogVec_neon(ratio)
	result := half.Mul(logRatio)
	zeroMask := x.Equal(zero)
	result = zero.Merge(result, zeroMask)
	return result
}

func BaseAtanhVec_neon_Float64(x asm.Float64x2) asm.Float64x2 {
	one := BaseAtanhVec_NEON_one_f64
	half := BaseAtanhVec_NEON_half_f64
	zero := BaseAtanhVec_NEON_zero_f64
	onePlusX := one.Add(x)
	oneMinusX := one.Sub(x)
	ratio := onePlusX.Div(oneMinusX)
	logRatio := BaseLogVec_neon_Float64(ratio)
	result := half.Mul(logRatio)
	zeroMask := x.Equal(zero)
	result = zero.Merge(result, zeroMask)
	return result
}
