// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package activation

import (
	stdmath "math"
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

func BaseGELU_avx2_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(0.5))))
	vOne := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(1.0))))
	vInvSqrt2 := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(0.7071067811865476))))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2_Float16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx2_Float16(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2_Float16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToFloat16(float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476))))
	}
}

func BaseGELU_avx2_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(0.5))))
	vOne := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(1.0))))
	vInvSqrt2 := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(0.7071067811865476))))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2_BFloat16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx2_BFloat16(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2_BFloat16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToBFloat16(float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476))))
	}
}

func BaseGELU_avx2(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := archsimd.BroadcastFloat32x8(0.5)
	vOne := archsimd.BroadcastFloat32x8(1.0)
	vInvSqrt2 := archsimd.BroadcastFloat32x8(0.7071067811865476)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii+8])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx2(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.Store((*[8]float32)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476)))
	}
}

func BaseGELU_avx2_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := archsimd.BroadcastFloat64x4(0.5)
	vOne := archsimd.BroadcastFloat64x4(1.0)
	vInvSqrt2 := archsimd.BroadcastFloat64x4(0.7071067811865476)
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2_Float64(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii+4])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx2_Float64(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.Store((*[4]float64)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx2_Float64(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float64(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476)))
	}
}

func BaseGELUApprox_avx2_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(1.702))))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2_Float16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx2_Float16(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2_Float16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = hwy.Float32ToFloat16(float32(x * sigmoid))
	}
}

func BaseGELUApprox_avx2_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(1.702))))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2_BFloat16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx2_BFloat16(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2_BFloat16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = hwy.Float32ToBFloat16(float32(x * sigmoid))
	}
}

func BaseGELUApprox_avx2(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := archsimd.BroadcastFloat32x8(1.702)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii+8])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx2(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[8]float32)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = float32(x * sigmoid)
	}
}

func BaseGELUApprox_avx2_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := archsimd.BroadcastFloat64x4(1.702)
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2_Float64(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii+4])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx2_Float64(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[4]float64)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx2_Float64(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = float64(x * sigmoid)
	}
}

func BaseReLU_avx2_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(0.0))))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		result1 := x1.Max(vZero)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToFloat16(0)
		}
	}
}

func BaseReLU_avx2_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(0.0))))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		result1 := x1.Max(vZero)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToBFloat16(0)
		}
	}
}

func BaseReLU_avx2(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := archsimd.BroadcastFloat32x8(0.0)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii+8])))
		result1 := x1.Max(vZero)
		result1.Store((*[8]float32)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = 0
		}
	}
}

func BaseReLU_avx2_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := archsimd.BroadcastFloat64x4(0.0)
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii+4])))
		result1 := x1.Max(vZero)
		result1.Store((*[4]float64)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = 0
		}
	}
}

func BaseSiLU_avx2_Float16(input []hwy.Float16, output []hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		sigmoidX := math.BaseSigmoidVec_avx2_Float16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		sigmoidX1 := math.BaseSigmoidVec_avx2_Float16(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		sigmoidX := math.BaseSigmoidVec_avx2_Float16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = hwy.Float32ToFloat16(float32(x * sigmoid))
	}
}

func BaseSiLU_avx2_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		sigmoidX := math.BaseSigmoidVec_avx2_BFloat16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		sigmoidX1 := math.BaseSigmoidVec_avx2_BFloat16(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		sigmoidX := math.BaseSigmoidVec_avx2_BFloat16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = hwy.Float32ToBFloat16(float32(x * sigmoid))
	}
}

func BaseSiLU_avx2(input []float32, output []float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx2(x)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii+8])))
		sigmoidX1 := math.BaseSigmoidVec_avx2(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[8]float32)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx2(x)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = float32(x * sigmoid)
	}
}

func BaseSiLU_avx2_Float64(input []float64, output []float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx2_Float64(x)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii+4])))
		sigmoidX1 := math.BaseSigmoidVec_avx2_Float64(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[4]float64)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx2_Float64(x)
		result := x.Mul(sigmoidX)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = float64(x * sigmoid)
	}
}

func BaseLeakyReLU_avx2_Float16(input []hwy.Float16, output []hwy.Float16, alpha hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastFloat16x8AVX2(uint16(alpha))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToFloat16(alpha.Float32() * input[i].Float32())
		}
	}
}

func BaseLeakyReLU_avx2_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastBFloat16x8AVX2(uint16(alpha))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToBFloat16(alpha.Float32() * input[i].Float32())
		}
	}
}

func BaseLeakyReLU_avx2(input []float32, output []float32, alpha float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := archsimd.BroadcastFloat32x8(alpha)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii+8])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.Store((*[8]float32)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = alpha * input[i]
		}
	}
}

func BaseLeakyReLU_avx2_Float64(input []float64, output []float64, alpha float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := archsimd.BroadcastFloat64x4(alpha)
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii+4])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.Store((*[4]float64)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = alpha * input[i]
		}
	}
}

func BaseELU_avx2_Float16(input []hwy.Float16, output []hwy.Float16, alpha hwy.Float16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(0.0))))
	vOne := asm.BroadcastFloat16x8AVX2(uint16(hwy.Float32ToFloat16(float32(1.0))))
	vAlpha := asm.BroadcastFloat16x8AVX2(uint16(alpha))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		expX := math.BaseExpVec_avx2_Float16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		expX1 := math.BaseExpVec_avx2_Float16(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		expX := math.BaseExpVec_avx2_Float16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			x := float64(input[i].Float32())
			output[i] = hwy.Float32ToFloat16(float32(float64(alpha) * (stdmath.Exp(x) - 1.0)))
		}
	}
}

func BaseELU_avx2_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(0.0))))
	vOne := asm.BroadcastBFloat16x8AVX2(uint16(hwy.Float32ToBFloat16(float32(1.0))))
	vAlpha := asm.BroadcastBFloat16x8AVX2(uint16(alpha))
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		expX := math.BaseExpVec_avx2_BFloat16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii+8:]))), len(input[ii+8:])))
		expX1 := math.BaseExpVec_avx2_BFloat16(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+8:]))), len(output[ii+8:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x8AVX2Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(input[ii:]))), len(input[ii:])))
		expX := math.BaseExpVec_avx2_BFloat16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			x := float64(input[i].Float32())
			output[i] = hwy.Float32ToBFloat16(float32(float64(alpha) * (stdmath.Exp(x) - 1.0)))
		}
	}
}

func BaseELU_avx2(input []float32, output []float32, alpha float32) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := archsimd.BroadcastFloat32x8(0.0)
	vOne := archsimd.BroadcastFloat32x8(1.0)
	vAlpha := archsimd.BroadcastFloat32x8(alpha)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx2(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii+8])))
		expX1 := math.BaseExpVec_avx2(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.Store((*[8]float32)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx2(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[8]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			x := float64(input[i])
			output[i] = float32(float64(alpha) * (stdmath.Exp(x) - 1.0))
		}
	}
}

func BaseELU_avx2_Float64(input []float64, output []float64, alpha float64) {
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := archsimd.BroadcastFloat64x4(0.0)
	vOne := archsimd.BroadcastFloat64x4(1.0)
	vAlpha := archsimd.BroadcastFloat64x4(alpha)
	lanes := 4
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx2_Float64(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii+4])))
		expX1 := math.BaseExpVec_avx2_Float64(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.Store((*[4]float64)(unsafe.Pointer(&output[ii+4])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx2_Float64(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[4]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			x := float64(input[i])
			output[i] = float64(float64(alpha) * (stdmath.Exp(x) - 1.0))
		}
	}
}
