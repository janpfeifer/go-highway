// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package activation

import (
	stdmath "math"
	"simd/archsimd"
	"sync"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

// Hoisted constants - lazily initialized on first use to avoid init-time crashes
var (
	BaseELU_AVX512_vOne_f32          archsimd.Float32x16
	BaseELU_AVX512_vOne_f64          archsimd.Float64x8
	BaseELU_AVX512_vZero_f32         archsimd.Float32x16
	BaseELU_AVX512_vZero_f64         archsimd.Float64x8
	BaseGELUApprox_AVX512_vCoeff_f32 archsimd.Float32x16
	BaseGELUApprox_AVX512_vCoeff_f64 archsimd.Float64x8
	BaseGELU_AVX512_vHalf_f32        archsimd.Float32x16
	BaseGELU_AVX512_vHalf_f64        archsimd.Float64x8
	BaseGELU_AVX512_vInvSqrt2_f32    archsimd.Float32x16
	BaseGELU_AVX512_vInvSqrt2_f64    archsimd.Float64x8
	BaseGELU_AVX512_vOne_f32         archsimd.Float32x16
	BaseGELU_AVX512_vOne_f64         archsimd.Float64x8
	BaseReLU_AVX512_vZero_f32        archsimd.Float32x16
	BaseReLU_AVX512_vZero_f64        archsimd.Float64x8
	_activationBaseHoistOnce         sync.Once
)

func _activationBaseInitHoistedConstants() {
	_activationBaseHoistOnce.Do(func() {
		BaseELU_AVX512_vOne_f32 = archsimd.BroadcastFloat32x16(1.0)
		BaseELU_AVX512_vOne_f64 = archsimd.BroadcastFloat64x8(1.0)
		BaseELU_AVX512_vZero_f32 = archsimd.BroadcastFloat32x16(0.0)
		BaseELU_AVX512_vZero_f64 = archsimd.BroadcastFloat64x8(0.0)
		BaseGELUApprox_AVX512_vCoeff_f32 = archsimd.BroadcastFloat32x16(1.702)
		BaseGELUApprox_AVX512_vCoeff_f64 = archsimd.BroadcastFloat64x8(1.702)
		BaseGELU_AVX512_vHalf_f32 = archsimd.BroadcastFloat32x16(0.5)
		BaseGELU_AVX512_vHalf_f64 = archsimd.BroadcastFloat64x8(0.5)
		BaseGELU_AVX512_vInvSqrt2_f32 = archsimd.BroadcastFloat32x16(0.7071067811865476)
		BaseGELU_AVX512_vInvSqrt2_f64 = archsimd.BroadcastFloat64x8(0.7071067811865476)
		BaseGELU_AVX512_vOne_f32 = archsimd.BroadcastFloat32x16(1.0)
		BaseGELU_AVX512_vOne_f64 = archsimd.BroadcastFloat64x8(1.0)
		BaseReLU_AVX512_vZero_f32 = archsimd.BroadcastFloat32x16(0.0)
		BaseReLU_AVX512_vZero_f64 = archsimd.BroadcastFloat64x8(0.0)
	})
}

func BaseGELU_avx512_Float16(input []hwy.Float16, output []hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(0.5))))
	vOne := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(1.0))))
	vInvSqrt2 := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(0.7071067811865476))))
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512_Float16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx512_Float16(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512_Float16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToFloat16(float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476))))
	}
}

func BaseGELU_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(0.5))))
	vOne := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(1.0))))
	vInvSqrt2 := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(0.7071067811865476))))
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512_BFloat16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx512_BFloat16(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512_BFloat16(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToBFloat16(float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476))))
	}
}

func BaseGELU_avx512(input []float32, output []float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := BaseGELU_AVX512_vHalf_f32
	vOne := BaseGELU_AVX512_vOne_f32
	vInvSqrt2 := BaseGELU_AVX512_vInvSqrt2_f32
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx512(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float32(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476)))
	}
}

func BaseGELU_avx512_Float64(input []float64, output []float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vHalf := BaseGELU_AVX512_vHalf_f64
	vOne := BaseGELU_AVX512_vOne_f64
	vInvSqrt2 := BaseGELU_AVX512_vInvSqrt2_f64
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512_Float64(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		xScaled1 := x1.Mul(vInvSqrt2)
		erfX1 := math.BaseErfVec_avx512_Float64(xScaled1)
		onePlusErf1 := vOne.Add(erfX1)
		halfOnePlusErf1 := vHalf.Mul(onePlusErf1)
		result1 := x1.Mul(halfOnePlusErf1)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vInvSqrt2)
		erfX := math.BaseErfVec_avx512_Float64(xScaled)
		onePlusErf := vOne.Add(erfX)
		halfOnePlusErf := vHalf.Mul(onePlusErf)
		result := x.Mul(halfOnePlusErf)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float64(x * 0.5 * (1.0 + stdmath.Erf(x*0.7071067811865476)))
	}
}

func BaseGELUApprox_avx512_Float16(input []hwy.Float16, output []hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(1.702))))
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512_Float16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx512_Float16(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512_Float16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = hwy.Float32ToFloat16(float32(x * sigmoid))
	}
}

func BaseGELUApprox_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(1.702))))
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512_BFloat16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx512_BFloat16(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512_BFloat16(xScaled)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = hwy.Float32ToBFloat16(float32(x * sigmoid))
	}
}

func BaseGELUApprox_avx512(input []float32, output []float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := BaseGELUApprox_AVX512_vCoeff_f32
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx512(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = float32(x * sigmoid)
	}
}

func BaseGELUApprox_avx512_Float64(input []float64, output []float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vCoeff := BaseGELUApprox_AVX512_vCoeff_f64
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512_Float64(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		xScaled1 := x1.Mul(vCoeff)
		sigmoidX1 := math.BaseSigmoidVec_avx512_Float64(xScaled1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		xScaled := x.Mul(vCoeff)
		sigmoidX := math.BaseSigmoidVec_avx512_Float64(xScaled)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-1.702*x))
		output[i] = float64(x * sigmoid)
	}
}

func BaseReLU_avx512_Float16(input []hwy.Float16, output []hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(0.0))))
	lanes := 16
	ii := 0
	for ; ii+lanes*3 <= size; ii += lanes * 3 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		result1 := x1.Max(vZero)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
		x2 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+32:][0]))
		result2 := x2.Max(vZero)
		result2.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+32:]))), len(output[ii+32:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToFloat16(0)
		}
	}
}

func BaseReLU_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(0.0))))
	lanes := 16
	ii := 0
	for ; ii+lanes*3 <= size; ii += lanes * 3 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		result1 := x1.Max(vZero)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
		x2 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+32:][0]))
		result2 := x2.Max(vZero)
		result2.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+32:]))), len(output[ii+32:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := x.Max(vZero)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToBFloat16(0)
		}
	}
}

func BaseReLU_avx512(input []float32, output []float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseReLU_AVX512_vZero_f32
	lanes := 16
	ii := 0
	for ; ii+lanes*3 <= size; ii += lanes * 3 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		result1 := x1.Max(vZero)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
		x2 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+32])))
		result2 := x2.Max(vZero)
		result2.Store((*[16]float32)(unsafe.Pointer(&output[ii+32])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = 0
		}
	}
}

func BaseReLU_avx512_Float64(input []float64, output []float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseReLU_AVX512_vZero_f64
	lanes := 8
	ii := 0
	for ; ii+lanes*3 <= size; ii += lanes * 3 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		result1 := x1.Max(vZero)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
		x2 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+16])))
		result2 := x2.Max(vZero)
		result2.Store((*[8]float64)(unsafe.Pointer(&output[ii+16])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		result := x.Max(vZero)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = 0
		}
	}
}

func BaseSiLU_avx512_Float16(input []hwy.Float16, output []hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		sigmoidX := math.BaseSigmoidVec_avx512_Float16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		sigmoidX1 := math.BaseSigmoidVec_avx512_Float16(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		sigmoidX := math.BaseSigmoidVec_avx512_Float16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = hwy.Float32ToFloat16(float32(x * sigmoid))
	}
}

func BaseSiLU_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		sigmoidX := math.BaseSigmoidVec_avx512_BFloat16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		sigmoidX1 := math.BaseSigmoidVec_avx512_BFloat16(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		sigmoidX := math.BaseSigmoidVec_avx512_BFloat16(x)
		result := x.Mul(sigmoidX)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = hwy.Float32ToBFloat16(float32(x * sigmoid))
	}
}

func BaseSiLU_avx512(input []float32, output []float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx512(x)
		result := x.Mul(sigmoidX)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		sigmoidX1 := math.BaseSigmoidVec_avx512(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx512(x)
		result := x.Mul(sigmoidX)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = float32(x * sigmoid)
	}
}

func BaseSiLU_avx512_Float64(input []float64, output []float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx512_Float64(x)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		sigmoidX1 := math.BaseSigmoidVec_avx512_Float64(x1)
		result1 := x1.Mul(sigmoidX1)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		sigmoidX := math.BaseSigmoidVec_avx512_Float64(x)
		result := x.Mul(sigmoidX)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		sigmoid := 1.0 / (1.0 + stdmath.Exp(-x))
		output[i] = float64(x * sigmoid)
	}
}

func BaseLeakyReLU_avx512_Float16(input []hwy.Float16, output []hwy.Float16, alpha hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastFloat16x16AVX512(uint16(alpha))
	lanes := 16
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
		x2 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+32:][0]))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+32:]))), len(output[ii+32:])))
		x3 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+48:][0]))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+48:]))), len(output[ii+48:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToFloat16(alpha.Float32() * input[i].Float32())
		}
	}
}

func BaseLeakyReLU_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := asm.BroadcastBFloat16x16AVX512(uint16(alpha))
	lanes := 16
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
		x2 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+32:][0]))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+32:]))), len(output[ii+32:])))
		x3 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+48:][0]))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+48:]))), len(output[ii+48:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			output[i] = hwy.Float32ToBFloat16(alpha.Float32() * input[i].Float32())
		}
	}
}

func BaseLeakyReLU_avx512(input []float32, output []float32, alpha float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := archsimd.BroadcastFloat32x16(alpha)
	lanes := 16
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
		x2 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+32])))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.Store((*[16]float32)(unsafe.Pointer(&output[ii+32])))
		x3 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+48])))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.Store((*[16]float32)(unsafe.Pointer(&output[ii+48])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = alpha * input[i]
		}
	}
}

func BaseLeakyReLU_avx512_Float64(input []float64, output []float64, alpha float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vAlpha := archsimd.BroadcastFloat64x8(alpha)
	lanes := 8
	ii := 0
	for ; ii+lanes*4 <= size; ii += lanes * 4 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		negPart1 := x1.Mul(vAlpha)
		result1 := x1.Max(negPart1)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
		x2 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+16])))
		negPart2 := x2.Mul(vAlpha)
		result2 := x2.Max(negPart2)
		result2.Store((*[8]float64)(unsafe.Pointer(&output[ii+16])))
		x3 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+24])))
		negPart3 := x3.Mul(vAlpha)
		result3 := x3.Max(negPart3)
		result3.Store((*[8]float64)(unsafe.Pointer(&output[ii+24])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		negPart := x.Mul(vAlpha)
		result := x.Max(negPart)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			output[i] = alpha * input[i]
		}
	}
}

func BaseTanh_avx512_Float16(input []hwy.Float16, output []hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := math.BaseTanhVec_avx512_Float16(x)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		result1 := math.BaseTanhVec_avx512_Float16(x1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := math.BaseTanhVec_avx512_Float16(x)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToFloat16(float32(stdmath.Tanh(x)))
	}
}

func BaseTanh_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := math.BaseTanhVec_avx512_BFloat16(x)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		result1 := math.BaseTanhVec_avx512_BFloat16(x1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		result := math.BaseTanhVec_avx512_BFloat16(x)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i].Float32())
		output[i] = hwy.Float32ToBFloat16(float32(stdmath.Tanh(x)))
	}
}

func BaseTanh_avx512(input []float32, output []float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_avx512(x)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		result1 := math.BaseTanhVec_avx512(x1)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_avx512(x)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float32(stdmath.Tanh(x))
	}
}

func BaseTanh_avx512_Float64(input []float64, output []float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_avx512_Float64(x)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		result1 := math.BaseTanhVec_avx512_Float64(x1)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		result := math.BaseTanhVec_avx512_Float64(x)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		x := float64(input[i])
		output[i] = float64(stdmath.Tanh(x))
	}
}

func BaseELU_avx512_Float16(input []hwy.Float16, output []hwy.Float16, alpha hwy.Float16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(0.0))))
	vOne := asm.BroadcastFloat16x16AVX512(uint16(hwy.Float32ToFloat16(float32(1.0))))
	vAlpha := asm.BroadcastFloat16x16AVX512(uint16(alpha))
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		expX := math.BaseExpVec_avx512_Float16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		expX1 := math.BaseExpVec_avx512_Float16(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		expX := math.BaseExpVec_avx512_Float16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToFloat16(input[i].Float32())
		} else {
			x := float64(input[i].Float32())
			output[i] = hwy.Float32ToFloat16(float32(float64(alpha.Float32()) * (stdmath.Exp(x) - 1.0)))
		}
	}
}

func BaseELU_avx512_BFloat16(input []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(0.0))))
	vOne := asm.BroadcastBFloat16x16AVX512(uint16(hwy.Float32ToBFloat16(float32(1.0))))
	vAlpha := asm.BroadcastBFloat16x16AVX512(uint16(alpha))
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		expX := math.BaseExpVec_avx512_BFloat16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
		x1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii+16:][0]))
		expX1 := math.BaseExpVec_avx512_BFloat16(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii+16:]))), len(output[ii+16:])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&input[ii:][0]))
		expX := math.BaseExpVec_avx512_BFloat16(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(output[ii:]))), len(output[ii:])))
	}
	for i := ii; i < size; i++ {
		if input[i].Float32() > 0 {
			output[i] = hwy.Float32ToBFloat16(input[i].Float32())
		} else {
			x := float64(input[i].Float32())
			output[i] = hwy.Float32ToBFloat16(float32(float64(alpha.Float32()) * (stdmath.Exp(x) - 1.0)))
		}
	}
}

func BaseELU_avx512(input []float32, output []float32, alpha float32) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseELU_AVX512_vZero_f32
	vOne := BaseELU_AVX512_vOne_f32
	vAlpha := archsimd.BroadcastFloat32x16(alpha)
	lanes := 16
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx512(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii+16])))
		expX1 := math.BaseExpVec_avx512(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.Store((*[16]float32)(unsafe.Pointer(&output[ii+16])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx512(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[16]float32)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			x := float64(input[i])
			output[i] = float32(float64(alpha) * (stdmath.Exp(x) - 1.0))
		}
	}
}

func BaseELU_avx512_Float64(input []float64, output []float64, alpha float64) {
	_activationBaseInitHoistedConstants()
	size := min(len(input), len(output))
	if size == 0 {
		return
	}
	vZero := BaseELU_AVX512_vZero_f64
	vOne := BaseELU_AVX512_vOne_f64
	vAlpha := archsimd.BroadcastFloat64x8(alpha)
	lanes := 8
	ii := 0
	for ; ii+lanes*2 <= size; ii += lanes * 2 {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx512_Float64(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
		x1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii+8])))
		expX1 := math.BaseExpVec_avx512_Float64(x1)
		expM11 := expX1.Sub(vOne)
		negPart1 := vAlpha.Mul(expM11)
		isPositive1 := x1.Greater(vZero)
		result1 := x1.Merge(negPart1, isPositive1)
		result1.Store((*[8]float64)(unsafe.Pointer(&output[ii+8])))
	}
	for ; ii+lanes <= size; ii += lanes {
		x := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&input[ii])))
		expX := math.BaseExpVec_avx512_Float64(x)
		expM1 := expX.Sub(vOne)
		negPart := vAlpha.Mul(expM1)
		isPositive := x.Greater(vZero)
		result := x.Merge(negPart, isPositive)
		result.Store((*[8]float64)(unsafe.Pointer(&output[ii])))
	}
	for i := ii; i < size; i++ {
		if input[i] > 0 {
			output[i] = input[i]
		} else {
			x := float64(input[i])
			output[i] = float64(float64(alpha) * (stdmath.Exp(x) - 1.0))
		}
	}
}
