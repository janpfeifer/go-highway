// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package image

import (
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
)

// Hoisted constants - pre-broadcasted at package init time
var (
	BaseForwardRCT_AVX2_twoVec_f32     = archsimd.BroadcastInt64x4(int64(2))
	BaseForwardRCT_AVX2_twoVec_i32_f32 = archsimd.BroadcastInt32x8(int32(2))
)

func BaseForwardRCT_avx2_Int32(r *Image[int32], g *Image[int32], b *Image[int32], outY *Image[int32], outCb *Image[int32], outCr *Image[int32]) {
	if r == nil || g == nil || b == nil || outY == nil || outCb == nil || outCr == nil {
		return
	}
	if r.data == nil || g.data == nil || b.data == nil || outY.data == nil || outCb.data == nil || outCr.data == nil {
		return
	}
	twoVec := BaseForwardRCT_AVX2_twoVec_i32_f32
	lanes := 8
	height := r.height
	width := r.width
	for y := range height {
		rRow := r.Row(y)
		gRow := g.Row(y)
		bRow := b.Row(y)
		yRow := outY.Row(y)
		cbRow := outCb.Row(y)
		crRow := outCr.Row(y)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vr := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&rRow[i])))
			vg := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&gRow[i])))
			vb := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bRow[i])))
			twoG := vg.Mul(twoVec)
			sum := vr.Add(twoG).Add(vb)
			vy := sum.ShiftAllRight(uint64(2))
			vcb := vb.Sub(vg)
			vcr := vr.Sub(vg)
			vy.Store((*[8]int32)(unsafe.Pointer(&yRow[i])))
			vcb.Store((*[8]int32)(unsafe.Pointer(&cbRow[i])))
			vcr.Store((*[8]int32)(unsafe.Pointer(&crRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufR := [8]int32{}
			bufG := [8]int32{}
			bufB := [8]int32{}
			bufY := [8]int32{}
			bufCb := [8]int32{}
			bufCr := [8]int32{}
			copy(bufR[:], rRow[i:i+remaining])
			copy(bufG[:], gRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			vr := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bufR[0])))
			vg := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bufG[0])))
			vb := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bufB[0])))
			twoG := vg.Mul(twoVec)
			sum := vr.Add(twoG).Add(vb)
			vy := sum.ShiftAllRight(uint64(2))
			vcb := vb.Sub(vg)
			vcr := vr.Sub(vg)
			vy.Store((*[8]int32)(unsafe.Pointer(&bufY[0])))
			vcb.Store((*[8]int32)(unsafe.Pointer(&bufCb[0])))
			vcr.Store((*[8]int32)(unsafe.Pointer(&bufCr[0])))
			copy(yRow[i:i+remaining], bufY[:remaining])
			copy(cbRow[i:i+remaining], bufCb[:remaining])
			copy(crRow[i:i+remaining], bufCr[:remaining])
		}
	}
}

func BaseForwardRCT_avx2_Int64(r *Image[int64], g *Image[int64], b *Image[int64], outY *Image[int64], outCb *Image[int64], outCr *Image[int64]) {
	if r == nil || g == nil || b == nil || outY == nil || outCb == nil || outCr == nil {
		return
	}
	if r.data == nil || g.data == nil || b.data == nil || outY.data == nil || outCb.data == nil || outCr.data == nil {
		return
	}
	twoVec := BaseForwardRCT_AVX2_twoVec_f32
	lanes := 4
	height := r.height
	width := r.width
	for y := range height {
		rRow := r.Row(y)
		gRow := g.Row(y)
		bRow := b.Row(y)
		yRow := outY.Row(y)
		cbRow := outCb.Row(y)
		crRow := outCr.Row(y)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vr := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&rRow[i])))
			vg := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&gRow[i])))
			vb := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bRow[i])))
			twoG := vg.Mul(twoVec)
			sum := vr.Add(twoG).Add(vb)
			vy := sum.ShiftAllRight(uint64(2))
			vcb := vb.Sub(vg)
			vcr := vr.Sub(vg)
			vy.Store((*[4]int64)(unsafe.Pointer(&yRow[i])))
			vcb.Store((*[4]int64)(unsafe.Pointer(&cbRow[i])))
			vcr.Store((*[4]int64)(unsafe.Pointer(&crRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufR := [4]int64{}
			bufG := [4]int64{}
			bufB := [4]int64{}
			bufY := [4]int64{}
			bufCb := [4]int64{}
			bufCr := [4]int64{}
			copy(bufR[:], rRow[i:i+remaining])
			copy(bufG[:], gRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			vr := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bufR[0])))
			vg := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bufG[0])))
			vb := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bufB[0])))
			twoG := vg.Mul(twoVec)
			sum := vr.Add(twoG).Add(vb)
			vy := sum.ShiftAllRight(uint64(2))
			vcb := vb.Sub(vg)
			vcr := vr.Sub(vg)
			vy.Store((*[4]int64)(unsafe.Pointer(&bufY[0])))
			vcb.Store((*[4]int64)(unsafe.Pointer(&bufCb[0])))
			vcr.Store((*[4]int64)(unsafe.Pointer(&bufCr[0])))
			copy(yRow[i:i+remaining], bufY[:remaining])
			copy(cbRow[i:i+remaining], bufCb[:remaining])
			copy(crRow[i:i+remaining], bufCr[:remaining])
		}
	}
}

func BaseInverseRCT_avx2_Int32(y *Image[int32], cb *Image[int32], cr *Image[int32], outR *Image[int32], outG *Image[int32], outB *Image[int32]) {
	if y == nil || cb == nil || cr == nil || outR == nil || outG == nil || outB == nil {
		return
	}
	if y.data == nil || cb.data == nil || cr.data == nil || outR.data == nil || outG.data == nil || outB.data == nil {
		return
	}
	lanes := 8
	height := y.height
	width := y.width
	for row := range height {
		yRow := y.Row(row)
		cbRow := cb.Row(row)
		crRow := cr.Row(row)
		rRow := outR.Row(row)
		gRow := outG.Row(row)
		bRow := outB.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vy := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&yRow[i])))
			vcb := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&cbRow[i])))
			vcr := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&crRow[i])))
			cbPlusCr := vcb.Add(vcr)
			shift := cbPlusCr.ShiftAllRight(uint64(2))
			vg := vy.Sub(shift)
			vr := vcr.Add(vg)
			vb := vcb.Add(vg)
			vr.Store((*[8]int32)(unsafe.Pointer(&rRow[i])))
			vg.Store((*[8]int32)(unsafe.Pointer(&gRow[i])))
			vb.Store((*[8]int32)(unsafe.Pointer(&bRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufY := [8]int32{}
			bufCb := [8]int32{}
			bufCr := [8]int32{}
			bufR := [8]int32{}
			bufG := [8]int32{}
			bufB := [8]int32{}
			copy(bufY[:], yRow[i:i+remaining])
			copy(bufCb[:], cbRow[i:i+remaining])
			copy(bufCr[:], crRow[i:i+remaining])
			vy := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bufY[0])))
			vcb := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bufCb[0])))
			vcr := archsimd.LoadInt32x8((*[8]int32)(unsafe.Pointer(&bufCr[0])))
			cbPlusCr := vcb.Add(vcr)
			shift := cbPlusCr.ShiftAllRight(uint64(2))
			vg := vy.Sub(shift)
			vr := vcr.Add(vg)
			vb := vcb.Add(vg)
			vr.Store((*[8]int32)(unsafe.Pointer(&bufR[0])))
			vg.Store((*[8]int32)(unsafe.Pointer(&bufG[0])))
			vb.Store((*[8]int32)(unsafe.Pointer(&bufB[0])))
			copy(rRow[i:i+remaining], bufR[:remaining])
			copy(gRow[i:i+remaining], bufG[:remaining])
			copy(bRow[i:i+remaining], bufB[:remaining])
		}
	}
}

func BaseInverseRCT_avx2_Int64(y *Image[int64], cb *Image[int64], cr *Image[int64], outR *Image[int64], outG *Image[int64], outB *Image[int64]) {
	if y == nil || cb == nil || cr == nil || outR == nil || outG == nil || outB == nil {
		return
	}
	if y.data == nil || cb.data == nil || cr.data == nil || outR.data == nil || outG.data == nil || outB.data == nil {
		return
	}
	lanes := 4
	height := y.height
	width := y.width
	for row := range height {
		yRow := y.Row(row)
		cbRow := cb.Row(row)
		crRow := cr.Row(row)
		rRow := outR.Row(row)
		gRow := outG.Row(row)
		bRow := outB.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vy := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&yRow[i])))
			vcb := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&cbRow[i])))
			vcr := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&crRow[i])))
			cbPlusCr := vcb.Add(vcr)
			shift := cbPlusCr.ShiftAllRight(uint64(2))
			vg := vy.Sub(shift)
			vr := vcr.Add(vg)
			vb := vcb.Add(vg)
			vr.Store((*[4]int64)(unsafe.Pointer(&rRow[i])))
			vg.Store((*[4]int64)(unsafe.Pointer(&gRow[i])))
			vb.Store((*[4]int64)(unsafe.Pointer(&bRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufY := [4]int64{}
			bufCb := [4]int64{}
			bufCr := [4]int64{}
			bufR := [4]int64{}
			bufG := [4]int64{}
			bufB := [4]int64{}
			copy(bufY[:], yRow[i:i+remaining])
			copy(bufCb[:], cbRow[i:i+remaining])
			copy(bufCr[:], crRow[i:i+remaining])
			vy := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bufY[0])))
			vcb := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bufCb[0])))
			vcr := archsimd.LoadInt64x4((*[4]int64)(unsafe.Pointer(&bufCr[0])))
			cbPlusCr := vcb.Add(vcr)
			shift := cbPlusCr.ShiftAllRight(uint64(2))
			vg := vy.Sub(shift)
			vr := vcr.Add(vg)
			vb := vcb.Add(vg)
			vr.Store((*[4]int64)(unsafe.Pointer(&bufR[0])))
			vg.Store((*[4]int64)(unsafe.Pointer(&bufG[0])))
			vb.Store((*[4]int64)(unsafe.Pointer(&bufB[0])))
			copy(rRow[i:i+remaining], bufR[:remaining])
			copy(gRow[i:i+remaining], bufG[:remaining])
			copy(bRow[i:i+remaining], bufB[:remaining])
		}
	}
}

func BaseForwardICT_avx2_Float16(r *Image[hwy.Float16], g *Image[hwy.Float16], b *Image[hwy.Float16], outY *Image[hwy.Float16], outCb *Image[hwy.Float16], outCr *Image[hwy.Float16]) {
	if r == nil || g == nil || b == nil || outY == nil || outCb == nil || outCr == nil {
		return
	}
	if r.data == nil || g.data == nil || b.data == nil || outY.data == nil || outCb.data == nil || outCr.data == nil {
		return
	}
	rToY, gToY, bToY, rToCb, gToCb, bToCb, rToCr, gToCr, bToCr, _, _, _, _ := ictCoeffs[hwy.Float16]()
	rToYVec := asm.BroadcastFloat16x8AVX2(uint16(rToY))
	gToYVec := asm.BroadcastFloat16x8AVX2(uint16(gToY))
	bToYVec := asm.BroadcastFloat16x8AVX2(uint16(bToY))
	rToCbVec := asm.BroadcastFloat16x8AVX2(uint16(rToCb))
	gToCbVec := asm.BroadcastFloat16x8AVX2(uint16(gToCb))
	bToCbVec := asm.BroadcastFloat16x8AVX2(uint16(bToCb))
	rToCrVec := asm.BroadcastFloat16x8AVX2(uint16(rToCr))
	gToCrVec := asm.BroadcastFloat16x8AVX2(uint16(gToCr))
	bToCrVec := asm.BroadcastFloat16x8AVX2(uint16(bToCr))
	lanes := 8
	height := r.height
	width := r.width
	for row := range height {
		rRow := r.Row(row)
		gRow := g.Row(row)
		bRow := b.Row(row)
		yRow := outY.Row(row)
		cbRow := outCb.Row(row)
		crRow := outCr.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vr := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&rRow[i:][0]))
			vg := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&gRow[i:][0]))
			vb := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bRow[i:][0]))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.StorePtr(unsafe.Pointer(&yRow[i:][0]))
			vcb.StorePtr(unsafe.Pointer(&cbRow[i:][0]))
			vcr.StorePtr(unsafe.Pointer(&crRow[i:][0]))
		}
		if remaining := width - i; remaining > 0 {
			bufR := [8]hwy.Float16{}
			bufG := [8]hwy.Float16{}
			bufB := [8]hwy.Float16{}
			bufY := [8]hwy.Float16{}
			bufCb := [8]hwy.Float16{}
			bufCr := [8]hwy.Float16{}
			copy(bufR[:], rRow[i:i+remaining])
			copy(bufG[:], gRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			vr := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bufR[0]))
			vg := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bufG[0]))
			vb := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bufB[0]))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.StorePtr(unsafe.Pointer(&bufY[0]))
			vcb.StorePtr(unsafe.Pointer(&bufCb[0]))
			vcr.StorePtr(unsafe.Pointer(&bufCr[0]))
			copy(yRow[i:i+remaining], bufY[:remaining])
			copy(cbRow[i:i+remaining], bufCb[:remaining])
			copy(crRow[i:i+remaining], bufCr[:remaining])
		}
	}
}

func BaseForwardICT_avx2_BFloat16(r *Image[hwy.BFloat16], g *Image[hwy.BFloat16], b *Image[hwy.BFloat16], outY *Image[hwy.BFloat16], outCb *Image[hwy.BFloat16], outCr *Image[hwy.BFloat16]) {
	if r == nil || g == nil || b == nil || outY == nil || outCb == nil || outCr == nil {
		return
	}
	if r.data == nil || g.data == nil || b.data == nil || outY.data == nil || outCb.data == nil || outCr.data == nil {
		return
	}
	rToY, gToY, bToY, rToCb, gToCb, bToCb, rToCr, gToCr, bToCr, _, _, _, _ := ictCoeffs[hwy.BFloat16]()
	rToYVec := asm.BroadcastBFloat16x8AVX2(uint16(rToY))
	gToYVec := asm.BroadcastBFloat16x8AVX2(uint16(gToY))
	bToYVec := asm.BroadcastBFloat16x8AVX2(uint16(bToY))
	rToCbVec := asm.BroadcastBFloat16x8AVX2(uint16(rToCb))
	gToCbVec := asm.BroadcastBFloat16x8AVX2(uint16(gToCb))
	bToCbVec := asm.BroadcastBFloat16x8AVX2(uint16(bToCb))
	rToCrVec := asm.BroadcastBFloat16x8AVX2(uint16(rToCr))
	gToCrVec := asm.BroadcastBFloat16x8AVX2(uint16(gToCr))
	bToCrVec := asm.BroadcastBFloat16x8AVX2(uint16(bToCr))
	lanes := 8
	height := r.height
	width := r.width
	for row := range height {
		rRow := r.Row(row)
		gRow := g.Row(row)
		bRow := b.Row(row)
		yRow := outY.Row(row)
		cbRow := outCb.Row(row)
		crRow := outCr.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vr := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&rRow[i:][0]))
			vg := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&gRow[i:][0]))
			vb := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bRow[i:][0]))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.StorePtr(unsafe.Pointer(&yRow[i:][0]))
			vcb.StorePtr(unsafe.Pointer(&cbRow[i:][0]))
			vcr.StorePtr(unsafe.Pointer(&crRow[i:][0]))
		}
		if remaining := width - i; remaining > 0 {
			bufR := [8]hwy.BFloat16{}
			bufG := [8]hwy.BFloat16{}
			bufB := [8]hwy.BFloat16{}
			bufY := [8]hwy.BFloat16{}
			bufCb := [8]hwy.BFloat16{}
			bufCr := [8]hwy.BFloat16{}
			copy(bufR[:], rRow[i:i+remaining])
			copy(bufG[:], gRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			vr := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bufR[0]))
			vg := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bufG[0]))
			vb := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bufB[0]))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.StorePtr(unsafe.Pointer(&bufY[0]))
			vcb.StorePtr(unsafe.Pointer(&bufCb[0]))
			vcr.StorePtr(unsafe.Pointer(&bufCr[0]))
			copy(yRow[i:i+remaining], bufY[:remaining])
			copy(cbRow[i:i+remaining], bufCb[:remaining])
			copy(crRow[i:i+remaining], bufCr[:remaining])
		}
	}
}

func BaseForwardICT_avx2(r *Image[float32], g *Image[float32], b *Image[float32], outY *Image[float32], outCb *Image[float32], outCr *Image[float32]) {
	if r == nil || g == nil || b == nil || outY == nil || outCb == nil || outCr == nil {
		return
	}
	if r.data == nil || g.data == nil || b.data == nil || outY.data == nil || outCb.data == nil || outCr.data == nil {
		return
	}
	rToY, gToY, bToY, rToCb, gToCb, bToCb, rToCr, gToCr, bToCr, _, _, _, _ := ictCoeffs[float32]()
	rToYVec := archsimd.BroadcastFloat32x8(rToY)
	gToYVec := archsimd.BroadcastFloat32x8(gToY)
	bToYVec := archsimd.BroadcastFloat32x8(bToY)
	rToCbVec := archsimd.BroadcastFloat32x8(rToCb)
	gToCbVec := archsimd.BroadcastFloat32x8(gToCb)
	bToCbVec := archsimd.BroadcastFloat32x8(bToCb)
	rToCrVec := archsimd.BroadcastFloat32x8(rToCr)
	gToCrVec := archsimd.BroadcastFloat32x8(gToCr)
	bToCrVec := archsimd.BroadcastFloat32x8(bToCr)
	lanes := 8
	height := r.height
	width := r.width
	for row := range height {
		rRow := r.Row(row)
		gRow := g.Row(row)
		bRow := b.Row(row)
		yRow := outY.Row(row)
		cbRow := outCb.Row(row)
		crRow := outCr.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vr := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&rRow[i])))
			vg := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&gRow[i])))
			vb := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bRow[i])))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.Store((*[8]float32)(unsafe.Pointer(&yRow[i])))
			vcb.Store((*[8]float32)(unsafe.Pointer(&cbRow[i])))
			vcr.Store((*[8]float32)(unsafe.Pointer(&crRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufR := [8]float32{}
			bufG := [8]float32{}
			bufB := [8]float32{}
			bufY := [8]float32{}
			bufCb := [8]float32{}
			bufCr := [8]float32{}
			copy(bufR[:], rRow[i:i+remaining])
			copy(bufG[:], gRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			vr := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bufR[0])))
			vg := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bufG[0])))
			vb := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bufB[0])))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.Store((*[8]float32)(unsafe.Pointer(&bufY[0])))
			vcb.Store((*[8]float32)(unsafe.Pointer(&bufCb[0])))
			vcr.Store((*[8]float32)(unsafe.Pointer(&bufCr[0])))
			copy(yRow[i:i+remaining], bufY[:remaining])
			copy(cbRow[i:i+remaining], bufCb[:remaining])
			copy(crRow[i:i+remaining], bufCr[:remaining])
		}
	}
}

func BaseForwardICT_avx2_Float64(r *Image[float64], g *Image[float64], b *Image[float64], outY *Image[float64], outCb *Image[float64], outCr *Image[float64]) {
	if r == nil || g == nil || b == nil || outY == nil || outCb == nil || outCr == nil {
		return
	}
	if r.data == nil || g.data == nil || b.data == nil || outY.data == nil || outCb.data == nil || outCr.data == nil {
		return
	}
	rToY, gToY, bToY, rToCb, gToCb, bToCb, rToCr, gToCr, bToCr, _, _, _, _ := ictCoeffs[float64]()
	rToYVec := archsimd.BroadcastFloat64x4(rToY)
	gToYVec := archsimd.BroadcastFloat64x4(gToY)
	bToYVec := archsimd.BroadcastFloat64x4(bToY)
	rToCbVec := archsimd.BroadcastFloat64x4(rToCb)
	gToCbVec := archsimd.BroadcastFloat64x4(gToCb)
	bToCbVec := archsimd.BroadcastFloat64x4(bToCb)
	rToCrVec := archsimd.BroadcastFloat64x4(rToCr)
	gToCrVec := archsimd.BroadcastFloat64x4(gToCr)
	bToCrVec := archsimd.BroadcastFloat64x4(bToCr)
	lanes := 4
	height := r.height
	width := r.width
	for row := range height {
		rRow := r.Row(row)
		gRow := g.Row(row)
		bRow := b.Row(row)
		yRow := outY.Row(row)
		cbRow := outCb.Row(row)
		crRow := outCr.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vr := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&rRow[i])))
			vg := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&gRow[i])))
			vb := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bRow[i])))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.Store((*[4]float64)(unsafe.Pointer(&yRow[i])))
			vcb.Store((*[4]float64)(unsafe.Pointer(&cbRow[i])))
			vcr.Store((*[4]float64)(unsafe.Pointer(&crRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufR := [4]float64{}
			bufG := [4]float64{}
			bufB := [4]float64{}
			bufY := [4]float64{}
			bufCb := [4]float64{}
			bufCr := [4]float64{}
			copy(bufR[:], rRow[i:i+remaining])
			copy(bufG[:], gRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			vr := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bufR[0])))
			vg := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bufG[0])))
			vb := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bufB[0])))
			vy := vr.MulAdd(rToYVec, vg.MulAdd(gToYVec, vb.Mul(bToYVec)))
			vcb := vr.MulAdd(rToCbVec, vg.MulAdd(gToCbVec, vb.Mul(bToCbVec)))
			vcr := vr.MulAdd(rToCrVec, vg.MulAdd(gToCrVec, vb.Mul(bToCrVec)))
			vy.Store((*[4]float64)(unsafe.Pointer(&bufY[0])))
			vcb.Store((*[4]float64)(unsafe.Pointer(&bufCb[0])))
			vcr.Store((*[4]float64)(unsafe.Pointer(&bufCr[0])))
			copy(yRow[i:i+remaining], bufY[:remaining])
			copy(cbRow[i:i+remaining], bufCb[:remaining])
			copy(crRow[i:i+remaining], bufCr[:remaining])
		}
	}
}

func BaseInverseICT_avx2_Float16(y *Image[hwy.Float16], cb *Image[hwy.Float16], cr *Image[hwy.Float16], outR *Image[hwy.Float16], outG *Image[hwy.Float16], outB *Image[hwy.Float16]) {
	if y == nil || cb == nil || cr == nil || outR == nil || outG == nil || outB == nil {
		return
	}
	if y.data == nil || cb.data == nil || cr.data == nil || outR.data == nil || outG.data == nil || outB.data == nil {
		return
	}
	_, _, _, _, _, _, _, _, _, crToR, cbToG, crToG, cbToB := ictCoeffs[hwy.Float16]()
	crToRVec := asm.BroadcastFloat16x8AVX2(uint16(crToR))
	cbToGVec := asm.BroadcastFloat16x8AVX2(uint16(cbToG))
	crToGVec := asm.BroadcastFloat16x8AVX2(uint16(crToG))
	cbToBVec := asm.BroadcastFloat16x8AVX2(uint16(cbToB))
	lanes := 8
	height := y.height
	width := y.width
	for row := range height {
		yRow := y.Row(row)
		cbRow := cb.Row(row)
		crRow := cr.Row(row)
		rRow := outR.Row(row)
		gRow := outG.Row(row)
		bRow := outB.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vy := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&yRow[i:][0]))
			vcb := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&cbRow[i:][0]))
			vcr := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&crRow[i:][0]))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.StorePtr(unsafe.Pointer(&rRow[i:][0]))
			vg.StorePtr(unsafe.Pointer(&gRow[i:][0]))
			vb.StorePtr(unsafe.Pointer(&bRow[i:][0]))
		}
		if remaining := width - i; remaining > 0 {
			bufY := [8]hwy.Float16{}
			bufCb := [8]hwy.Float16{}
			bufCr := [8]hwy.Float16{}
			bufR := [8]hwy.Float16{}
			bufG := [8]hwy.Float16{}
			bufB := [8]hwy.Float16{}
			copy(bufY[:], yRow[i:i+remaining])
			copy(bufCb[:], cbRow[i:i+remaining])
			copy(bufCr[:], crRow[i:i+remaining])
			vy := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bufY[0]))
			vcb := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bufCb[0]))
			vcr := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&bufCr[0]))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.StorePtr(unsafe.Pointer(&bufR[0]))
			vg.StorePtr(unsafe.Pointer(&bufG[0]))
			vb.StorePtr(unsafe.Pointer(&bufB[0]))
			copy(rRow[i:i+remaining], bufR[:remaining])
			copy(gRow[i:i+remaining], bufG[:remaining])
			copy(bRow[i:i+remaining], bufB[:remaining])
		}
	}
}

func BaseInverseICT_avx2_BFloat16(y *Image[hwy.BFloat16], cb *Image[hwy.BFloat16], cr *Image[hwy.BFloat16], outR *Image[hwy.BFloat16], outG *Image[hwy.BFloat16], outB *Image[hwy.BFloat16]) {
	if y == nil || cb == nil || cr == nil || outR == nil || outG == nil || outB == nil {
		return
	}
	if y.data == nil || cb.data == nil || cr.data == nil || outR.data == nil || outG.data == nil || outB.data == nil {
		return
	}
	_, _, _, _, _, _, _, _, _, crToR, cbToG, crToG, cbToB := ictCoeffs[hwy.BFloat16]()
	crToRVec := asm.BroadcastBFloat16x8AVX2(uint16(crToR))
	cbToGVec := asm.BroadcastBFloat16x8AVX2(uint16(cbToG))
	crToGVec := asm.BroadcastBFloat16x8AVX2(uint16(crToG))
	cbToBVec := asm.BroadcastBFloat16x8AVX2(uint16(cbToB))
	lanes := 8
	height := y.height
	width := y.width
	for row := range height {
		yRow := y.Row(row)
		cbRow := cb.Row(row)
		crRow := cr.Row(row)
		rRow := outR.Row(row)
		gRow := outG.Row(row)
		bRow := outB.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vy := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&yRow[i:][0]))
			vcb := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&cbRow[i:][0]))
			vcr := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&crRow[i:][0]))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.StorePtr(unsafe.Pointer(&rRow[i:][0]))
			vg.StorePtr(unsafe.Pointer(&gRow[i:][0]))
			vb.StorePtr(unsafe.Pointer(&bRow[i:][0]))
		}
		if remaining := width - i; remaining > 0 {
			bufY := [8]hwy.BFloat16{}
			bufCb := [8]hwy.BFloat16{}
			bufCr := [8]hwy.BFloat16{}
			bufR := [8]hwy.BFloat16{}
			bufG := [8]hwy.BFloat16{}
			bufB := [8]hwy.BFloat16{}
			copy(bufY[:], yRow[i:i+remaining])
			copy(bufCb[:], cbRow[i:i+remaining])
			copy(bufCr[:], crRow[i:i+remaining])
			vy := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bufY[0]))
			vcb := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bufCb[0]))
			vcr := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&bufCr[0]))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.StorePtr(unsafe.Pointer(&bufR[0]))
			vg.StorePtr(unsafe.Pointer(&bufG[0]))
			vb.StorePtr(unsafe.Pointer(&bufB[0]))
			copy(rRow[i:i+remaining], bufR[:remaining])
			copy(gRow[i:i+remaining], bufG[:remaining])
			copy(bRow[i:i+remaining], bufB[:remaining])
		}
	}
}

func BaseInverseICT_avx2(y *Image[float32], cb *Image[float32], cr *Image[float32], outR *Image[float32], outG *Image[float32], outB *Image[float32]) {
	if y == nil || cb == nil || cr == nil || outR == nil || outG == nil || outB == nil {
		return
	}
	if y.data == nil || cb.data == nil || cr.data == nil || outR.data == nil || outG.data == nil || outB.data == nil {
		return
	}
	_, _, _, _, _, _, _, _, _, crToR, cbToG, crToG, cbToB := ictCoeffs[float32]()
	crToRVec := archsimd.BroadcastFloat32x8(crToR)
	cbToGVec := archsimd.BroadcastFloat32x8(cbToG)
	crToGVec := archsimd.BroadcastFloat32x8(crToG)
	cbToBVec := archsimd.BroadcastFloat32x8(cbToB)
	lanes := 8
	height := y.height
	width := y.width
	for row := range height {
		yRow := y.Row(row)
		cbRow := cb.Row(row)
		crRow := cr.Row(row)
		rRow := outR.Row(row)
		gRow := outG.Row(row)
		bRow := outB.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vy := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&yRow[i])))
			vcb := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&cbRow[i])))
			vcr := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&crRow[i])))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.Store((*[8]float32)(unsafe.Pointer(&rRow[i])))
			vg.Store((*[8]float32)(unsafe.Pointer(&gRow[i])))
			vb.Store((*[8]float32)(unsafe.Pointer(&bRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufY := [8]float32{}
			bufCb := [8]float32{}
			bufCr := [8]float32{}
			bufR := [8]float32{}
			bufG := [8]float32{}
			bufB := [8]float32{}
			copy(bufY[:], yRow[i:i+remaining])
			copy(bufCb[:], cbRow[i:i+remaining])
			copy(bufCr[:], crRow[i:i+remaining])
			vy := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bufY[0])))
			vcb := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bufCb[0])))
			vcr := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&bufCr[0])))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.Store((*[8]float32)(unsafe.Pointer(&bufR[0])))
			vg.Store((*[8]float32)(unsafe.Pointer(&bufG[0])))
			vb.Store((*[8]float32)(unsafe.Pointer(&bufB[0])))
			copy(rRow[i:i+remaining], bufR[:remaining])
			copy(gRow[i:i+remaining], bufG[:remaining])
			copy(bRow[i:i+remaining], bufB[:remaining])
		}
	}
}

func BaseInverseICT_avx2_Float64(y *Image[float64], cb *Image[float64], cr *Image[float64], outR *Image[float64], outG *Image[float64], outB *Image[float64]) {
	if y == nil || cb == nil || cr == nil || outR == nil || outG == nil || outB == nil {
		return
	}
	if y.data == nil || cb.data == nil || cr.data == nil || outR.data == nil || outG.data == nil || outB.data == nil {
		return
	}
	_, _, _, _, _, _, _, _, _, crToR, cbToG, crToG, cbToB := ictCoeffs[float64]()
	crToRVec := archsimd.BroadcastFloat64x4(crToR)
	cbToGVec := archsimd.BroadcastFloat64x4(cbToG)
	crToGVec := archsimd.BroadcastFloat64x4(crToG)
	cbToBVec := archsimd.BroadcastFloat64x4(cbToB)
	lanes := 4
	height := y.height
	width := y.width
	for row := range height {
		yRow := y.Row(row)
		cbRow := cb.Row(row)
		crRow := cr.Row(row)
		rRow := outR.Row(row)
		gRow := outG.Row(row)
		bRow := outB.Row(row)
		i := 0
		for ; i+lanes <= width; i += lanes {
			vy := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&yRow[i])))
			vcb := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&cbRow[i])))
			vcr := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&crRow[i])))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.Store((*[4]float64)(unsafe.Pointer(&rRow[i])))
			vg.Store((*[4]float64)(unsafe.Pointer(&gRow[i])))
			vb.Store((*[4]float64)(unsafe.Pointer(&bRow[i])))
		}
		if remaining := width - i; remaining > 0 {
			bufY := [4]float64{}
			bufCb := [4]float64{}
			bufCr := [4]float64{}
			bufR := [4]float64{}
			bufG := [4]float64{}
			bufB := [4]float64{}
			copy(bufY[:], yRow[i:i+remaining])
			copy(bufCb[:], cbRow[i:i+remaining])
			copy(bufCr[:], crRow[i:i+remaining])
			vy := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bufY[0])))
			vcb := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bufCb[0])))
			vcr := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&bufCr[0])))
			vr := vcr.MulAdd(crToRVec, vy)
			vg := vcb.MulAdd(cbToGVec, vcr.MulAdd(crToGVec, vy))
			vb := vcb.MulAdd(cbToBVec, vy)
			vr.Store((*[4]float64)(unsafe.Pointer(&bufR[0])))
			vg.Store((*[4]float64)(unsafe.Pointer(&bufG[0])))
			vb.Store((*[4]float64)(unsafe.Pointer(&bufB[0])))
			copy(rRow[i:i+remaining], bufR[:remaining])
			copy(gRow[i:i+remaining], bufG[:remaining])
			copy(bRow[i:i+remaining], bufB[:remaining])
		}
	}
}
