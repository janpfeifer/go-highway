// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package image

import (
	stdmath "math"
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

func BaseBrightnessContrast_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], scale hwy.Float16, offset hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := asm.BroadcastFloat16x16AVX512(uint16(scale))
	offsetVec := asm.BroadcastFloat16x16AVX512(uint16(offset))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseBrightnessContrast_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], scale hwy.BFloat16, offset hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := asm.BroadcastBFloat16x16AVX512(uint16(scale))
	offsetVec := asm.BroadcastBFloat16x16AVX512(uint16(offset))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseBrightnessContrast_avx512(img *Image[float32], out *Image[float32], scale float32, offset float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := archsimd.BroadcastFloat32x16(scale)
	offsetVec := archsimd.BroadcastFloat32x16(offset)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseBrightnessContrast_avx512_Float64(img *Image[float64], out *Image[float64], scale float64, offset float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := archsimd.BroadcastFloat64x8(scale)
	offsetVec := archsimd.BroadcastFloat64x8(offset)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := v.MulAdd(scaleVec, offsetVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseClampImage_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], minVal hwy.Float16, maxVal hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	minVec := asm.BroadcastFloat16x16AVX512(uint16(minVal))
	maxVec := asm.BroadcastFloat16x16AVX512(uint16(maxVal))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseClampImage_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], minVal hwy.BFloat16, maxVal hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	minVec := asm.BroadcastBFloat16x16AVX512(uint16(minVal))
	maxVec := asm.BroadcastBFloat16x16AVX512(uint16(maxVal))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseClampImage_avx512(img *Image[float32], out *Image[float32], minVal float32, maxVal float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	minVec := archsimd.BroadcastFloat32x16(minVal)
	maxVec := archsimd.BroadcastFloat32x16(maxVal)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseClampImage_avx512_Float64(img *Image[float64], out *Image[float64], minVal float64, maxVal float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	minVec := archsimd.BroadcastFloat64x8(minVal)
	maxVec := archsimd.BroadcastFloat64x8(maxVal)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := v.Min(maxVec).Max(minVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseThreshold_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], threshold hwy.Float16, below hwy.Float16, above hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	threshVec := asm.BroadcastFloat16x16AVX512(uint16(threshold))
	belowVec := asm.BroadcastFloat16x16AVX512(uint16(below))
	aboveVec := asm.BroadcastFloat16x16AVX512(uint16(above))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			mask := v.GreaterEqual(threshVec)
			result := aboveVec.Merge(belowVec, mask)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			mask := v.GreaterEqual(threshVec)
			result := aboveVec.Merge(belowVec, mask)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseThreshold_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], threshold hwy.BFloat16, below hwy.BFloat16, above hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	threshVec := asm.BroadcastBFloat16x16AVX512(uint16(threshold))
	belowVec := asm.BroadcastBFloat16x16AVX512(uint16(below))
	aboveVec := asm.BroadcastBFloat16x16AVX512(uint16(above))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			mask := v.GreaterEqual(threshVec)
			result := aboveVec.Merge(belowVec, mask)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			mask := v.GreaterEqual(threshVec)
			result := aboveVec.Merge(belowVec, mask)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseThreshold_avx512(img *Image[float32], out *Image[float32], threshold float32, below float32, above float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	threshVec := archsimd.BroadcastFloat32x16(threshold)
	belowVec := archsimd.BroadcastFloat32x16(below)
	aboveVec := archsimd.BroadcastFloat32x16(above)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			mask := v.GreaterEqual(threshVec)
			result := hwy.IfThenElse_AVX512_F32x16(mask, aboveVec, belowVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			mask := v.GreaterEqual(threshVec)
			result := hwy.IfThenElse_AVX512_F32x16(mask, aboveVec, belowVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseThreshold_avx512_Float64(img *Image[float64], out *Image[float64], threshold float64, below float64, above float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	threshVec := archsimd.BroadcastFloat64x8(threshold)
	belowVec := archsimd.BroadcastFloat64x8(below)
	aboveVec := archsimd.BroadcastFloat64x8(above)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			mask := v.GreaterEqual(threshVec)
			result := hwy.IfThenElse_AVX512_F64x8(mask, aboveVec, belowVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			mask := v.GreaterEqual(threshVec)
			result := hwy.IfThenElse_AVX512_F64x8(mask, aboveVec, belowVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseInvert_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], maxVal hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	maxVec := asm.BroadcastFloat16x16AVX512(uint16(maxVal))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := maxVec.Sub(v)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := maxVec.Sub(v)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseInvert_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], maxVal hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	maxVec := asm.BroadcastBFloat16x16AVX512(uint16(maxVal))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := maxVec.Sub(v)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := maxVec.Sub(v)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseInvert_avx512(img *Image[float32], out *Image[float32], maxVal float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	maxVec := archsimd.BroadcastFloat32x16(maxVal)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := maxVec.Sub(v)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := maxVec.Sub(v)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseInvert_avx512_Float64(img *Image[float64], out *Image[float64], maxVal float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	maxVec := archsimd.BroadcastFloat64x8(maxVal)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := maxVec.Sub(v)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := maxVec.Sub(v)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseAbs_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16]) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Abs()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Abs()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseAbs_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16]) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Abs()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Abs()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseAbs_avx512(img *Image[float32], out *Image[float32]) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := v.Max(archsimd.BroadcastFloat32x16(0).Sub(v))
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := v.Max(archsimd.BroadcastFloat32x16(0).Sub(v))
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseAbs_avx512_Float64(img *Image[float64], out *Image[float64]) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := v.Max(archsimd.BroadcastFloat64x8(0).Sub(v))
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := v.Max(archsimd.BroadcastFloat64x8(0).Sub(v))
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseScale_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], scale hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := asm.BroadcastFloat16x16AVX512(uint16(scale))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Mul(scaleVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Mul(scaleVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseScale_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], scale hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := asm.BroadcastBFloat16x16AVX512(uint16(scale))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Mul(scaleVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Mul(scaleVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseScale_avx512(img *Image[float32], out *Image[float32], scale float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := archsimd.BroadcastFloat32x16(scale)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := v.Mul(scaleVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := v.Mul(scaleVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseScale_avx512_Float64(img *Image[float64], out *Image[float64], scale float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	scaleVec := archsimd.BroadcastFloat64x8(scale)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := v.Mul(scaleVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := v.Mul(scaleVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseOffset_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], offset hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	offsetVec := asm.BroadcastFloat16x16AVX512(uint16(offset))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Add(offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Add(offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseOffset_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], offset hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	offsetVec := asm.BroadcastBFloat16x16AVX512(uint16(offset))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := v.Add(offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := v.Add(offsetVec)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseOffset_avx512(img *Image[float32], out *Image[float32], offset float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	offsetVec := archsimd.BroadcastFloat32x16(offset)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := v.Add(offsetVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := v.Add(offsetVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseOffset_avx512_Float64(img *Image[float64], out *Image[float64], offset float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	offsetVec := archsimd.BroadcastFloat64x8(offset)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := v.Add(offsetVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := v.Add(offsetVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseGamma_avx512_Float16(img *Image[hwy.Float16], out *Image[hwy.Float16], gamma hwy.Float16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	gammaVec := asm.BroadcastFloat16x16AVX512(uint16(gamma))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := func() asm.Float16x16AVX512 {
				var _powBase, _powExp [16]float32
				v.AsFloat32x16().StoreSlice(_powBase[:])
				gammaVec.AsFloat32x16().StoreSlice(_powExp[:])
				for _powI := range _powBase {
					_powBase[_powI] = float32(stdmath.Pow(float64(_powBase[_powI]), float64(_powExp[_powI])))
				}
				return asm.Float16x16AVX512FromFloat32x16(archsimd.LoadFloat32x16Slice(_powBase[:]))
			}()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.Float16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := func() asm.Float16x16AVX512 {
				var _powBase, _powExp [16]float32
				v.AsFloat32x16().StoreSlice(_powBase[:])
				gammaVec.AsFloat32x16().StoreSlice(_powExp[:])
				for _powI := range _powBase {
					_powBase[_powI] = float32(stdmath.Pow(float64(_powBase[_powI]), float64(_powExp[_powI])))
				}
				return asm.Float16x16AVX512FromFloat32x16(archsimd.LoadFloat32x16Slice(_powBase[:]))
			}()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseGamma_avx512_BFloat16(img *Image[hwy.BFloat16], out *Image[hwy.BFloat16], gamma hwy.BFloat16) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	gammaVec := asm.BroadcastBFloat16x16AVX512(uint16(gamma))
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(inRow[i:]))), len(inRow[i:])))
			result := func() asm.BFloat16x16AVX512 {
				var _powBase, _powExp [16]float32
				v.AsFloat32x16().StoreSlice(_powBase[:])
				gammaVec.AsFloat32x16().StoreSlice(_powExp[:])
				for _powI := range _powBase {
					_powBase[_powI] = float32(stdmath.Pow(float64(_powBase[_powI]), float64(_powExp[_powI])))
				}
				return asm.BFloat16x16AVX512FromFloat32x16(archsimd.LoadFloat32x16Slice(_powBase[:]))
			}()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]hwy.BFloat16{}
			copy(buf[:], inRow[i:i+remaining])
			v := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			result := func() asm.BFloat16x16AVX512 {
				var _powBase, _powExp [16]float32
				v.AsFloat32x16().StoreSlice(_powBase[:])
				gammaVec.AsFloat32x16().StoreSlice(_powExp[:])
				for _powI := range _powBase {
					_powBase[_powI] = float32(stdmath.Pow(float64(_powBase[_powI]), float64(_powExp[_powI])))
				}
				return asm.BFloat16x16AVX512FromFloat32x16(archsimd.LoadFloat32x16Slice(_powBase[:]))
			}()
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(buf[:]))), len(buf[:])))
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseGamma_avx512(img *Image[float32], out *Image[float32], gamma float32) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	gammaVec := archsimd.BroadcastFloat32x16(gamma)
	lanes := 16
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat32x16Slice(inRow[i:])
			result := math.BasePowVec_avx512(v, gammaVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [16]float32{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat32x16Slice(buf[:])
			result := math.BasePowVec_avx512(v, gammaVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseGamma_avx512_Float64(img *Image[float64], out *Image[float64], gamma float64) {
	if img == nil || out == nil || img.data == nil || out.data == nil {
		return
	}
	gammaVec := archsimd.BroadcastFloat64x8(gamma)
	lanes := 8
	for y := 0; y < img.height; y++ {
		inRow := img.Row(y)
		outRow := out.Row(y)
		width := img.width
		i := 0
		for ; i+lanes <= width; i += lanes {
			v := archsimd.LoadFloat64x8Slice(inRow[i:])
			result := math.BasePowVec_avx512_Float64(v, gammaVec)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			buf := [8]float64{}
			copy(buf[:], inRow[i:i+remaining])
			v := archsimd.LoadFloat64x8Slice(buf[:])
			result := math.BasePowVec_avx512_Float64(v, gammaVec)
			result.StoreSlice(buf[:])
			copy(outRow[i:i+remaining], buf[:remaining])
		}
	}
}

func BaseMinImage_avx512_Float16(a *Image[hwy.Float16], b *Image[hwy.Float16], out *Image[hwy.Float16]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 16
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(aRow[i:]))), len(aRow[i:])))
			vb := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bRow[i:]))), len(bRow[i:])))
			result := va.Min(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			bufA := [16]hwy.Float16{}
			bufB := [16]hwy.Float16{}
			bufOut := [16]hwy.Float16{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufA[:]))), len(bufA[:])))
			vb := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufB[:]))), len(bufB[:])))
			result := va.Min(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufOut[:]))), len(bufOut[:])))
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMinImage_avx512_BFloat16(a *Image[hwy.BFloat16], b *Image[hwy.BFloat16], out *Image[hwy.BFloat16]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 16
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(aRow[i:]))), len(aRow[i:])))
			vb := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bRow[i:]))), len(bRow[i:])))
			result := va.Min(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			bufA := [16]hwy.BFloat16{}
			bufB := [16]hwy.BFloat16{}
			bufOut := [16]hwy.BFloat16{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufA[:]))), len(bufA[:])))
			vb := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufB[:]))), len(bufB[:])))
			result := va.Min(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufOut[:]))), len(bufOut[:])))
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMinImage_avx512(a *Image[float32], b *Image[float32], out *Image[float32]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 16
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := archsimd.LoadFloat32x16Slice(aRow[i:])
			vb := archsimd.LoadFloat32x16Slice(bRow[i:])
			result := va.Min(vb)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			bufA := [16]float32{}
			bufB := [16]float32{}
			bufOut := [16]float32{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := archsimd.LoadFloat32x16Slice(bufA[:])
			vb := archsimd.LoadFloat32x16Slice(bufB[:])
			result := va.Min(vb)
			result.StoreSlice(bufOut[:])
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMinImage_avx512_Float64(a *Image[float64], b *Image[float64], out *Image[float64]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 8
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := archsimd.LoadFloat64x8Slice(aRow[i:])
			vb := archsimd.LoadFloat64x8Slice(bRow[i:])
			result := va.Min(vb)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			bufA := [8]float64{}
			bufB := [8]float64{}
			bufOut := [8]float64{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := archsimd.LoadFloat64x8Slice(bufA[:])
			vb := archsimd.LoadFloat64x8Slice(bufB[:])
			result := va.Min(vb)
			result.StoreSlice(bufOut[:])
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMaxImage_avx512_Float16(a *Image[hwy.Float16], b *Image[hwy.Float16], out *Image[hwy.Float16]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 16
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(aRow[i:]))), len(aRow[i:])))
			vb := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bRow[i:]))), len(bRow[i:])))
			result := va.Max(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			bufA := [16]hwy.Float16{}
			bufB := [16]hwy.Float16{}
			bufOut := [16]hwy.Float16{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufA[:]))), len(bufA[:])))
			vb := asm.LoadFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufB[:]))), len(bufB[:])))
			result := va.Max(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufOut[:]))), len(bufOut[:])))
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMaxImage_avx512_BFloat16(a *Image[hwy.BFloat16], b *Image[hwy.BFloat16], out *Image[hwy.BFloat16]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 16
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(aRow[i:]))), len(aRow[i:])))
			vb := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bRow[i:]))), len(bRow[i:])))
			result := va.Max(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(outRow[i:]))), len(outRow[i:])))
		}
		if remaining := width - i; remaining > 0 {
			bufA := [16]hwy.BFloat16{}
			bufB := [16]hwy.BFloat16{}
			bufOut := [16]hwy.BFloat16{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufA[:]))), len(bufA[:])))
			vb := asm.LoadBFloat16x16AVX512Slice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufB[:]))), len(bufB[:])))
			result := va.Max(vb)
			result.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(bufOut[:]))), len(bufOut[:])))
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMaxImage_avx512(a *Image[float32], b *Image[float32], out *Image[float32]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 16
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := archsimd.LoadFloat32x16Slice(aRow[i:])
			vb := archsimd.LoadFloat32x16Slice(bRow[i:])
			result := va.Max(vb)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			bufA := [16]float32{}
			bufB := [16]float32{}
			bufOut := [16]float32{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := archsimd.LoadFloat32x16Slice(bufA[:])
			vb := archsimd.LoadFloat32x16Slice(bufB[:])
			result := va.Max(vb)
			result.StoreSlice(bufOut[:])
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}

func BaseMaxImage_avx512_Float64(a *Image[float64], b *Image[float64], out *Image[float64]) {
	if a == nil || b == nil || out == nil || a.data == nil || b.data == nil || out.data == nil {
		return
	}
	lanes := 8
	height := min(a.height, b.height)
	for y := range height {
		aRow := a.Row(y)
		bRow := b.Row(y)
		outRow := out.Row(y)
		width := min(a.width, b.width)
		i := 0
		for ; i+lanes <= width; i += lanes {
			va := archsimd.LoadFloat64x8Slice(aRow[i:])
			vb := archsimd.LoadFloat64x8Slice(bRow[i:])
			result := va.Max(vb)
			result.StoreSlice(outRow[i:])
		}
		if remaining := width - i; remaining > 0 {
			bufA := [8]float64{}
			bufB := [8]float64{}
			bufOut := [8]float64{}
			copy(bufA[:], aRow[i:i+remaining])
			copy(bufB[:], bRow[i:i+remaining])
			va := archsimd.LoadFloat64x8Slice(bufA[:])
			vb := archsimd.LoadFloat64x8Slice(bufB[:])
			result := va.Max(vb)
			result.StoreSlice(bufOut[:])
			copy(outRow[i:i+remaining], bufOut[:remaining])
		}
	}
}
