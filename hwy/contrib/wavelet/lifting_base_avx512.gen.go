// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package wavelet

import (
	"simd/archsimd"
	"sync"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
)

// Hoisted constants - lazily initialized on first use to avoid init-time crashes
var (
	BaseLiftUpdate53_AVX512_twoVec_f32         archsimd.Int64x8
	BaseLiftUpdate53_AVX512_twoVec_i32_f32     archsimd.Int32x16
	BaseSynthesize53Core_AVX512_twoVec_f32     archsimd.Int64x8
	BaseSynthesize53Core_AVX512_twoVec_i32_f32 archsimd.Int32x16
	_liftingBaseHoistOnce                      sync.Once
)

func _liftingBaseInitHoistedConstants() {
	_liftingBaseHoistOnce.Do(func() {
		BaseLiftUpdate53_AVX512_twoVec_f32 = archsimd.BroadcastInt64x8(int64(2))
		BaseLiftUpdate53_AVX512_twoVec_i32_f32 = archsimd.BroadcastInt32x16(int32(2))
		BaseSynthesize53Core_AVX512_twoVec_f32 = archsimd.BroadcastInt64x8(int64(2))
		BaseSynthesize53Core_AVX512_twoVec_i32_f32 = archsimd.BroadcastInt32x16(int32(2))
	})
}

func BaseLiftUpdate53_avx512_Int32(target []int32, tLen int, neighbor []int32, nLen int, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	twoVec := BaseLiftUpdate53_AVX512_twoVec_i32_f32
	lanes := 16
	start := 0
	if phase == 0 {
		target[0] -= (neighbor[0] + neighbor[0] + 2) >> 2
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	} else {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	}
	i := start
	for ; i+lanes*3 <= safeEnd; i += lanes * 3 {
		var n1, n2 archsimd.Int32x16
		if phase == 0 {
			n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i-1])))
			n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i])))
		} else {
			n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i])))
			n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+1])))
		}
		sum := n1.Add(n2).Add(twoVec)
		update := sum.ShiftAllRight(uint64(2))
		t := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&target[i])))
		t.Sub(update).Store((*[16]int32)(unsafe.Pointer(&target[i])))
		var n11, n21 archsimd.Int32x16
		if phase == 0 {
			n11 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i-1+16])))
			n21 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+16])))
		} else {
			n11 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+16])))
			n21 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+1+16])))
		}
		sum1 := n11.Add(n21).Add(twoVec)
		update1 := sum1.ShiftAllRight(uint64(2))
		t1 := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&target[i+16])))
		t1.Sub(update1).Store((*[16]int32)(unsafe.Pointer(&target[i+16])))
		var n12, n22 archsimd.Int32x16
		if phase == 0 {
			n12 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i-1+32])))
			n22 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+32])))
		} else {
			n12 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+32])))
			n22 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+1+32])))
		}
		sum2 := n12.Add(n22).Add(twoVec)
		update2 := sum2.ShiftAllRight(uint64(2))
		t2 := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&target[i+32])))
		t2.Sub(update2).Store((*[16]int32)(unsafe.Pointer(&target[i+32])))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i - 1
			n2Idx = i
		} else {
			n1Idx = i
			n2Idx = i + 1
		}
		target[i] -= (neighbor[n1Idx] + neighbor[n2Idx] + 2) >> 2
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i - 1
			n2Idx = i
		} else {
			n1Idx = i
			n2Idx = i + 1
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] -= (neighbor[n1Idx] + neighbor[n2Idx] + 2) >> 2
	}
	_ = lanes
}

func BaseLiftUpdate53_avx512_Int64(target []int64, tLen int, neighbor []int64, nLen int, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	twoVec := BaseLiftUpdate53_AVX512_twoVec_f32
	lanes := 8
	start := 0
	if phase == 0 {
		target[0] -= (neighbor[0] + neighbor[0] + 2) >> 2
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	} else {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	}
	i := start
	for ; i+lanes*3 <= safeEnd; i += lanes * 3 {
		var n1, n2 archsimd.Int64x8
		if phase == 0 {
			n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i-1])))
			n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i])))
		} else {
			n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i])))
			n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+1])))
		}
		sum := n1.Add(n2).Add(twoVec)
		update := sum.ShiftAllRight(uint64(2))
		t := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&target[i])))
		t.Sub(update).Store((*[8]int64)(unsafe.Pointer(&target[i])))
		var n11, n21 archsimd.Int64x8
		if phase == 0 {
			n11 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i-1+8])))
			n21 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+8])))
		} else {
			n11 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+8])))
			n21 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+1+8])))
		}
		sum1 := n11.Add(n21).Add(twoVec)
		update1 := sum1.ShiftAllRight(uint64(2))
		t1 := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&target[i+8])))
		t1.Sub(update1).Store((*[8]int64)(unsafe.Pointer(&target[i+8])))
		var n12, n22 archsimd.Int64x8
		if phase == 0 {
			n12 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i-1+16])))
			n22 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+16])))
		} else {
			n12 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+16])))
			n22 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+1+16])))
		}
		sum2 := n12.Add(n22).Add(twoVec)
		update2 := sum2.ShiftAllRight(uint64(2))
		t2 := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&target[i+16])))
		t2.Sub(update2).Store((*[8]int64)(unsafe.Pointer(&target[i+16])))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i - 1
			n2Idx = i
		} else {
			n1Idx = i
			n2Idx = i + 1
		}
		target[i] -= (neighbor[n1Idx] + neighbor[n2Idx] + 2) >> 2
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i - 1
			n2Idx = i
		} else {
			n1Idx = i
			n2Idx = i + 1
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] -= (neighbor[n1Idx] + neighbor[n2Idx] + 2) >> 2
	}
	_ = lanes
}

func BaseLiftPredict53_avx512_Int32(target []int32, tLen int, neighbor []int32, nLen int, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	lanes := 16
	start := 0
	if phase == 1 {
		target[0] += (neighbor[0] + neighbor[0]) >> 1
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	} else {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	}
	i := start
	for ; i+lanes*3 <= safeEnd; i += lanes * 3 {
		var n1, n2 archsimd.Int32x16
		if phase == 0 {
			n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i])))
			n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+1])))
		} else {
			n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i-1])))
			n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i])))
		}
		update := n1.Add(n2).ShiftAllRight(uint64(1))
		t := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&target[i])))
		t.Add(update).Store((*[16]int32)(unsafe.Pointer(&target[i])))
		var n11, n21 archsimd.Int32x16
		if phase == 0 {
			n11 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+16])))
			n21 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+1+16])))
		} else {
			n11 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i-1+16])))
			n21 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+16])))
		}
		update1 := n11.Add(n21).ShiftAllRight(uint64(1))
		t1 := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&target[i+16])))
		t1.Add(update1).Store((*[16]int32)(unsafe.Pointer(&target[i+16])))
		var n12, n22 archsimd.Int32x16
		if phase == 0 {
			n12 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+32])))
			n22 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+1+32])))
		} else {
			n12 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i-1+32])))
			n22 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&neighbor[i+32])))
		}
		update2 := n12.Add(n22).ShiftAllRight(uint64(1))
		t2 := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&target[i+32])))
		t2.Add(update2).Store((*[16]int32)(unsafe.Pointer(&target[i+32])))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		target[i] += (neighbor[n1Idx] + neighbor[n2Idx]) >> 1
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		if n1Idx < 0 {
			n1Idx = 0
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] += (neighbor[n1Idx] + neighbor[n2Idx]) >> 1
	}
	_ = lanes
}

func BaseLiftPredict53_avx512_Int64(target []int64, tLen int, neighbor []int64, nLen int, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	lanes := 8
	start := 0
	if phase == 1 {
		target[0] += (neighbor[0] + neighbor[0]) >> 1
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	} else {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	}
	i := start
	for ; i+lanes*3 <= safeEnd; i += lanes * 3 {
		var n1, n2 archsimd.Int64x8
		if phase == 0 {
			n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i])))
			n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+1])))
		} else {
			n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i-1])))
			n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i])))
		}
		update := n1.Add(n2).ShiftAllRight(uint64(1))
		t := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&target[i])))
		t.Add(update).Store((*[8]int64)(unsafe.Pointer(&target[i])))
		var n11, n21 archsimd.Int64x8
		if phase == 0 {
			n11 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+8])))
			n21 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+1+8])))
		} else {
			n11 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i-1+8])))
			n21 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+8])))
		}
		update1 := n11.Add(n21).ShiftAllRight(uint64(1))
		t1 := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&target[i+8])))
		t1.Add(update1).Store((*[8]int64)(unsafe.Pointer(&target[i+8])))
		var n12, n22 archsimd.Int64x8
		if phase == 0 {
			n12 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+16])))
			n22 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+1+16])))
		} else {
			n12 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i-1+16])))
			n22 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&neighbor[i+16])))
		}
		update2 := n12.Add(n22).ShiftAllRight(uint64(1))
		t2 := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&target[i+16])))
		t2.Add(update2).Store((*[8]int64)(unsafe.Pointer(&target[i+16])))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		target[i] += (neighbor[n1Idx] + neighbor[n2Idx]) >> 1
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		if n1Idx < 0 {
			n1Idx = 0
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] += (neighbor[n1Idx] + neighbor[n2Idx]) >> 1
	}
	_ = lanes
}

func BaseLiftStep97_avx512_Float16(target []hwy.Float16, tLen int, neighbor []hwy.Float16, nLen int, coeff hwy.Float16, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	coeffVec := asm.BroadcastFloat16x16AVX512(uint16(coeff))
	lanes := 16
	start := 0
	if phase == 1 {
		target[0] = hwy.Float32ToFloat16(target[0].Float32() - coeff.Float32()*(neighbor[0].Float32()+neighbor[0].Float32()))
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	} else {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	}
	i := start
	for ; i+lanes*4 <= safeEnd; i += lanes * 4 {
		var n1, n2 asm.Float16x16AVX512
		if phase == 0 {
			n1 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i:][0]))
			n2 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1:][0]))
		} else {
			n1 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1:][0]))
			n2 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i:][0]))
		}
		sum := n1.Add(n2)
		update := coeffVec.Mul(sum)
		t := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&target[i:][0]))
		t.Sub(update).StorePtr(unsafe.Pointer(&target[i:][0]))
		var n11, n21 asm.Float16x16AVX512
		if phase == 0 {
			n11 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+16:][0]))
			n21 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1+16:][0]))
		} else {
			n11 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1+16:][0]))
			n21 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+16:][0]))
		}
		sum1 := n11.Add(n21)
		update1 := coeffVec.Mul(sum1)
		t1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&target[i+16:][0]))
		t1.Sub(update1).StorePtr(unsafe.Pointer(&target[i+16:][0]))
		var n12, n22 asm.Float16x16AVX512
		if phase == 0 {
			n12 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+32:][0]))
			n22 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1+32:][0]))
		} else {
			n12 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1+32:][0]))
			n22 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+32:][0]))
		}
		sum2 := n12.Add(n22)
		update2 := coeffVec.Mul(sum2)
		t2 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&target[i+32:][0]))
		t2.Sub(update2).StorePtr(unsafe.Pointer(&target[i+32:][0]))
		var n13, n23 asm.Float16x16AVX512
		if phase == 0 {
			n13 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+48:][0]))
			n23 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1+48:][0]))
		} else {
			n13 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1+48:][0]))
			n23 = asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+48:][0]))
		}
		sum3 := n13.Add(n23)
		update3 := coeffVec.Mul(sum3)
		t3 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&target[i+48:][0]))
		t3.Sub(update3).StorePtr(unsafe.Pointer(&target[i+48:][0]))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		target[i] = hwy.Float32ToFloat16(target[i].Float32() - coeff.Float32()*(neighbor[n1Idx].Float32()+neighbor[n2Idx].Float32()))
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		if n1Idx < 0 {
			n1Idx = 0
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] = hwy.Float32ToFloat16(target[i].Float32() - coeff.Float32()*(neighbor[n1Idx].Float32()+neighbor[n2Idx].Float32()))
	}
	_ = coeffVec
	_ = lanes
}

func BaseLiftStep97_avx512_BFloat16(target []hwy.BFloat16, tLen int, neighbor []hwy.BFloat16, nLen int, coeff hwy.BFloat16, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	coeffVec := asm.BroadcastBFloat16x16AVX512(uint16(coeff))
	lanes := 16
	start := 0
	if phase == 1 {
		target[0] = hwy.Float32ToBFloat16(target[0].Float32() - coeff.Float32()*(neighbor[0].Float32()+neighbor[0].Float32()))
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	} else {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	}
	i := start
	for ; i+lanes*4 <= safeEnd; i += lanes * 4 {
		var n1, n2 asm.BFloat16x16AVX512
		if phase == 0 {
			n1 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i:][0]))
			n2 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1:][0]))
		} else {
			n1 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1:][0]))
			n2 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i:][0]))
		}
		sum := n1.Add(n2)
		update := coeffVec.Mul(sum)
		t := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&target[i:][0]))
		t.Sub(update).StorePtr(unsafe.Pointer(&target[i:][0]))
		var n11, n21 asm.BFloat16x16AVX512
		if phase == 0 {
			n11 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+16:][0]))
			n21 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1+16:][0]))
		} else {
			n11 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1+16:][0]))
			n21 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+16:][0]))
		}
		sum1 := n11.Add(n21)
		update1 := coeffVec.Mul(sum1)
		t1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&target[i+16:][0]))
		t1.Sub(update1).StorePtr(unsafe.Pointer(&target[i+16:][0]))
		var n12, n22 asm.BFloat16x16AVX512
		if phase == 0 {
			n12 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+32:][0]))
			n22 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1+32:][0]))
		} else {
			n12 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1+32:][0]))
			n22 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+32:][0]))
		}
		sum2 := n12.Add(n22)
		update2 := coeffVec.Mul(sum2)
		t2 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&target[i+32:][0]))
		t2.Sub(update2).StorePtr(unsafe.Pointer(&target[i+32:][0]))
		var n13, n23 asm.BFloat16x16AVX512
		if phase == 0 {
			n13 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+48:][0]))
			n23 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+1+48:][0]))
		} else {
			n13 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i-1+48:][0]))
			n23 = asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&neighbor[i+48:][0]))
		}
		sum3 := n13.Add(n23)
		update3 := coeffVec.Mul(sum3)
		t3 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&target[i+48:][0]))
		t3.Sub(update3).StorePtr(unsafe.Pointer(&target[i+48:][0]))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		target[i] = hwy.Float32ToBFloat16(target[i].Float32() - coeff.Float32()*(neighbor[n1Idx].Float32()+neighbor[n2Idx].Float32()))
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		if n1Idx < 0 {
			n1Idx = 0
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] = hwy.Float32ToBFloat16(target[i].Float32() - coeff.Float32()*(neighbor[n1Idx].Float32()+neighbor[n2Idx].Float32()))
	}
	_ = coeffVec
	_ = lanes
}

func BaseLiftStep97_avx512(target []float32, tLen int, neighbor []float32, nLen int, coeff float32, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	coeffVec := archsimd.BroadcastFloat32x16(coeff)
	lanes := 16
	start := 0
	if phase == 1 {
		target[0] -= coeff * (neighbor[0] + neighbor[0])
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	} else {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	}
	i := start
	for ; i+lanes*4 <= safeEnd; i += lanes * 4 {
		var n1, n2 archsimd.Float32x16
		if phase == 0 {
			n1 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i])))
			n2 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+1])))
		} else {
			n1 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i-1])))
			n2 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i])))
		}
		sum := n1.Add(n2)
		update := coeffVec.Mul(sum)
		t := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&target[i])))
		t.Sub(update).Store((*[16]float32)(unsafe.Pointer(&target[i])))
		var n11, n21 archsimd.Float32x16
		if phase == 0 {
			n11 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+16])))
			n21 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+1+16])))
		} else {
			n11 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i-1+16])))
			n21 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+16])))
		}
		sum1 := n11.Add(n21)
		update1 := coeffVec.Mul(sum1)
		t1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&target[i+16])))
		t1.Sub(update1).Store((*[16]float32)(unsafe.Pointer(&target[i+16])))
		var n12, n22 archsimd.Float32x16
		if phase == 0 {
			n12 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+32])))
			n22 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+1+32])))
		} else {
			n12 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i-1+32])))
			n22 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+32])))
		}
		sum2 := n12.Add(n22)
		update2 := coeffVec.Mul(sum2)
		t2 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&target[i+32])))
		t2.Sub(update2).Store((*[16]float32)(unsafe.Pointer(&target[i+32])))
		var n13, n23 archsimd.Float32x16
		if phase == 0 {
			n13 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+48])))
			n23 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+1+48])))
		} else {
			n13 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i-1+48])))
			n23 = archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&neighbor[i+48])))
		}
		sum3 := n13.Add(n23)
		update3 := coeffVec.Mul(sum3)
		t3 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&target[i+48])))
		t3.Sub(update3).Store((*[16]float32)(unsafe.Pointer(&target[i+48])))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		target[i] -= coeff * (neighbor[n1Idx] + neighbor[n2Idx])
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		if n1Idx < 0 {
			n1Idx = 0
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] -= coeff * (neighbor[n1Idx] + neighbor[n2Idx])
	}
	_ = coeffVec
	_ = lanes
}

func BaseLiftStep97_avx512_Float64(target []float64, tLen int, neighbor []float64, nLen int, coeff float64, phase int) {
	_liftingBaseInitHoistedConstants()
	if tLen == 0 || nLen == 0 {
		return
	}
	coeffVec := archsimd.BroadcastFloat64x8(coeff)
	lanes := 8
	start := 0
	if phase == 1 {
		target[0] -= coeff * (neighbor[0] + neighbor[0])
		start = 1
	}
	safeEnd := tLen
	if phase == 0 {
		if nLen-1 < safeEnd {
			safeEnd = nLen - 1
		}
	} else {
		if nLen < safeEnd {
			safeEnd = nLen
		}
	}
	i := start
	for ; i+lanes*4 <= safeEnd; i += lanes * 4 {
		var n1, n2 archsimd.Float64x8
		if phase == 0 {
			n1 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i])))
			n2 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+1])))
		} else {
			n1 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i-1])))
			n2 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i])))
		}
		sum := n1.Add(n2)
		update := coeffVec.Mul(sum)
		t := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&target[i])))
		t.Sub(update).Store((*[8]float64)(unsafe.Pointer(&target[i])))
		var n11, n21 archsimd.Float64x8
		if phase == 0 {
			n11 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+8])))
			n21 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+1+8])))
		} else {
			n11 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i-1+8])))
			n21 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+8])))
		}
		sum1 := n11.Add(n21)
		update1 := coeffVec.Mul(sum1)
		t1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&target[i+8])))
		t1.Sub(update1).Store((*[8]float64)(unsafe.Pointer(&target[i+8])))
		var n12, n22 archsimd.Float64x8
		if phase == 0 {
			n12 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+16])))
			n22 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+1+16])))
		} else {
			n12 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i-1+16])))
			n22 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+16])))
		}
		sum2 := n12.Add(n22)
		update2 := coeffVec.Mul(sum2)
		t2 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&target[i+16])))
		t2.Sub(update2).Store((*[8]float64)(unsafe.Pointer(&target[i+16])))
		var n13, n23 archsimd.Float64x8
		if phase == 0 {
			n13 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+24])))
			n23 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+1+24])))
		} else {
			n13 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i-1+24])))
			n23 = archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&neighbor[i+24])))
		}
		sum3 := n13.Add(n23)
		update3 := coeffVec.Mul(sum3)
		t3 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&target[i+24])))
		t3.Sub(update3).Store((*[8]float64)(unsafe.Pointer(&target[i+24])))
	}
	for ; i < safeEnd; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		target[i] -= coeff * (neighbor[n1Idx] + neighbor[n2Idx])
	}
	for ; i < tLen; i++ {
		var n1Idx, n2Idx int
		if phase == 0 {
			n1Idx = i
			n2Idx = i + 1
		} else {
			n1Idx = i - 1
			n2Idx = i
		}
		if n1Idx < 0 {
			n1Idx = 0
		}
		if n1Idx >= nLen {
			n1Idx = nLen - 1
		}
		if n2Idx >= nLen {
			n2Idx = nLen - 1
		}
		target[i] -= coeff * (neighbor[n1Idx] + neighbor[n2Idx])
	}
	_ = coeffVec
	_ = lanes
}

func BaseScaleSlice_avx512_Float16(data []hwy.Float16, n int, scale hwy.Float16) {
	_liftingBaseInitHoistedConstants()
	if n == 0 || data == nil {
		return
	}
	scaleVec := asm.BroadcastFloat16x16AVX512(uint16(scale))
	lanes := 16
	i := 0
	for ; i+lanes*4 <= n; i += lanes * 4 {
		v := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&data[i:][0]))
		result := v.Mul(scaleVec)
		result.StorePtr(unsafe.Pointer(&data[i:][0]))
		v1 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&data[i+16:][0]))
		result1 := v1.Mul(scaleVec)
		result1.StorePtr(unsafe.Pointer(&data[i+16:][0]))
		v2 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&data[i+32:][0]))
		result2 := v2.Mul(scaleVec)
		result2.StorePtr(unsafe.Pointer(&data[i+32:][0]))
		v3 := asm.LoadFloat16x16AVX512Ptr(unsafe.Pointer(&data[i+48:][0]))
		result3 := v3.Mul(scaleVec)
		result3.StorePtr(unsafe.Pointer(&data[i+48:][0]))
	}
	if i < n {
		BaseScaleSlice_fallback_Float16(data[i:n], n, scale)
	}
}

func BaseScaleSlice_avx512_BFloat16(data []hwy.BFloat16, n int, scale hwy.BFloat16) {
	_liftingBaseInitHoistedConstants()
	if n == 0 || data == nil {
		return
	}
	scaleVec := asm.BroadcastBFloat16x16AVX512(uint16(scale))
	lanes := 16
	i := 0
	for ; i+lanes*4 <= n; i += lanes * 4 {
		v := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&data[i:][0]))
		result := v.Mul(scaleVec)
		result.StorePtr(unsafe.Pointer(&data[i:][0]))
		v1 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&data[i+16:][0]))
		result1 := v1.Mul(scaleVec)
		result1.StorePtr(unsafe.Pointer(&data[i+16:][0]))
		v2 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&data[i+32:][0]))
		result2 := v2.Mul(scaleVec)
		result2.StorePtr(unsafe.Pointer(&data[i+32:][0]))
		v3 := asm.LoadBFloat16x16AVX512Ptr(unsafe.Pointer(&data[i+48:][0]))
		result3 := v3.Mul(scaleVec)
		result3.StorePtr(unsafe.Pointer(&data[i+48:][0]))
	}
	if i < n {
		BaseScaleSlice_fallback_BFloat16(data[i:n], n, scale)
	}
}

func BaseScaleSlice_avx512(data []float32, n int, scale float32) {
	_liftingBaseInitHoistedConstants()
	if n == 0 || data == nil {
		return
	}
	scaleVec := archsimd.BroadcastFloat32x16(scale)
	lanes := 16
	i := 0
	for ; i+lanes*4 <= n; i += lanes * 4 {
		v := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&data[i])))
		result := v.Mul(scaleVec)
		result.Store((*[16]float32)(unsafe.Pointer(&data[i])))
		v1 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&data[i+16])))
		result1 := v1.Mul(scaleVec)
		result1.Store((*[16]float32)(unsafe.Pointer(&data[i+16])))
		v2 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&data[i+32])))
		result2 := v2.Mul(scaleVec)
		result2.Store((*[16]float32)(unsafe.Pointer(&data[i+32])))
		v3 := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&data[i+48])))
		result3 := v3.Mul(scaleVec)
		result3.Store((*[16]float32)(unsafe.Pointer(&data[i+48])))
	}
	for ; i < n; i++ {
		data[i] *= scale
	}
}

func BaseScaleSlice_avx512_Float64(data []float64, n int, scale float64) {
	_liftingBaseInitHoistedConstants()
	if n == 0 || data == nil {
		return
	}
	scaleVec := archsimd.BroadcastFloat64x8(scale)
	lanes := 8
	i := 0
	for ; i+lanes*4 <= n; i += lanes * 4 {
		v := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&data[i])))
		result := v.Mul(scaleVec)
		result.Store((*[8]float64)(unsafe.Pointer(&data[i])))
		v1 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&data[i+8])))
		result1 := v1.Mul(scaleVec)
		result1.Store((*[8]float64)(unsafe.Pointer(&data[i+8])))
		v2 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&data[i+16])))
		result2 := v2.Mul(scaleVec)
		result2.Store((*[8]float64)(unsafe.Pointer(&data[i+16])))
		v3 := archsimd.LoadFloat64x8((*[8]float64)(unsafe.Pointer(&data[i+24])))
		result3 := v3.Mul(scaleVec)
		result3.Store((*[8]float64)(unsafe.Pointer(&data[i+24])))
	}
	for ; i < n; i++ {
		data[i] *= scale
	}
}

func BaseInterleave_avx512(dst []float32, low []float32, sn int, high []float32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = low[i]
			dst[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i+1] = high[i]
		}
	} else {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = high[i]
			dst[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i] = high[i]
		}
	}
}

func BaseInterleave_avx512_Float64(dst []float64, low []float64, sn int, high []float64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = low[i]
			dst[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i+1] = high[i]
		}
	} else {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = high[i]
			dst[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i] = high[i]
		}
	}
}

func BaseInterleave_avx512_Int32(dst []int32, low []int32, sn int, high []int32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = low[i]
			dst[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i+1] = high[i]
		}
	} else {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = high[i]
			dst[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i] = high[i]
		}
	}
}

func BaseInterleave_avx512_Int64(dst []int64, low []int64, sn int, high []int64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = low[i]
			dst[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i+1] = high[i]
		}
	} else {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = high[i]
			dst[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i] = high[i]
		}
	}
}

func BaseInterleave_avx512_Uint32(dst []uint32, low []uint32, sn int, high []uint32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = low[i]
			dst[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i+1] = high[i]
		}
	} else {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = high[i]
			dst[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i] = high[i]
		}
	}
}

func BaseInterleave_avx512_Uint64(dst []uint64, low []uint64, sn int, high []uint64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = low[i]
			dst[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i+1] = high[i]
		}
	} else {
		for i := 0; i < sn && i < dn; i++ {
			dst[2*i] = high[i]
			dst[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			dst[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			dst[2*i] = high[i]
		}
	}
}

func BaseSynthesize53Core_avx512_Int32(data []int32, n int, low []int32, sn int, high []int32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	for ci := 0; ci < sn; ci++ {
		low[ci] = data[ci]
	}
	for ci := 0; ci < dn; ci++ {
		high[ci] = data[sn+ci]
	}
	{
		twoVec := BaseSynthesize53Core_AVX512_twoVec_i32_f32
		lanes := 16
		start := 0
		if phase == 0 {
			low[0] -= (high[0] + high[0] + 2) >> 2
			start = 1
		}
		safeEnd := sn
		if phase == 0 {
			if dn < safeEnd {
				safeEnd = dn
			}
		} else {
			if dn-1 < safeEnd {
				safeEnd = dn - 1
			}
		}
		i := start
		for ; i+lanes <= safeEnd; i += lanes {
			var n1, n2 archsimd.Int32x16
			if phase == 0 {
				n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&high[i-1])))
				n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&high[i])))
			} else {
				n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&high[i])))
				n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&high[i+1])))
			}
			sum := n1.Add(n2).Add(twoVec)
			update := sum.ShiftAllRight(uint64(2))
			t := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&low[i])))
			t.Sub(update).Store((*[16]int32)(unsafe.Pointer(&low[i])))
		}
		for ; i < safeEnd; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i - 1
				n2Idx = i
			} else {
				n1Idx = i
				n2Idx = i + 1
			}
			low[i] -= (high[n1Idx] + high[n2Idx] + 2) >> 2
		}
		for ; i < sn; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i - 1
				n2Idx = i
			} else {
				n1Idx = i
				n2Idx = i + 1
			}
			if n1Idx >= dn {
				n1Idx = dn - 1
			}
			if n2Idx >= dn {
				n2Idx = dn - 1
			}
			low[i] -= (high[n1Idx] + high[n2Idx] + 2) >> 2
		}
		_ = twoVec
		_ = lanes
	}
	{
		lanes := 16
		start := 0
		if phase == 1 {
			high[0] += (low[0] + low[0]) >> 1
			start = 1
		}
		safeEnd := dn
		if phase == 0 {
			if sn-1 < safeEnd {
				safeEnd = sn - 1
			}
		} else {
			if sn < safeEnd {
				safeEnd = sn
			}
		}
		i := start
		for ; i+lanes <= safeEnd; i += lanes {
			var n1, n2 archsimd.Int32x16
			if phase == 0 {
				n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&low[i])))
				n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&low[i+1])))
			} else {
				n1 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&low[i-1])))
				n2 = archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&low[i])))
			}
			update := n1.Add(n2).ShiftAllRight(uint64(1))
			t := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&high[i])))
			t.Add(update).Store((*[16]int32)(unsafe.Pointer(&high[i])))
		}
		for ; i < safeEnd; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i
				n2Idx = i + 1
			} else {
				n1Idx = i - 1
				n2Idx = i
			}
			high[i] += (low[n1Idx] + low[n2Idx]) >> 1
		}
		for ; i < dn; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i
				n2Idx = i + 1
			} else {
				n1Idx = i - 1
				n2Idx = i
			}
			if n1Idx < 0 {
				n1Idx = 0
			}
			if n1Idx >= sn {
				n1Idx = sn - 1
			}
			if n2Idx >= sn {
				n2Idx = sn - 1
			}
			high[i] += (low[n1Idx] + low[n2Idx]) >> 1
		}
		_ = lanes
	}
	if phase == 0 {
		lanes := 16
		minN := min(sn, dn)
		i := 0
		for ; i+lanes <= minN; i += lanes {
			lo := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&low[i])))
			hi := archsimd.LoadInt32x16((*[16]int32)(unsafe.Pointer(&high[i])))
			z0 := hwy.InterleaveLower_AVX512_I32x16(lo, hi)
			z1 := hwy.InterleaveUpper_AVX512_I32x16(lo, hi)
			z0.Store((*[16]int32)(unsafe.Pointer(&data[2*i])))
			z1.Store((*[16]int32)(unsafe.Pointer(&data[2*i+lanes])))
		}
		for ; i < minN; i++ {
			data[2*i] = low[i]
			data[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			data[2*i] = low[i]
		}
		_ = lanes
	} else {
		minN := min(sn, dn)
		for i := range minN {
			data[2*i] = high[i]
			data[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			data[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			data[2*i] = high[i]
		}
	}
}

func BaseSynthesize53Core_avx512_Int64(data []int64, n int, low []int64, sn int, high []int64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	for ci := 0; ci < sn; ci++ {
		low[ci] = data[ci]
	}
	for ci := 0; ci < dn; ci++ {
		high[ci] = data[sn+ci]
	}
	{
		twoVec := BaseSynthesize53Core_AVX512_twoVec_f32
		lanes := 8
		start := 0
		if phase == 0 {
			low[0] -= (high[0] + high[0] + 2) >> 2
			start = 1
		}
		safeEnd := sn
		if phase == 0 {
			if dn < safeEnd {
				safeEnd = dn
			}
		} else {
			if dn-1 < safeEnd {
				safeEnd = dn - 1
			}
		}
		i := start
		for ; i+lanes <= safeEnd; i += lanes {
			var n1, n2 archsimd.Int64x8
			if phase == 0 {
				n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&high[i-1])))
				n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&high[i])))
			} else {
				n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&high[i])))
				n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&high[i+1])))
			}
			sum := n1.Add(n2).Add(twoVec)
			update := sum.ShiftAllRight(uint64(2))
			t := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&low[i])))
			t.Sub(update).Store((*[8]int64)(unsafe.Pointer(&low[i])))
		}
		for ; i < safeEnd; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i - 1
				n2Idx = i
			} else {
				n1Idx = i
				n2Idx = i + 1
			}
			low[i] -= (high[n1Idx] + high[n2Idx] + 2) >> 2
		}
		for ; i < sn; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i - 1
				n2Idx = i
			} else {
				n1Idx = i
				n2Idx = i + 1
			}
			if n1Idx >= dn {
				n1Idx = dn - 1
			}
			if n2Idx >= dn {
				n2Idx = dn - 1
			}
			low[i] -= (high[n1Idx] + high[n2Idx] + 2) >> 2
		}
		_ = twoVec
		_ = lanes
	}
	{
		lanes := 8
		start := 0
		if phase == 1 {
			high[0] += (low[0] + low[0]) >> 1
			start = 1
		}
		safeEnd := dn
		if phase == 0 {
			if sn-1 < safeEnd {
				safeEnd = sn - 1
			}
		} else {
			if sn < safeEnd {
				safeEnd = sn
			}
		}
		i := start
		for ; i+lanes <= safeEnd; i += lanes {
			var n1, n2 archsimd.Int64x8
			if phase == 0 {
				n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&low[i])))
				n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&low[i+1])))
			} else {
				n1 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&low[i-1])))
				n2 = archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&low[i])))
			}
			update := n1.Add(n2).ShiftAllRight(uint64(1))
			t := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&high[i])))
			t.Add(update).Store((*[8]int64)(unsafe.Pointer(&high[i])))
		}
		for ; i < safeEnd; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i
				n2Idx = i + 1
			} else {
				n1Idx = i - 1
				n2Idx = i
			}
			high[i] += (low[n1Idx] + low[n2Idx]) >> 1
		}
		for ; i < dn; i++ {
			var n1Idx, n2Idx int
			if phase == 0 {
				n1Idx = i
				n2Idx = i + 1
			} else {
				n1Idx = i - 1
				n2Idx = i
			}
			if n1Idx < 0 {
				n1Idx = 0
			}
			if n1Idx >= sn {
				n1Idx = sn - 1
			}
			if n2Idx >= sn {
				n2Idx = sn - 1
			}
			high[i] += (low[n1Idx] + low[n2Idx]) >> 1
		}
		_ = lanes
	}
	if phase == 0 {
		lanes := 8
		minN := min(sn, dn)
		i := 0
		for ; i+lanes <= minN; i += lanes {
			lo := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&low[i])))
			hi := archsimd.LoadInt64x8((*[8]int64)(unsafe.Pointer(&high[i])))
			z0 := hwy.InterleaveLower_AVX512_I64x8(lo, hi)
			z1 := hwy.InterleaveUpper_AVX512_I64x8(lo, hi)
			z0.Store((*[8]int64)(unsafe.Pointer(&data[2*i])))
			z1.Store((*[8]int64)(unsafe.Pointer(&data[2*i+lanes])))
		}
		for ; i < minN; i++ {
			data[2*i] = low[i]
			data[2*i+1] = high[i]
		}
		for i := dn; i < sn; i++ {
			data[2*i] = low[i]
		}
		_ = lanes
	} else {
		minN := min(sn, dn)
		for i := range minN {
			data[2*i] = high[i]
			data[2*i+1] = low[i]
		}
		for i := dn; i < sn; i++ {
			data[2*i+1] = low[i]
		}
		for i := sn; i < dn; i++ {
			data[2*i] = high[i]
		}
	}
}

func BaseDeinterleave_avx512(src []float32, low []float32, sn int, high []float32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := range sn {
			low[i] = src[2*i]
		}
		for i := range dn {
			high[i] = src[2*i+1]
		}
	} else {
		for i := range dn {
			high[i] = src[2*i]
		}
		for i := range sn {
			low[i] = src[2*i+1]
		}
	}
}

func BaseDeinterleave_avx512_Float64(src []float64, low []float64, sn int, high []float64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := range sn {
			low[i] = src[2*i]
		}
		for i := range dn {
			high[i] = src[2*i+1]
		}
	} else {
		for i := range dn {
			high[i] = src[2*i]
		}
		for i := range sn {
			low[i] = src[2*i+1]
		}
	}
}

func BaseDeinterleave_avx512_Int32(src []int32, low []int32, sn int, high []int32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := range sn {
			low[i] = src[2*i]
		}
		for i := range dn {
			high[i] = src[2*i+1]
		}
	} else {
		for i := range dn {
			high[i] = src[2*i]
		}
		for i := range sn {
			low[i] = src[2*i+1]
		}
	}
}

func BaseDeinterleave_avx512_Int64(src []int64, low []int64, sn int, high []int64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := range sn {
			low[i] = src[2*i]
		}
		for i := range dn {
			high[i] = src[2*i+1]
		}
	} else {
		for i := range dn {
			high[i] = src[2*i]
		}
		for i := range sn {
			low[i] = src[2*i+1]
		}
	}
}

func BaseDeinterleave_avx512_Uint32(src []uint32, low []uint32, sn int, high []uint32, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := range sn {
			low[i] = src[2*i]
		}
		for i := range dn {
			high[i] = src[2*i+1]
		}
	} else {
		for i := range dn {
			high[i] = src[2*i]
		}
		for i := range sn {
			low[i] = src[2*i+1]
		}
	}
}

func BaseDeinterleave_avx512_Uint64(src []uint64, low []uint64, sn int, high []uint64, dn int, phase int) {
	_liftingBaseInitHoistedConstants()
	if phase == 0 {
		for i := range sn {
			low[i] = src[2*i]
		}
		for i := range dn {
			high[i] = src[2*i+1]
		}
	} else {
		for i := range dn {
			high[i] = src[2*i]
		}
		for i := range sn {
			low[i] = src[2*i+1]
		}
	}
}
