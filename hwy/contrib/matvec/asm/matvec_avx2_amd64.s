//go:build !noasm && amd64
// Code generated by GoAT. DO NOT EDIT.
// versions:
// 	clang   21.1.8
// 	objdump 2.45.1
// flags: -mavx2 -mfma -mf16c -O3
// source: ../c/matvec_avx2_amd64.c

TEXT 路matvec_avx2_f16(SB), $0-40
	MOVQ m+0(FP), DI
	MOVQ v+8(FP), SI
	MOVQ result+16(FP), DX
	MOVQ prows+24(FP), CX
	MOVQ pcols+32(FP), R8
	BYTE $0x55               // pushq	%rbp
	WORD $0x5741             // pushq	%r15
	WORD $0x5641             // pushq	%r14
	WORD $0x5541             // pushq	%r13
	WORD $0x5441             // pushq	%r12
	BYTE $0x53               // pushq	%rbx
	BYTE $0x50               // pushq	%rax
	WORD $0x8b48; BYTE $0x01 // movq	(%rcx), %rax
	WORD $0x8548; BYTE $0xc0 // testq	%rax, %rax
	JLE  BB0_28
	WORD $0x8b49; BYTE $0x08 // movq	(%r8), %rcx
	LONG $0x08f98348         // cmpq	$8, %rcx
	JGE  BB0_2
	LONG $0xc957f0c5         // vxorps	%xmm1, %xmm1, %xmm1
	LONG $0xc17cf3c5         // vhaddps	%xmm1, %xmm1, %xmm0
	LONG $0xc07cfbc5         // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	JLE  BB0_15
	LONG $0x0cc78348         // addq	$12, %rdi
	LONG $0x09048d4c         // leaq	(%rcx,%rcx), %r8
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	JMP  BB0_7

BB0_14:
	LONG $0x1d79e3c4; WORD $0x00c9             // vcvtps2ph	$0, %xmm1, %xmm1
	LONG $0x1579a3c4; WORD $0x4a0c; BYTE $0x00 // vpextrw	$0, %xmm1, (%rdx,%r9,2)
	WORD $0xff49; BYTE $0xc1                   // incq	%r9
	WORD $0x014c; BYTE $0xc7                   // addq	%r8, %rdi
	WORD $0x394c; BYTE $0xc8                   // cmpq	%r9, %rax
	JE   BB0_28

BB0_7:
	LONG $0x4fc4f9c5; WORD $0x00f4 // vpinsrw	$0, -12(%rdi), %xmm0, %xmm1
	LONG $0x16c4f9c5; BYTE $0x00   // vpinsrw	$0, (%rsi), %xmm0, %xmm2
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0x1379e2c4; BYTE $0xc9   // vcvtph2ps	%xmm1, %xmm1
	LONG $0xca59f2c5               // vmulss	%xmm2, %xmm1, %xmm1
	LONG $0xc958fac5               // vaddss	%xmm1, %xmm0, %xmm1
	LONG $0x01f98348               // cmpq	$1, %rcx
	JE   BB0_14
	LONG $0x57c4f9c5; WORD $0x00f6 // vpinsrw	$0, -10(%rdi), %xmm0, %xmm2
	LONG $0x5ec4f9c5; WORD $0x0002 // vpinsrw	$0, 2(%rsi), %xmm0, %xmm3
	LONG $0x1379e2c4; BYTE $0xdb   // vcvtph2ps	%xmm3, %xmm3
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0xd359eac5               // vmulss	%xmm3, %xmm2, %xmm2
	LONG $0xca58f2c5               // vaddss	%xmm2, %xmm1, %xmm1
	LONG $0x02f98348               // cmpq	$2, %rcx
	JE   BB0_14
	LONG $0x57c4f9c5; WORD $0x00f8 // vpinsrw	$0, -8(%rdi), %xmm0, %xmm2
	LONG $0x5ec4f9c5; WORD $0x0004 // vpinsrw	$0, 4(%rsi), %xmm0, %xmm3
	LONG $0x1379e2c4; BYTE $0xdb   // vcvtph2ps	%xmm3, %xmm3
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0xd359eac5               // vmulss	%xmm3, %xmm2, %xmm2
	LONG $0xca58f2c5               // vaddss	%xmm2, %xmm1, %xmm1
	LONG $0x03f98348               // cmpq	$3, %rcx
	JE   BB0_14
	LONG $0x57c4f9c5; WORD $0x00fa // vpinsrw	$0, -6(%rdi), %xmm0, %xmm2
	LONG $0x5ec4f9c5; WORD $0x0006 // vpinsrw	$0, 6(%rsi), %xmm0, %xmm3
	LONG $0x1379e2c4; BYTE $0xdb   // vcvtph2ps	%xmm3, %xmm3
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0xd359eac5               // vmulss	%xmm3, %xmm2, %xmm2
	LONG $0xca58f2c5               // vaddss	%xmm2, %xmm1, %xmm1
	LONG $0x04f98348               // cmpq	$4, %rcx
	JE   BB0_14
	LONG $0x57c4f9c5; WORD $0x00fc // vpinsrw	$0, -4(%rdi), %xmm0, %xmm2
	LONG $0x5ec4f9c5; WORD $0x0008 // vpinsrw	$0, 8(%rsi), %xmm0, %xmm3
	LONG $0x1379e2c4; BYTE $0xdb   // vcvtph2ps	%xmm3, %xmm3
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0xd359eac5               // vmulss	%xmm3, %xmm2, %xmm2
	LONG $0xca58f2c5               // vaddss	%xmm2, %xmm1, %xmm1
	LONG $0x05f98348               // cmpq	$5, %rcx
	JE   BB0_14
	LONG $0x57c4f9c5; WORD $0x00fe // vpinsrw	$0, -2(%rdi), %xmm0, %xmm2
	LONG $0x5ec4f9c5; WORD $0x000a // vpinsrw	$0, 10(%rsi), %xmm0, %xmm3
	LONG $0x1379e2c4; BYTE $0xdb   // vcvtph2ps	%xmm3, %xmm3
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0xd359eac5               // vmulss	%xmm3, %xmm2, %xmm2
	LONG $0xca58f2c5               // vaddss	%xmm2, %xmm1, %xmm1
	LONG $0x06f98348               // cmpq	$6, %rcx
	JE   BB0_14
	LONG $0x17c4f9c5; BYTE $0x00   // vpinsrw	$0, (%rdi), %xmm0, %xmm2
	LONG $0x5ec4f9c5; WORD $0x000c // vpinsrw	$0, 12(%rsi), %xmm0, %xmm3
	LONG $0x1379e2c4; BYTE $0xdb   // vcvtph2ps	%xmm3, %xmm3
	LONG $0x1379e2c4; BYTE $0xd2   // vcvtph2ps	%xmm2, %xmm2
	LONG $0xd359eac5               // vmulss	%xmm3, %xmm2, %xmm2
	LONG $0xca58f2c5               // vaddss	%xmm2, %xmm1, %xmm1
	JMP  BB0_14

BB0_2:
	LONG $0xf8418d4c         // leaq	-8(%rcx), %r8
	WORD $0x894d; BYTE $0xc2 // movq	%r8, %r10
	LONG $0x03eac149         // shrq	$3, %r10
	WORD $0xff49; BYTE $0xc2 // incq	%r10
	WORD $0x8945; BYTE $0xd1 // movl	%r10d, %r9d
	LONG $0x03e18341         // andl	$3, %r9d
	LONG $0xfce28349         // andq	$-4, %r10
	LONG $0x2414894c         // movq	%r10, (%rsp)                    ## 8-byte Spill
	LONG $0x305f8d4c         // leaq	48(%rdi), %r11
	LONG $0x091c8d48         // leaq	(%rcx,%rcx), %rbx
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
	WORD $0x8949; BYTE $0xff // movq	%rdi, %r15
	JMP  BB0_3

BB0_41:
	LONG $0x1d79e3c4; WORD $0x00c0             // vcvtps2ph	$0, %xmm0, %xmm0
	LONG $0x1579a3c4; WORD $0x7204; BYTE $0x00 // vpextrw	$0, %xmm0, (%rdx,%r14,2)
	WORD $0xff49; BYTE $0xc6                   // incq	%r14
	WORD $0x0149; BYTE $0xdb                   // addq	%rbx, %r11
	WORD $0x0149; BYTE $0xdf                   // addq	%rbx, %r15
	WORD $0x3949; BYTE $0xc6                   // cmpq	%rax, %r14
	JE   BB0_28

BB0_3:
	LONG $0xc057f8c5             // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x18f88349             // cmpq	$24, %r8
	JAE  BB0_29
	LONG $0x000008bd; BYTE $0x00 // movl	$8, %ebp
	WORD $0x3145; BYTE $0xe4     // xorl	%r12d, %r12d
	JMP  BB0_32

BB0_29:
	LONG $0x242c8b4c         // movq	(%rsp), %r13                    ## 8-byte Reload
	WORD $0x3145; BYTE $0xe4 // xorl	%r12d, %r12d

BB0_30:
	LONG $0x137d82c4; WORD $0x634c; BYTE $0xd0 // vcvtph2ps	-48(%r11,%r12,2), %ymm1
	LONG $0x137da2c4; WORD $0x6614             // vcvtph2ps	(%rsi,%r12,2), %ymm2
	LONG $0x137d82c4; WORD $0x635c; BYTE $0xe0 // vcvtph2ps	-32(%r11,%r12,2), %ymm3
	LONG $0x137da2c4; WORD $0x6664; BYTE $0x10 // vcvtph2ps	16(%rsi,%r12,2), %ymm4
	LONG $0x137d82c4; WORD $0x636c; BYTE $0xf0 // vcvtph2ps	-16(%r11,%r12,2), %ymm5
	LONG $0x137da2c4; WORD $0x6674; BYTE $0x20 // vcvtph2ps	32(%rsi,%r12,2), %ymm6
	LONG $0xa875e2c4; BYTE $0xd0               // vfmadd213ps	%ymm0, %ymm1, %ymm2     ## ymm2 = (ymm1 * ymm2) + ymm0
	LONG $0x137d82c4; WORD $0x630c             // vcvtph2ps	(%r11,%r12,2), %ymm1
	LONG $0xa865e2c4; BYTE $0xe2               // vfmadd213ps	%ymm2, %ymm3, %ymm4     ## ymm4 = (ymm3 * ymm4) + ymm2
	LONG $0x137da2c4; WORD $0x6644; BYTE $0x30 // vcvtph2ps	48(%rsi,%r12,2), %ymm0
	LONG $0xa855e2c4; BYTE $0xf4               // vfmadd213ps	%ymm4, %ymm5, %ymm6     ## ymm6 = (ymm5 * ymm6) + ymm4
	LONG $0xa875e2c4; BYTE $0xc6               // vfmadd213ps	%ymm6, %ymm1, %ymm0     ## ymm0 = (ymm1 * ymm0) + ymm6
	LONG $0x20c48349                           // addq	$32, %r12
	LONG $0xfcc58349                           // addq	$-4, %r13
	JNE  BB0_30
	LONG $0x246c8d49; BYTE $0x08               // leaq	8(%r12), %rbp

BB0_32:
	WORD $0x894d; BYTE $0xf2 // movq	%r14, %r10
	LONG $0xd1af0f4c         // imulq	%rcx, %r10
	LONG $0x572c8d4e         // leaq	(%rdi,%r10,2), %r13
	WORD $0x854d; BYTE $0xc9 // testq	%r9, %r9
	JE   BB0_36
	WORD $0x894d; BYTE $0xca // movq	%r9, %r10

BB0_34:
	LONG $0x137d82c4; WORD $0x654c; BYTE $0x00 // vcvtph2ps	(%r13,%r12,2), %ymm1
	LONG $0x137da2c4; WORD $0x6614             // vcvtph2ps	(%rsi,%r12,2), %ymm2
	LONG $0xb875e2c4; BYTE $0xc2               // vfmadd231ps	%ymm2, %ymm1, %ymm0     ## ymm0 = (ymm1 * ymm2) + ymm0
	WORD $0x8949; BYTE $0xec                   // movq	%rbp, %r12
	LONG $0x08c58348                           // addq	$8, %rbp
	WORD $0xff49; BYTE $0xca                   // decq	%r10
	JNE  BB0_34
	LONG $0xf8c58348                           // addq	$-8, %rbp
	WORD $0x8949; BYTE $0xec                   // movq	%rbp, %r12

BB0_36:
	LONG $0x197de3c4; WORD $0x01c1             // vextractf128	$1, %ymm0, %xmm1
	LONG $0xc158f8c5                           // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5                           // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5                           // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x394c; BYTE $0xe1                   // cmpq	%r12, %rcx
	JLE  BB0_41
	WORD $0x8941; BYTE $0xca                   // movl	%ecx, %r10d
	WORD $0x2945; BYTE $0xe2                   // subl	%r12d, %r10d
	LONG $0x246c8d49; BYTE $0x01               // leaq	1(%r12), %rbp
	LONG $0x01c2f641                           // testb	$1, %r10b
	JE   BB0_39
	QUAD $0x0000654cc47981c4                   // vpinsrw	$0, (%r13,%r12,2), %xmm0, %xmm1
	LONG $0xc479a1c4; WORD $0x6614; BYTE $0x00 // vpinsrw	$0, (%rsi,%r12,2), %xmm0, %xmm2
	LONG $0x1379e2c4; BYTE $0xd2               // vcvtph2ps	%xmm2, %xmm2
	LONG $0x1379e2c4; BYTE $0xc9               // vcvtph2ps	%xmm1, %xmm1
	LONG $0xca59f2c5                           // vmulss	%xmm2, %xmm1, %xmm1
	LONG $0xc158fac5                           // vaddss	%xmm1, %xmm0, %xmm0
	WORD $0x8949; BYTE $0xec                   // movq	%rbp, %r12

BB0_39:
	WORD $0x3948; BYTE $0xe9 // cmpq	%rbp, %rcx
	JE   BB0_41

BB0_40:
	LONG $0xc47981c4; WORD $0x670c; BYTE $0x00 // vpinsrw	$0, (%r15,%r12,2), %xmm0, %xmm1
	LONG $0xc479a1c4; WORD $0x6614; BYTE $0x00 // vpinsrw	$0, (%rsi,%r12,2), %xmm0, %xmm2
	LONG $0x1379e2c4; BYTE $0xd2               // vcvtph2ps	%xmm2, %xmm2
	LONG $0x1379e2c4; BYTE $0xc9               // vcvtph2ps	%xmm1, %xmm1
	LONG $0xca59f2c5                           // vmulss	%xmm2, %xmm1, %xmm1
	LONG $0xc158fac5                           // vaddss	%xmm1, %xmm0, %xmm0
	QUAD $0x0002674cc47981c4                   // vpinsrw	$0, 2(%r15,%r12,2), %xmm0, %xmm1
	QUAD $0x00026654c479a1c4                   // vpinsrw	$0, 2(%rsi,%r12,2), %xmm0, %xmm2
	LONG $0x1379e2c4; BYTE $0xd2               // vcvtph2ps	%xmm2, %xmm2
	LONG $0x1379e2c4; BYTE $0xc9               // vcvtph2ps	%xmm1, %xmm1
	LONG $0xca59f2c5                           // vmulss	%xmm2, %xmm1, %xmm1
	LONG $0xc158fac5                           // vaddss	%xmm1, %xmm0, %xmm0
	LONG $0x02c48349                           // addq	$2, %r12
	WORD $0x3949; BYTE $0xcc                   // cmpq	%rcx, %r12
	JL   BB0_40
	JMP  BB0_41

BB0_15:
	LONG $0x0c71e3c4; WORD $0x01c0 // vblendps	$1, %xmm0, %xmm1, %xmm0         ## xmm0 = xmm0[0],xmm1[1,2,3]
	LONG $0x1d79e3c4; WORD $0x00c0 // vcvtps2ph	$0, %xmm0, %xmm0
	LONG $0x08f88348               // cmpq	$8, %rax
	JAE  BB0_17
	WORD $0xc931                   // xorl	%ecx, %ecx
	JMP  BB0_26

BB0_17:
	QUAD $0xffffffffffc0be48; WORD $0x7fff // movabsq	$9223372036854775744, %rsi      ## imm = 0x7FFFFFFFFFFFFFC0
	LONG $0x40f88348                       // cmpq	$64, %rax
	JAE  BB0_19
	WORD $0xc931                           // xorl	%ecx, %ecx
	JMP  BB0_23

BB0_19:
	WORD $0x8948; BYTE $0xc1     // movq	%rax, %rcx
	WORD $0x2148; BYTE $0xf1     // andq	%rsi, %rcx
	LONG $0x797de2c4; BYTE $0xc8 // vpbroadcastw	%xmm0, %ymm1
	WORD $0xff31                 // xorl	%edi, %edi

BB0_20:
	LONG $0x0c7ffec5; BYTE $0x7a   // vmovdqu	%ymm1, (%rdx,%rdi,2)
	LONG $0x4c7ffec5; WORD $0x207a // vmovdqu	%ymm1, 32(%rdx,%rdi,2)
	LONG $0x4c7ffec5; WORD $0x407a // vmovdqu	%ymm1, 64(%rdx,%rdi,2)
	LONG $0x4c7ffec5; WORD $0x607a // vmovdqu	%ymm1, 96(%rdx,%rdi,2)
	LONG $0x40c78348               // addq	$64, %rdi
	WORD $0x3948; BYTE $0xf9       // cmpq	%rdi, %rcx
	JNE  BB0_20
	WORD $0x3948; BYTE $0xc8       // cmpq	%rcx, %rax
	JE   BB0_28
	WORD $0x38a8                   // testb	$56, %al
	JE   BB0_26

BB0_23:
	WORD $0x8948; BYTE $0xcf     // movq	%rcx, %rdi
	LONG $0x38c68348             // addq	$56, %rsi
	WORD $0x8948; BYTE $0xf1     // movq	%rsi, %rcx
	WORD $0x2148; BYTE $0xc1     // andq	%rax, %rcx
	LONG $0x7979e2c4; BYTE $0xc8 // vpbroadcastw	%xmm0, %xmm1

BB0_24:
	LONG $0x0c7ffac5; BYTE $0x7a // vmovdqu	%xmm1, (%rdx,%rdi,2)
	LONG $0x08c78348             // addq	$8, %rdi
	WORD $0x3948; BYTE $0xf9     // cmpq	%rdi, %rcx
	JNE  BB0_24
	WORD $0x3948; BYTE $0xc8     // cmpq	%rcx, %rax
	JE   BB0_28

BB0_26:
	LONG $0xc67ef9c5 // vmovd	%xmm0, %esi

BB0_27:
	LONG $0x4a348966         // movw	%si, (%rdx,%rcx,2)
	WORD $0xff48; BYTE $0xc1 // incq	%rcx
	WORD $0x3948; BYTE $0xc8 // cmpq	%rcx, %rax
	JNE  BB0_27

BB0_28:
	LONG $0x08c48348         // addq	$8, %rsp
	BYTE $0x5b               // popq	%rbx
	WORD $0x5c41             // popq	%r12
	WORD $0x5d41             // popq	%r13
	WORD $0x5e41             // popq	%r14
	WORD $0x5f41             // popq	%r15
	BYTE $0x5d               // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT 路matvec_avx2_bf16(SB), $0-40
	MOVQ m+0(FP), DI
	MOVQ v+8(FP), SI
	MOVQ result+16(FP), DX
	MOVQ prows+24(FP), CX
	MOVQ pcols+32(FP), R8
	BYTE $0x55               // pushq	%rbp
	WORD $0x5741             // pushq	%r15
	WORD $0x5641             // pushq	%r14
	WORD $0x5441             // pushq	%r12
	BYTE $0x53               // pushq	%rbx
	WORD $0x8b48; BYTE $0x01 // movq	(%rcx), %rax
	WORD $0x8548; BYTE $0xc0 // testq	%rax, %rax
	JLE  BB1_27
	WORD $0x8b49; BYTE $0x08 // movq	(%r8), %rcx
	LONG $0x08f98348         // cmpq	$8, %rcx
	JGE  BB1_2
	LONG $0xc057f8c5         // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5         // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5         // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	JLE  BB1_15
	LONG $0x0cc78348         // addq	$12, %rdi
	LONG $0x09048d4c         // leaq	(%rcx,%rcx), %r8
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	JMP  BB1_7

BB1_14:
	LONG $0x7e79c1c4; BYTE $0xca               // vmovd	%xmm1, %r10d
	LONG $0xe2ba0f41; BYTE $0x10               // btl	$16, %r10d
	LONG $0xffd28141; WORD $0x007f; BYTE $0x00 // adcl	$32767, %r10d                   ## imm = 0x7FFF
	LONG $0x10eac141                           // shrl	$16, %r10d
	LONG $0x14894666; BYTE $0x4a               // movw	%r10w, (%rdx,%r9,2)
	WORD $0xff49; BYTE $0xc1                   // incq	%r9
	WORD $0x014c; BYTE $0xc7                   // addq	%r8, %rdi
	WORD $0x394c; BYTE $0xc8                   // cmpq	%r9, %rax
	JE   BB1_27

BB1_7:
	LONG $0x57b70f44; BYTE $0xf4 // movzwl	-12(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x1eb70f44             // movzwl	(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xcb // vmovd	%r11d, %xmm1
	LONG $0xa969e2c4; BYTE $0xc8 // vfmadd213ss	%xmm0, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm1) + xmm0
	LONG $0x01f98348             // cmpq	$1, %rcx
	JE   BB1_14
	LONG $0x57b70f44; BYTE $0xf6 // movzwl	-10(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x5eb70f44; BYTE $0x02 // movzwl	2(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xdb // vmovd	%r11d, %xmm3
	LONG $0xb969e2c4; BYTE $0xcb // vfmadd231ss	%xmm3, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm3) + xmm1
	LONG $0x02f98348             // cmpq	$2, %rcx
	JE   BB1_14
	LONG $0x57b70f44; BYTE $0xf8 // movzwl	-8(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x5eb70f44; BYTE $0x04 // movzwl	4(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xdb // vmovd	%r11d, %xmm3
	LONG $0xb969e2c4; BYTE $0xcb // vfmadd231ss	%xmm3, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm3) + xmm1
	LONG $0x03f98348             // cmpq	$3, %rcx
	JE   BB1_14
	LONG $0x57b70f44; BYTE $0xfa // movzwl	-6(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x5eb70f44; BYTE $0x06 // movzwl	6(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xdb // vmovd	%r11d, %xmm3
	LONG $0xb969e2c4; BYTE $0xcb // vfmadd231ss	%xmm3, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm3) + xmm1
	LONG $0x04f98348             // cmpq	$4, %rcx
	JE   BB1_14
	LONG $0x57b70f44; BYTE $0xfc // movzwl	-4(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x5eb70f44; BYTE $0x08 // movzwl	8(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xdb // vmovd	%r11d, %xmm3
	LONG $0xb969e2c4; BYTE $0xcb // vfmadd231ss	%xmm3, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm3) + xmm1
	LONG $0x05f98348             // cmpq	$5, %rcx
	JE   BB1_14
	LONG $0x57b70f44; BYTE $0xfe // movzwl	-2(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x5eb70f44; BYTE $0x0a // movzwl	10(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xdb // vmovd	%r11d, %xmm3
	LONG $0xb969e2c4; BYTE $0xcb // vfmadd231ss	%xmm3, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm3) + xmm1
	LONG $0x06f98348             // cmpq	$6, %rcx
	JE   BB1_14
	LONG $0x17b70f44             // movzwl	(%rdi), %r10d
	LONG $0x10e2c141             // shll	$16, %r10d
	LONG $0x5eb70f44; BYTE $0x0c // movzwl	12(%rsi), %r11d
	LONG $0x10e3c141             // shll	$16, %r11d
	LONG $0x6e79c1c4; BYTE $0xd2 // vmovd	%r10d, %xmm2
	LONG $0x6e79c1c4; BYTE $0xdb // vmovd	%r11d, %xmm3
	LONG $0xb969e2c4; BYTE $0xcb // vfmadd231ss	%xmm3, %xmm2, %xmm1     ## xmm1 = (xmm2 * xmm3) + xmm1
	JMP  BB1_14

BB1_2:
	LONG $0xf8418d4c         // leaq	-8(%rcx), %r8
	WORD $0x894d; BYTE $0xc1 // movq	%r8, %r9
	LONG $0x03e9c149         // shrq	$3, %r9
	WORD $0xff49; BYTE $0xc1 // incq	%r9
	LONG $0xfee18349         // andq	$-2, %r9
	LONG $0x09148d4c         // leaq	(%rcx,%rcx), %r10
	WORD $0x3145; BYTE $0xdb // xorl	%r11d, %r11d
	WORD $0x8948; BYTE $0xfb // movq	%rdi, %rbx
	JMP  BB1_3

BB1_38:
	LONG $0xc57ef9c5               // vmovd	%xmm0, %ebp
	LONG $0x10e5ba0f               // btl	$16, %ebp
	LONG $0x7fffd581; WORD $0x0000 // adcl	$32767, %ebp                    ## imm = 0x7FFF
	WORD $0xedc1; BYTE $0x10       // shrl	$16, %ebp
	LONG $0x2c894266; BYTE $0x5a   // movw	%bp, (%rdx,%r11,2)
	WORD $0xff49; BYTE $0xc3       // incq	%r11
	WORD $0x014c; BYTE $0xd3       // addq	%r10, %rbx
	WORD $0x3949; BYTE $0xc3       // cmpq	%rax, %r11
	JE   BB1_27

BB1_3:
	LONG $0xc057f8c5               // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x0008bf41; WORD $0x0000 // movl	$8, %r15d
	LONG $0x08f88349               // cmpq	$8, %r8
	JAE  BB1_28
	WORD $0x3145; BYTE $0xf6       // xorl	%r14d, %r14d
	JMP  BB1_31

BB1_28:
	WORD $0x894d; BYTE $0xce // movq	%r9, %r14

BB1_29:
	LONG $0x337da2c4; WORD $0x7b4c; BYTE $0xf0 // vpmovzxwd	-16(%rbx,%r15,2), %ymm1 ## ymm1 = mem[0],zero,mem[1],zero,mem[2],zero,mem[3],zero,mem[4],zero,mem[5],zero,mem[6],zero,mem[7],zero
	LONG $0x337da2c4; WORD $0x7e54; BYTE $0xf0 // vpmovzxwd	-16(%rsi,%r15,2), %ymm2 ## ymm2 = mem[0],zero,mem[1],zero,mem[2],zero,mem[3],zero,mem[4],zero,mem[5],zero,mem[6],zero,mem[7],zero
	LONG $0xf172f5c5; BYTE $0x10               // vpslld	$16, %ymm1, %ymm1
	LONG $0xf272edc5; BYTE $0x10               // vpslld	$16, %ymm2, %ymm2
	LONG $0x337da2c4; WORD $0x7b1c             // vpmovzxwd	(%rbx,%r15,2), %ymm3    ## ymm3 = mem[0],zero,mem[1],zero,mem[2],zero,mem[3],zero,mem[4],zero,mem[5],zero,mem[6],zero,mem[7],zero
	LONG $0xa875e2c4; BYTE $0xd0               // vfmadd213ps	%ymm0, %ymm1, %ymm2     ## ymm2 = (ymm1 * ymm2) + ymm0
	LONG $0xf372f5c5; BYTE $0x10               // vpslld	$16, %ymm3, %ymm1
	LONG $0x337da2c4; WORD $0x7e04             // vpmovzxwd	(%rsi,%r15,2), %ymm0    ## ymm0 = mem[0],zero,mem[1],zero,mem[2],zero,mem[3],zero,mem[4],zero,mem[5],zero,mem[6],zero,mem[7],zero
	LONG $0xf072fdc5; BYTE $0x10               // vpslld	$16, %ymm0, %ymm0
	LONG $0xa875e2c4; BYTE $0xc2               // vfmadd213ps	%ymm2, %ymm1, %ymm0     ## ymm0 = (ymm1 * ymm0) + ymm2
	LONG $0x10c78349                           // addq	$16, %r15
	LONG $0xfec68349                           // addq	$-2, %r14
	JNE  BB1_29
	LONG $0xf8778d4d                           // leaq	-8(%r15), %r14

BB1_31:
	WORD $0x894d; BYTE $0xdc       // movq	%r11, %r12
	LONG $0xe1af0f4c               // imulq	%rcx, %r12
	LONG $0x67248d4e               // leaq	(%rdi,%r12,2), %r12
	LONG $0x08c0f641               // testb	$8, %r8b
	JNE  BB1_33
	LONG $0x337d82c4; WORD $0x740c // vpmovzxwd	(%r12,%r14,2), %ymm1    ## ymm1 = mem[0],zero,mem[1],zero,mem[2],zero,mem[3],zero,mem[4],zero,mem[5],zero,mem[6],zero,mem[7],zero
	LONG $0x337da2c4; WORD $0x7614 // vpmovzxwd	(%rsi,%r14,2), %ymm2    ## ymm2 = mem[0],zero,mem[1],zero,mem[2],zero,mem[3],zero,mem[4],zero,mem[5],zero,mem[6],zero,mem[7],zero
	LONG $0xf172f5c5; BYTE $0x10   // vpslld	$16, %ymm1, %ymm1
	LONG $0xf272edc5; BYTE $0x10   // vpslld	$16, %ymm2, %ymm2
	LONG $0xb875e2c4; BYTE $0xc2   // vfmadd231ps	%ymm2, %ymm1, %ymm0     ## ymm0 = (ymm1 * ymm2) + ymm0
	WORD $0x894d; BYTE $0xfe       // movq	%r15, %r14

BB1_33:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$1, %ymm0, %xmm1
	LONG $0xc158f8c5               // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5               // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5               // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x394c; BYTE $0xf1       // cmpq	%r14, %rcx
	JLE  BB1_38
	WORD $0xcd89                   // movl	%ecx, %ebp
	WORD $0x2944; BYTE $0xf5       // subl	%r14d, %ebp
	LONG $0x017e8d4d               // leaq	1(%r14), %r15
	LONG $0x01c5f640               // testb	$1, %bpl
	JE   BB1_36
	LONG $0x2cb70f43; BYTE $0x74   // movzwl	(%r12,%r14,2), %ebp
	WORD $0xe5c1; BYTE $0x10       // shll	$16, %ebp
	LONG $0x34b70f46; BYTE $0x76   // movzwl	(%rsi,%r14,2), %r14d
	LONG $0x10e6c141               // shll	$16, %r14d
	LONG $0xcd6ef9c5               // vmovd	%ebp, %xmm1
	LONG $0x6e79c1c4; BYTE $0xd6   // vmovd	%r14d, %xmm2
	LONG $0xb971e2c4; BYTE $0xc2   // vfmadd231ss	%xmm2, %xmm1, %xmm0     ## xmm0 = (xmm1 * xmm2) + xmm0
	WORD $0x894d; BYTE $0xfe       // movq	%r15, %r14

BB1_36:
	WORD $0x394c; BYTE $0xf9 // cmpq	%r15, %rcx
	JE   BB1_38

BB1_37:
	LONG $0x2cb70f42; BYTE $0x73   // movzwl	(%rbx,%r14,2), %ebp
	WORD $0xe5c1; BYTE $0x10       // shll	$16, %ebp
	LONG $0x3cb70f46; BYTE $0x76   // movzwl	(%rsi,%r14,2), %r15d
	LONG $0x10e7c141               // shll	$16, %r15d
	LONG $0xcd6ef9c5               // vmovd	%ebp, %xmm1
	LONG $0x6e79c1c4; BYTE $0xd7   // vmovd	%r15d, %xmm2
	LONG $0xa971e2c4; BYTE $0xd0   // vfmadd213ss	%xmm0, %xmm1, %xmm2     ## xmm2 = (xmm1 * xmm2) + xmm0
	LONG $0x6cb70f42; WORD $0x0273 // movzwl	2(%rbx,%r14,2), %ebp
	WORD $0xe5c1; BYTE $0x10       // shll	$16, %ebp
	LONG $0x7cb70f46; WORD $0x0276 // movzwl	2(%rsi,%r14,2), %r15d
	LONG $0x10e7c141               // shll	$16, %r15d
	LONG $0xcd6ef9c5               // vmovd	%ebp, %xmm1
	LONG $0x6e79c1c4; BYTE $0xc7   // vmovd	%r15d, %xmm0
	LONG $0xa971e2c4; BYTE $0xc2   // vfmadd213ss	%xmm2, %xmm1, %xmm0     ## xmm0 = (xmm1 * xmm0) + xmm2
	LONG $0x02c68349               // addq	$2, %r14
	WORD $0x3949; BYTE $0xce       // cmpq	%rcx, %r14
	JL   BB1_37
	JMP  BB1_38

BB1_15:
	LONG $0xc17ef9c5               // vmovd	%xmm0, %ecx
	LONG $0x10e1ba0f               // btl	$16, %ecx
	LONG $0x7fffd181; WORD $0x0000 // adcl	$32767, %ecx                    ## imm = 0x7FFF
	WORD $0xe9c1; BYTE $0x10       // shrl	$16, %ecx
	LONG $0x08f88348               // cmpq	$8, %rax
	JAE  BB1_18
	WORD $0xf631                   // xorl	%esi, %esi
	JMP  BB1_17

BB1_18:
	QUAD $0xffffffffffc0bf48; WORD $0x7fff // movabsq	$9223372036854775744, %rdi      ## imm = 0x7FFFFFFFFFFFFFC0
	LONG $0x40f88348                       // cmpq	$64, %rax
	JAE  BB1_20
	WORD $0xf631                           // xorl	%esi, %esi
	JMP  BB1_24

BB1_20:
	WORD $0x8948; BYTE $0xc6     // movq	%rax, %rsi
	WORD $0x2148; BYTE $0xfe     // andq	%rdi, %rsi
	LONG $0xc16ef9c5             // vmovd	%ecx, %xmm0
	LONG $0x797de2c4; BYTE $0xc0 // vpbroadcastw	%xmm0, %ymm0
	WORD $0x3145; BYTE $0xc0     // xorl	%r8d, %r8d

BB1_21:
	LONG $0x7f7ea1c4; WORD $0x4204             // vmovdqu	%ymm0, (%rdx,%r8,2)
	LONG $0x7f7ea1c4; WORD $0x4244; BYTE $0x20 // vmovdqu	%ymm0, 32(%rdx,%r8,2)
	LONG $0x7f7ea1c4; WORD $0x4244; BYTE $0x40 // vmovdqu	%ymm0, 64(%rdx,%r8,2)
	LONG $0x7f7ea1c4; WORD $0x4244; BYTE $0x60 // vmovdqu	%ymm0, 96(%rdx,%r8,2)
	LONG $0x40c08349                           // addq	$64, %r8
	WORD $0x394c; BYTE $0xc6                   // cmpq	%r8, %rsi
	JNE  BB1_21
	WORD $0x3948; BYTE $0xf0                   // cmpq	%rsi, %rax
	JE   BB1_27
	WORD $0x38a8                               // testb	$56, %al
	JE   BB1_17

BB1_24:
	WORD $0x8949; BYTE $0xf0     // movq	%rsi, %r8
	LONG $0x38c78348             // addq	$56, %rdi
	WORD $0x8948; BYTE $0xfe     // movq	%rdi, %rsi
	WORD $0x2148; BYTE $0xc6     // andq	%rax, %rsi
	LONG $0xc16ef9c5             // vmovd	%ecx, %xmm0
	LONG $0x7979e2c4; BYTE $0xc0 // vpbroadcastw	%xmm0, %xmm0

BB1_25:
	LONG $0x7f7aa1c4; WORD $0x4204 // vmovdqu	%xmm0, (%rdx,%r8,2)
	LONG $0x08c08349               // addq	$8, %r8
	WORD $0x394c; BYTE $0xc6       // cmpq	%r8, %rsi
	JNE  BB1_25
	JMP  BB1_26

BB1_17:
	LONG $0x720c8966         // movw	%cx, (%rdx,%rsi,2)
	WORD $0xff48; BYTE $0xc6 // incq	%rsi

BB1_26:
	WORD $0x3948; BYTE $0xf0 // cmpq	%rsi, %rax
	JNE  BB1_17

BB1_27:
	BYTE $0x5b               // popq	%rbx
	WORD $0x5c41             // popq	%r12
	WORD $0x5e41             // popq	%r14
	WORD $0x5f41             // popq	%r15
	BYTE $0x5d               // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT 路matvec_avx2_f32(SB), $0-40
	MOVQ m+0(FP), DI
	MOVQ v+8(FP), SI
	MOVQ result+16(FP), DX
	MOVQ prows+24(FP), CX
	MOVQ pcols+32(FP), R8
	BYTE $0x55               // pushq	%rbp
	WORD $0x5741             // pushq	%r15
	WORD $0x5641             // pushq	%r14
	WORD $0x5541             // pushq	%r13
	WORD $0x5441             // pushq	%r12
	BYTE $0x53               // pushq	%rbx
	BYTE $0x50               // pushq	%rax
	WORD $0x8b48; BYTE $0x01 // movq	(%rcx), %rax
	WORD $0x8548; BYTE $0xc0 // testq	%rax, %rax
	JLE  BB2_27
	WORD $0x8b49; BYTE $0x08 // movq	(%r8), %rcx
	LONG $0x08f98348         // cmpq	$8, %rcx
	JGE  BB2_2
	LONG $0xc057f8c5         // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5         // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5         // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	JLE  BB2_15
	LONG $0x18c78348         // addq	$24, %rdi
	QUAD $0x000000008d048d4c // leaq	(,%rcx,4), %r8
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	JMP  BB2_7

BB2_14:
	LONG $0x117aa1c4; WORD $0x8a0c // vmovss	%xmm1, (%rdx,%r9,4)
	WORD $0xff49; BYTE $0xc1       // incq	%r9
	WORD $0x014c; BYTE $0xc7       // addq	%r8, %rdi
	WORD $0x394c; BYTE $0xc8       // cmpq	%r9, %rax
	JE   BB2_27

BB2_7:
	LONG $0x4f10fac5; BYTE $0xe8   // vmovss	-24(%rdi), %xmm1                ## xmm1 = mem[0],zero,zero,zero
	LONG $0x9979e2c4; BYTE $0x0e   // vfmadd132ss	(%rsi), %xmm0, %xmm1    ## xmm1 = (xmm1 * mem) + xmm0
	LONG $0x01f98348               // cmpq	$1, %rcx
	JE   BB2_14
	LONG $0x5710fac5; BYTE $0xec   // vmovss	-20(%rdi), %xmm2                ## xmm2 = mem[0],zero,zero,zero
	LONG $0xb969e2c4; WORD $0x044e // vfmadd231ss	4(%rsi), %xmm2, %xmm1   ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x02f98348               // cmpq	$2, %rcx
	JE   BB2_14
	LONG $0x5710fac5; BYTE $0xf0   // vmovss	-16(%rdi), %xmm2                ## xmm2 = mem[0],zero,zero,zero
	LONG $0xb969e2c4; WORD $0x084e // vfmadd231ss	8(%rsi), %xmm2, %xmm1   ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x03f98348               // cmpq	$3, %rcx
	JE   BB2_14
	LONG $0x5710fac5; BYTE $0xf4   // vmovss	-12(%rdi), %xmm2                ## xmm2 = mem[0],zero,zero,zero
	LONG $0xb969e2c4; WORD $0x0c4e // vfmadd231ss	12(%rsi), %xmm2, %xmm1  ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x04f98348               // cmpq	$4, %rcx
	JE   BB2_14
	LONG $0x5710fac5; BYTE $0xf8   // vmovss	-8(%rdi), %xmm2                 ## xmm2 = mem[0],zero,zero,zero
	LONG $0xb969e2c4; WORD $0x104e // vfmadd231ss	16(%rsi), %xmm2, %xmm1  ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x05f98348               // cmpq	$5, %rcx
	JE   BB2_14
	LONG $0x5710fac5; BYTE $0xfc   // vmovss	-4(%rdi), %xmm2                 ## xmm2 = mem[0],zero,zero,zero
	LONG $0xb969e2c4; WORD $0x144e // vfmadd231ss	20(%rsi), %xmm2, %xmm1  ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x06f98348               // cmpq	$6, %rcx
	JE   BB2_14
	LONG $0x1710fac5               // vmovss	(%rdi), %xmm2                   ## xmm2 = mem[0],zero,zero,zero
	LONG $0xb969e2c4; WORD $0x184e // vfmadd231ss	24(%rsi), %xmm2, %xmm1  ## xmm1 = (xmm2 * mem) + xmm1
	JMP  BB2_14

BB2_2:
	LONG $0xf8418d4c         // leaq	-8(%rcx), %r8
	WORD $0x894d; BYTE $0xc2 // movq	%r8, %r10
	LONG $0x03eac149         // shrq	$3, %r10
	WORD $0xff49; BYTE $0xc2 // incq	%r10
	WORD $0x8945; BYTE $0xd1 // movl	%r10d, %r9d
	LONG $0x03e18341         // andl	$3, %r9d
	LONG $0xfce28349         // andq	$-4, %r10
	LONG $0x2414894c         // movq	%r10, (%rsp)                    ## 8-byte Spill
	LONG $0x605f8d4c         // leaq	96(%rdi), %r11
	QUAD $0x000000008d1c8d48 // leaq	(,%rcx,4), %rbx
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
	WORD $0x8949; BYTE $0xff // movq	%rdi, %r15
	JMP  BB2_3

BB2_40:
	LONG $0x117aa1c4; WORD $0xb204 // vmovss	%xmm0, (%rdx,%r14,4)
	WORD $0xff49; BYTE $0xc6       // incq	%r14
	WORD $0x0149; BYTE $0xdb       // addq	%rbx, %r11
	WORD $0x0149; BYTE $0xdf       // addq	%rbx, %r15
	WORD $0x3949; BYTE $0xc6       // cmpq	%rax, %r14
	JE   BB2_27

BB2_3:
	LONG $0xc057f8c5               // vxorps	%xmm0, %xmm0, %xmm0
	LONG $0x18f88349               // cmpq	$24, %r8
	JAE  BB2_28
	LONG $0x0008bd41; WORD $0x0000 // movl	$8, %r13d
	WORD $0x3145; BYTE $0xe4       // xorl	%r12d, %r12d
	WORD $0x854d; BYTE $0xc9       // testq	%r9, %r9
	JNE  BB2_32
	JMP  BB2_35

BB2_28:
	LONG $0x242c8b4c         // movq	(%rsp), %r13                    ## 8-byte Reload
	WORD $0x3145; BYTE $0xe4 // xorl	%r12d, %r12d

BB2_29:
	LONG $0x107c81c4; WORD $0xa34c; BYTE $0xa0 // vmovups	-96(%r11,%r12,4), %ymm1
	LONG $0x107c81c4; WORD $0xa354; BYTE $0xc0 // vmovups	-64(%r11,%r12,4), %ymm2
	LONG $0x107c81c4; WORD $0xa35c; BYTE $0xe0 // vmovups	-32(%r11,%r12,4), %ymm3
	LONG $0x987da2c4; WORD $0xa60c             // vfmadd132ps	(%rsi,%r12,4), %ymm0, %ymm1 ## ymm1 = (ymm1 * mem) + ymm0
	LONG $0xb86da2c4; WORD $0xa64c; BYTE $0x20 // vfmadd231ps	32(%rsi,%r12,4), %ymm2, %ymm1 ## ymm1 = (ymm2 * mem) + ymm1
	LONG $0x107c81c4; WORD $0xa314             // vmovups	(%r11,%r12,4), %ymm2
	LONG $0xb865a2c4; WORD $0xa64c; BYTE $0x40 // vfmadd231ps	64(%rsi,%r12,4), %ymm3, %ymm1 ## ymm1 = (ymm3 * mem) + ymm1
	LONG $0xc128fcc5                           // vmovaps	%ymm1, %ymm0
	LONG $0xb86da2c4; WORD $0xa644; BYTE $0x60 // vfmadd231ps	96(%rsi,%r12,4), %ymm2, %ymm0 ## ymm0 = (ymm2 * mem) + ymm0
	LONG $0x20c48349                           // addq	$32, %r12
	LONG $0xfcc58349                           // addq	$-4, %r13
	JNE  BB2_29
	LONG $0x246c8d4d; BYTE $0x08               // leaq	8(%r12), %r13
	WORD $0x854d; BYTE $0xc9                   // testq	%r9, %r9
	JE   BB2_35

BB2_32:
	WORD $0x894d; BYTE $0xf2 // movq	%r14, %r10
	LONG $0xd1af0f4c         // imulq	%rcx, %r10
	LONG $0x972c8d4a         // leaq	(%rdi,%r10,4), %rbp
	WORD $0x894d; BYTE $0xca // movq	%r9, %r10

BB2_33:
	LONG $0x107ca1c4; WORD $0xa54c; BYTE $0x00 // vmovups	(%rbp,%r12,4), %ymm1
	LONG $0xb875a2c4; WORD $0xa604             // vfmadd231ps	(%rsi,%r12,4), %ymm1, %ymm0 ## ymm0 = (ymm1 * mem) + ymm0
	WORD $0x894d; BYTE $0xec                   // movq	%r13, %r12
	LONG $0x08c58349                           // addq	$8, %r13
	WORD $0xff49; BYTE $0xca                   // decq	%r10
	JNE  BB2_33
	LONG $0xf8c58349                           // addq	$-8, %r13
	WORD $0x894d; BYTE $0xec                   // movq	%r13, %r12

BB2_35:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$1, %ymm0, %xmm1
	LONG $0xc158f8c5               // vaddps	%xmm1, %xmm0, %xmm0
	LONG $0xc07cfbc5               // vhaddps	%xmm0, %xmm0, %xmm0
	LONG $0xc07cfbc5               // vhaddps	%xmm0, %xmm0, %xmm0
	WORD $0x894d; BYTE $0xe5       // movq	%r12, %r13
	WORD $0x2949; BYTE $0xcd       // subq	%rcx, %r13
	JGE  BB2_40
	WORD $0xcd89                   // movl	%ecx, %ebp
	WORD $0x2944; BYTE $0xe5       // subl	%r12d, %ebp
	WORD $0xe583; BYTE $0x03       // andl	$3, %ebp
	JE   BB2_38

BB2_37:
	LONG $0x107a81c4; WORD $0xa70c // vmovss	(%r15,%r12,4), %xmm1            ## xmm1 = mem[0],zero,zero,zero
	LONG $0xb971a2c4; WORD $0xa604 // vfmadd231ss	(%rsi,%r12,4), %xmm1, %xmm0 ## xmm0 = (xmm1 * mem) + xmm0
	WORD $0xff49; BYTE $0xc4       // incq	%r12
	WORD $0xff48; BYTE $0xcd       // decq	%rbp
	JNE  BB2_37

BB2_38:
	LONG $0xfcfd8349 // cmpq	$-4, %r13
	JA   BB2_40

BB2_39:
	LONG $0x107a81c4; WORD $0xa70c             // vmovss	(%r15,%r12,4), %xmm1            ## xmm1 = mem[0],zero,zero,zero
	LONG $0x107a81c4; WORD $0xa754; BYTE $0x04 // vmovss	4(%r15,%r12,4), %xmm2           ## xmm2 = mem[0],zero,zero,zero
	LONG $0x9979a2c4; WORD $0xa60c             // vfmadd132ss	(%rsi,%r12,4), %xmm0, %xmm1 ## xmm1 = (xmm1 * mem) + xmm0
	LONG $0xb969a2c4; WORD $0xa64c; BYTE $0x04 // vfmadd231ss	4(%rsi,%r12,4), %xmm2, %xmm1 ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x107a81c4; WORD $0xa754; BYTE $0x08 // vmovss	8(%r15,%r12,4), %xmm2           ## xmm2 = mem[0],zero,zero,zero
	LONG $0x9971a2c4; WORD $0xa654; BYTE $0x08 // vfmadd132ss	8(%rsi,%r12,4), %xmm1, %xmm2 ## xmm2 = (xmm2 * mem) + xmm1
	LONG $0x107a81c4; WORD $0xa744; BYTE $0x0c // vmovss	12(%r15,%r12,4), %xmm0          ## xmm0 = mem[0],zero,zero,zero
	LONG $0x9969a2c4; WORD $0xa644; BYTE $0x0c // vfmadd132ss	12(%rsi,%r12,4), %xmm2, %xmm0 ## xmm0 = (xmm0 * mem) + xmm2
	LONG $0x04c48349                           // addq	$4, %r12
	WORD $0x3949; BYTE $0xcc                   // cmpq	%rcx, %r12
	JL   BB2_39
	JMP  BB2_40

BB2_15:
	LONG $0x03f88348 // cmpq	$3, %rax
	JA   BB2_18
	WORD $0xc931     // xorl	%ecx, %ecx
	JMP  BB2_17

BB2_18:
	QUAD $0xffffffffffe0be48; WORD $0x7fff // movabsq	$9223372036854775776, %rsi      ## imm = 0x7FFFFFFFFFFFFFE0
	LONG $0x20f88348                       // cmpq	$32, %rax
	JAE  BB2_20
	WORD $0xc931                           // xorl	%ecx, %ecx
	JMP  BB2_24

BB2_20:
	WORD $0x8948; BYTE $0xc1     // movq	%rax, %rcx
	WORD $0x2148; BYTE $0xf1     // andq	%rsi, %rcx
	LONG $0x187de2c4; BYTE $0xc8 // vbroadcastss	%xmm0, %ymm1
	WORD $0xff31                 // xorl	%edi, %edi

BB2_21:
	LONG $0x0c11fcc5; BYTE $0xba   // vmovups	%ymm1, (%rdx,%rdi,4)
	LONG $0x4c11fcc5; WORD $0x20ba // vmovups	%ymm1, 32(%rdx,%rdi,4)
	LONG $0x4c11fcc5; WORD $0x40ba // vmovups	%ymm1, 64(%rdx,%rdi,4)
	LONG $0x4c11fcc5; WORD $0x60ba // vmovups	%ymm1, 96(%rdx,%rdi,4)
	LONG $0x20c78348               // addq	$32, %rdi
	WORD $0x3948; BYTE $0xf9       // cmpq	%rdi, %rcx
	JNE  BB2_21
	WORD $0x3948; BYTE $0xc8       // cmpq	%rcx, %rax
	JE   BB2_27
	WORD $0x1ca8                   // testb	$28, %al
	JE   BB2_17

BB2_24:
	WORD $0x8948; BYTE $0xcf     // movq	%rcx, %rdi
	LONG $0x1cc68348             // addq	$28, %rsi
	WORD $0x8948; BYTE $0xf1     // movq	%rsi, %rcx
	WORD $0x2148; BYTE $0xc1     // andq	%rax, %rcx
	LONG $0x1879e2c4; BYTE $0xc8 // vbroadcastss	%xmm0, %xmm1

BB2_25:
	LONG $0x0c11f8c5; BYTE $0xba // vmovups	%xmm1, (%rdx,%rdi,4)
	LONG $0x04c78348             // addq	$4, %rdi
	WORD $0x3948; BYTE $0xf9     // cmpq	%rdi, %rcx
	JNE  BB2_25
	JMP  BB2_26

BB2_17:
	LONG $0x0411fac5; BYTE $0x8a // vmovss	%xmm0, (%rdx,%rcx,4)
	WORD $0xff48; BYTE $0xc1     // incq	%rcx

BB2_26:
	WORD $0x3948; BYTE $0xc8 // cmpq	%rcx, %rax
	JNE  BB2_17

BB2_27:
	LONG $0x08c48348         // addq	$8, %rsp
	BYTE $0x5b               // popq	%rbx
	WORD $0x5c41             // popq	%r12
	WORD $0x5d41             // popq	%r13
	WORD $0x5e41             // popq	%r14
	WORD $0x5f41             // popq	%r15
	BYTE $0x5d               // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET

TEXT 路matvec_avx2_f64(SB), $0-40
	MOVQ m+0(FP), DI
	MOVQ v+8(FP), SI
	MOVQ result+16(FP), DX
	MOVQ prows+24(FP), CX
	MOVQ pcols+32(FP), R8
	BYTE $0x55               // pushq	%rbp
	WORD $0x5741             // pushq	%r15
	WORD $0x5641             // pushq	%r14
	WORD $0x5541             // pushq	%r13
	WORD $0x5441             // pushq	%r12
	BYTE $0x53               // pushq	%rbx
	BYTE $0x50               // pushq	%rax
	WORD $0x8b48; BYTE $0x01 // movq	(%rcx), %rax
	WORD $0x8548; BYTE $0xc0 // testq	%rax, %rax
	JLE  BB3_23
	WORD $0x8b49; BYTE $0x08 // movq	(%r8), %rcx
	LONG $0x04f98348         // cmpq	$4, %rcx
	JGE  BB3_2
	LONG $0xc057f9c5         // vxorpd	%xmm0, %xmm0, %xmm0
	LONG $0xc07cf9c5         // vhaddpd	%xmm0, %xmm0, %xmm0
	WORD $0x8548; BYTE $0xc9 // testq	%rcx, %rcx
	JLE  BB3_11
	LONG $0x10c78348         // addq	$16, %rdi
	QUAD $0x00000000cd048d4c // leaq	(,%rcx,8), %r8
	WORD $0x3145; BYTE $0xc9 // xorl	%r9d, %r9d
	JMP  BB3_7

BB3_10:
	LONG $0x117ba1c4; WORD $0xca0c // vmovsd	%xmm1, (%rdx,%r9,8)
	WORD $0xff49; BYTE $0xc1       // incq	%r9
	WORD $0x014c; BYTE $0xc7       // addq	%r8, %rdi
	WORD $0x394c; BYTE $0xc8       // cmpq	%r9, %rax
	JE   BB3_23

BB3_7:
	LONG $0x4f10fbc5; BYTE $0xf0   // vmovsd	-16(%rdi), %xmm1                ## xmm1 = mem[0],zero
	LONG $0x99f9e2c4; BYTE $0x0e   // vfmadd132sd	(%rsi), %xmm0, %xmm1    ## xmm1 = (xmm1 * mem) + xmm0
	LONG $0x01f98348               // cmpq	$1, %rcx
	JE   BB3_10
	LONG $0x5710fbc5; BYTE $0xf8   // vmovsd	-8(%rdi), %xmm2                 ## xmm2 = mem[0],zero
	LONG $0xb9e9e2c4; WORD $0x084e // vfmadd231sd	8(%rsi), %xmm2, %xmm1   ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x02f98348               // cmpq	$2, %rcx
	JE   BB3_10
	LONG $0x1710fbc5               // vmovsd	(%rdi), %xmm2                   ## xmm2 = mem[0],zero
	LONG $0xb9e9e2c4; WORD $0x104e // vfmadd231sd	16(%rsi), %xmm2, %xmm1  ## xmm1 = (xmm2 * mem) + xmm1
	JMP  BB3_10

BB3_2:
	LONG $0xfc418d4c         // leaq	-4(%rcx), %r8
	WORD $0x894d; BYTE $0xc2 // movq	%r8, %r10
	LONG $0x02eac149         // shrq	$2, %r10
	WORD $0xff49; BYTE $0xc2 // incq	%r10
	WORD $0x8945; BYTE $0xd1 // movl	%r10d, %r9d
	LONG $0x03e18341         // andl	$3, %r9d
	LONG $0xfce28349         // andq	$-4, %r10
	LONG $0x2414894c         // movq	%r10, (%rsp)                    ## 8-byte Spill
	LONG $0x605f8d4c         // leaq	96(%rdi), %r11
	QUAD $0x00000000cd1c8d48 // leaq	(,%rcx,8), %rbx
	WORD $0x3145; BYTE $0xf6 // xorl	%r14d, %r14d
	WORD $0x8949; BYTE $0xff // movq	%rdi, %r15
	JMP  BB3_3

BB3_36:
	LONG $0x117ba1c4; WORD $0xf204 // vmovsd	%xmm0, (%rdx,%r14,8)
	WORD $0xff49; BYTE $0xc6       // incq	%r14
	WORD $0x0149; BYTE $0xdb       // addq	%rbx, %r11
	WORD $0x0149; BYTE $0xdf       // addq	%rbx, %r15
	WORD $0x3949; BYTE $0xc6       // cmpq	%rax, %r14
	JE   BB3_23

BB3_3:
	LONG $0xc057f9c5               // vxorpd	%xmm0, %xmm0, %xmm0
	LONG $0x0cf88349               // cmpq	$12, %r8
	JAE  BB3_24
	LONG $0x0004bd41; WORD $0x0000 // movl	$4, %r13d
	WORD $0x3145; BYTE $0xe4       // xorl	%r12d, %r12d
	WORD $0x854d; BYTE $0xc9       // testq	%r9, %r9
	JNE  BB3_28
	JMP  BB3_31

BB3_24:
	LONG $0x242c8b4c         // movq	(%rsp), %r13                    ## 8-byte Reload
	WORD $0x3145; BYTE $0xe4 // xorl	%r12d, %r12d

BB3_25:
	LONG $0x107d81c4; WORD $0xe34c; BYTE $0xa0 // vmovupd	-96(%r11,%r12,8), %ymm1
	LONG $0x107d81c4; WORD $0xe354; BYTE $0xc0 // vmovupd	-64(%r11,%r12,8), %ymm2
	LONG $0x107d81c4; WORD $0xe35c; BYTE $0xe0 // vmovupd	-32(%r11,%r12,8), %ymm3
	LONG $0x98fda2c4; WORD $0xe60c             // vfmadd132pd	(%rsi,%r12,8), %ymm0, %ymm1 ## ymm1 = (ymm1 * mem) + ymm0
	LONG $0xb8eda2c4; WORD $0xe64c; BYTE $0x20 // vfmadd231pd	32(%rsi,%r12,8), %ymm2, %ymm1 ## ymm1 = (ymm2 * mem) + ymm1
	LONG $0x107d81c4; WORD $0xe314             // vmovupd	(%r11,%r12,8), %ymm2
	LONG $0xb8e5a2c4; WORD $0xe64c; BYTE $0x40 // vfmadd231pd	64(%rsi,%r12,8), %ymm3, %ymm1 ## ymm1 = (ymm3 * mem) + ymm1
	LONG $0xc128fdc5                           // vmovapd	%ymm1, %ymm0
	LONG $0xb8eda2c4; WORD $0xe644; BYTE $0x60 // vfmadd231pd	96(%rsi,%r12,8), %ymm2, %ymm0 ## ymm0 = (ymm2 * mem) + ymm0
	LONG $0x10c48349                           // addq	$16, %r12
	LONG $0xfcc58349                           // addq	$-4, %r13
	JNE  BB3_25
	LONG $0x246c8d4d; BYTE $0x04               // leaq	4(%r12), %r13
	WORD $0x854d; BYTE $0xc9                   // testq	%r9, %r9
	JE   BB3_31

BB3_28:
	WORD $0x894d; BYTE $0xf2 // movq	%r14, %r10
	LONG $0xd1af0f4c         // imulq	%rcx, %r10
	LONG $0xd72c8d4a         // leaq	(%rdi,%r10,8), %rbp
	WORD $0x894d; BYTE $0xca // movq	%r9, %r10

BB3_29:
	LONG $0x107da1c4; WORD $0xe54c; BYTE $0x00 // vmovupd	(%rbp,%r12,8), %ymm1
	LONG $0xb8f5a2c4; WORD $0xe604             // vfmadd231pd	(%rsi,%r12,8), %ymm1, %ymm0 ## ymm0 = (ymm1 * mem) + ymm0
	WORD $0x894d; BYTE $0xec                   // movq	%r13, %r12
	LONG $0x04c58349                           // addq	$4, %r13
	WORD $0xff49; BYTE $0xca                   // decq	%r10
	JNE  BB3_29
	LONG $0xfcc58349                           // addq	$-4, %r13
	WORD $0x894d; BYTE $0xec                   // movq	%r13, %r12

BB3_31:
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$1, %ymm0, %xmm1
	LONG $0xc158f9c5               // vaddpd	%xmm1, %xmm0, %xmm0
	LONG $0xc07cf9c5               // vhaddpd	%xmm0, %xmm0, %xmm0
	WORD $0x894d; BYTE $0xe5       // movq	%r12, %r13
	WORD $0x2949; BYTE $0xcd       // subq	%rcx, %r13
	JGE  BB3_36
	WORD $0xcd89                   // movl	%ecx, %ebp
	WORD $0x2944; BYTE $0xe5       // subl	%r12d, %ebp
	WORD $0xe583; BYTE $0x03       // andl	$3, %ebp
	JE   BB3_34

BB3_33:
	LONG $0x107b81c4; WORD $0xe70c // vmovsd	(%r15,%r12,8), %xmm1            ## xmm1 = mem[0],zero
	LONG $0xb9f1a2c4; WORD $0xe604 // vfmadd231sd	(%rsi,%r12,8), %xmm1, %xmm0 ## xmm0 = (xmm1 * mem) + xmm0
	WORD $0xff49; BYTE $0xc4       // incq	%r12
	WORD $0xff48; BYTE $0xcd       // decq	%rbp
	JNE  BB3_33

BB3_34:
	LONG $0xfcfd8349 // cmpq	$-4, %r13
	JA   BB3_36

BB3_35:
	LONG $0x107b81c4; WORD $0xe70c             // vmovsd	(%r15,%r12,8), %xmm1            ## xmm1 = mem[0],zero
	LONG $0x107b81c4; WORD $0xe754; BYTE $0x08 // vmovsd	8(%r15,%r12,8), %xmm2           ## xmm2 = mem[0],zero
	LONG $0x99f9a2c4; WORD $0xe60c             // vfmadd132sd	(%rsi,%r12,8), %xmm0, %xmm1 ## xmm1 = (xmm1 * mem) + xmm0
	LONG $0xb9e9a2c4; WORD $0xe64c; BYTE $0x08 // vfmadd231sd	8(%rsi,%r12,8), %xmm2, %xmm1 ## xmm1 = (xmm2 * mem) + xmm1
	LONG $0x107b81c4; WORD $0xe754; BYTE $0x10 // vmovsd	16(%r15,%r12,8), %xmm2          ## xmm2 = mem[0],zero
	LONG $0x99f1a2c4; WORD $0xe654; BYTE $0x10 // vfmadd132sd	16(%rsi,%r12,8), %xmm1, %xmm2 ## xmm2 = (xmm2 * mem) + xmm1
	LONG $0x107b81c4; WORD $0xe744; BYTE $0x18 // vmovsd	24(%r15,%r12,8), %xmm0          ## xmm0 = mem[0],zero
	LONG $0x99e9a2c4; WORD $0xe644; BYTE $0x18 // vfmadd132sd	24(%rsi,%r12,8), %xmm2, %xmm0 ## xmm0 = (xmm0 * mem) + xmm2
	LONG $0x04c48349                           // addq	$4, %r12
	WORD $0x3949; BYTE $0xcc                   // cmpq	%rcx, %r12
	JL   BB3_35
	JMP  BB3_36

BB3_11:
	LONG $0x03f88348 // cmpq	$3, %rax
	JA   BB3_13
	WORD $0xc931     // xorl	%ecx, %ecx
	JMP  BB3_22

BB3_13:
	QUAD $0xfffffffffffcbe48; WORD $0x7fff // movabsq	$9223372036854775804, %rsi      ## imm = 0x7FFFFFFFFFFFFFFC
	LONG $0x197de2c4; BYTE $0xc8           // vbroadcastsd	%xmm0, %ymm1
	LONG $0x10f88348                       // cmpq	$16, %rax
	JAE  BB3_15
	WORD $0xc931                           // xorl	%ecx, %ecx
	JMP  BB3_19

BB3_15:
	LONG $0xf44e8d48         // leaq	-12(%rsi), %rcx
	WORD $0x2148; BYTE $0xc1 // andq	%rax, %rcx
	WORD $0xff31             // xorl	%edi, %edi

BB3_16:
	LONG $0x0c11fdc5; BYTE $0xfa   // vmovupd	%ymm1, (%rdx,%rdi,8)
	LONG $0x4c11fdc5; WORD $0x20fa // vmovupd	%ymm1, 32(%rdx,%rdi,8)
	LONG $0x4c11fdc5; WORD $0x40fa // vmovupd	%ymm1, 64(%rdx,%rdi,8)
	LONG $0x4c11fdc5; WORD $0x60fa // vmovupd	%ymm1, 96(%rdx,%rdi,8)
	LONG $0x10c78348               // addq	$16, %rdi
	WORD $0x3948; BYTE $0xf9       // cmpq	%rdi, %rcx
	JNE  BB3_16
	WORD $0x3948; BYTE $0xc8       // cmpq	%rcx, %rax
	JE   BB3_23
	WORD $0x0ca8                   // testb	$12, %al
	JE   BB3_22

BB3_19:
	WORD $0x2148; BYTE $0xc6 // andq	%rax, %rsi

BB3_20:
	LONG $0x0c11fdc5; BYTE $0xca // vmovupd	%ymm1, (%rdx,%rcx,8)
	LONG $0x04c18348             // addq	$4, %rcx
	WORD $0x3948; BYTE $0xce     // cmpq	%rcx, %rsi
	JNE  BB3_20
	WORD $0x8948; BYTE $0xf1     // movq	%rsi, %rcx
	WORD $0x3948; BYTE $0xf0     // cmpq	%rsi, %rax
	JE   BB3_23

BB3_22:
	LONG $0x0411fbc5; BYTE $0xca // vmovsd	%xmm0, (%rdx,%rcx,8)
	WORD $0xff48; BYTE $0xc1     // incq	%rcx
	WORD $0x3948; BYTE $0xc8     // cmpq	%rcx, %rax
	JNE  BB3_22

BB3_23:
	LONG $0x08c48348         // addq	$8, %rsp
	BYTE $0x5b               // popq	%rbx
	WORD $0x5c41             // popq	%r12
	WORD $0x5d41             // popq	%r13
	WORD $0x5e41             // popq	%r14
	WORD $0x5f41             // popq	%r15
	BYTE $0x5d               // popq	%rbp
	WORD $0xf8c5; BYTE $0x77 // vzeroupper
	RET
