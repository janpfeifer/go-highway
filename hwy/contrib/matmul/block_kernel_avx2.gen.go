// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package matmul

import (
	"simd/archsimd"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
)

func BaseBlockMulAdd_avx2_Float16(aT []hwy.Float16, b []hwy.Float16, c []hwy.Float16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd: C slice too short")
	}
	lanes := 8
	for i := range blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAdd_avx2_BFloat16(aT []hwy.BFloat16, b []hwy.BFloat16, c []hwy.BFloat16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd: C slice too short")
	}
	lanes := 8
	for i := range blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastBFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToBFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAdd_avx2(aT []float32, b []float32, c []float32, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd: C slice too short")
	}
	lanes := 8
	for i := range blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat32x8(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAdd_avx2_Float64(aT []float64, b []float64, c []float64, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd: C slice too short")
	}
	lanes := 4
	for i := range blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat64x4(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAdd2_avx2_Float16(aT []hwy.Float16, b []hwy.Float16, c []hwy.Float16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd2: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd2: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd2: C slice too short")
	}
	lanes := 8
	var i int
	for i = 0; i+1 < blockDim; i += 2 {
		cRow0Start := i * blockDim
		cRow1Start := (i + 1) * blockDim
		for k := range blockDim {
			a0k := aT[k*blockDim+i]
			a1k := aT[k*blockDim+i+1]
			vA0 := asm.BroadcastFloat16x8AVX2(uint16(a0k))
			vA1 := asm.BroadcastFloat16x8AVX2(uint16(a1k))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC0 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0Start+j:][0]))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0Start+j:]))), len(c[cRow0Start+j:])))
				vC1 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1Start+j:][0]))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1Start+j:]))), len(c[cRow1Start+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRow0Start+j] = hwy.Float32ToFloat16(c[cRow0Start+j].Float32() + a0k.Float32()*b[bRowStart+j].Float32())
				c[cRow1Start+j] = hwy.Float32ToFloat16(c[cRow1Start+j].Float32() + a1k.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
	if i < blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAdd2_avx2_BFloat16(aT []hwy.BFloat16, b []hwy.BFloat16, c []hwy.BFloat16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd2: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd2: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd2: C slice too short")
	}
	lanes := 8
	var i int
	for i = 0; i+1 < blockDim; i += 2 {
		cRow0Start := i * blockDim
		cRow1Start := (i + 1) * blockDim
		for k := range blockDim {
			a0k := aT[k*blockDim+i]
			a1k := aT[k*blockDim+i+1]
			vA0 := asm.BroadcastBFloat16x8AVX2(uint16(a0k))
			vA1 := asm.BroadcastBFloat16x8AVX2(uint16(a1k))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC0 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0Start+j:][0]))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0Start+j:]))), len(c[cRow0Start+j:])))
				vC1 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1Start+j:][0]))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1Start+j:]))), len(c[cRow1Start+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRow0Start+j] = hwy.Float32ToBFloat16(c[cRow0Start+j].Float32() + a0k.Float32()*b[bRowStart+j].Float32())
				c[cRow1Start+j] = hwy.Float32ToBFloat16(c[cRow1Start+j].Float32() + a1k.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
	if i < blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastBFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToBFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAdd2_avx2(aT []float32, b []float32, c []float32, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd2: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd2: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd2: C slice too short")
	}
	lanes := 8
	var i int
	for i = 0; i+1 < blockDim; i += 2 {
		cRow0Start := i * blockDim
		cRow1Start := (i + 1) * blockDim
		for k := range blockDim {
			a0k := aT[k*blockDim+i]
			a1k := aT[k*blockDim+i+1]
			vA0 := archsimd.BroadcastFloat32x8(a0k)
			vA1 := archsimd.BroadcastFloat32x8(a1k)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vC0 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow0Start+j])))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.Store((*[8]float32)(unsafe.Pointer(&c[cRow0Start+j])))
				vC1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow1Start+j])))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.Store((*[8]float32)(unsafe.Pointer(&c[cRow1Start+j])))
			}
			for ; j < blockDim; j++ {
				c[cRow0Start+j] += a0k * b[bRowStart+j]
				c[cRow1Start+j] += a1k * b[bRowStart+j]
			}
		}
	}
	if i < blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat32x8(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAdd2_avx2_Float64(aT []float64, b []float64, c []float64, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd2: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd2: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd2: C slice too short")
	}
	lanes := 4
	var i int
	for i = 0; i+1 < blockDim; i += 2 {
		cRow0Start := i * blockDim
		cRow1Start := (i + 1) * blockDim
		for k := range blockDim {
			a0k := aT[k*blockDim+i]
			a1k := aT[k*blockDim+i+1]
			vA0 := archsimd.BroadcastFloat64x4(a0k)
			vA1 := archsimd.BroadcastFloat64x4(a1k)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vC0 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow0Start+j])))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.Store((*[4]float64)(unsafe.Pointer(&c[cRow0Start+j])))
				vC1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow1Start+j])))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.Store((*[4]float64)(unsafe.Pointer(&c[cRow1Start+j])))
			}
			for ; j < blockDim; j++ {
				c[cRow0Start+j] += a0k * b[bRowStart+j]
				c[cRow1Start+j] += a1k * b[bRowStart+j]
			}
		}
	}
	if i < blockDim {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat64x4(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAddRegBlocked_avx2_Float16(aT []hwy.Float16, b []hwy.Float16, c []hwy.Float16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: C slice too short")
	}
	lanes := 8
	mr := 4
	nr := lanes * 2
	var i int
	for i = 0; i+mr <= blockDim; i += mr {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		var j int
		for j = 0; j+nr <= blockDim; j += nr {
			acc00 := asm.ZeroFloat16x8AVX2()
			acc01 := asm.ZeroFloat16x8AVX2()
			acc10 := asm.ZeroFloat16x8AVX2()
			acc11 := asm.ZeroFloat16x8AVX2()
			acc20 := asm.ZeroFloat16x8AVX2()
			acc21 := asm.ZeroFloat16x8AVX2()
			acc30 := asm.ZeroFloat16x8AVX2()
			acc31 := asm.ZeroFloat16x8AVX2()
			for k := range blockDim {
				aTRowK := k * blockDim
				a0k := aT[aTRowK+i]
				a1k := aT[aTRowK+i+1]
				a2k := aT[aTRowK+i+2]
				a3k := aT[aTRowK+i+3]
				vA0 := asm.BroadcastFloat16x8AVX2(uint16(a0k))
				vA1 := asm.BroadcastFloat16x8AVX2(uint16(a1k))
				vA2 := asm.BroadcastFloat16x8AVX2(uint16(a2k))
				vA3 := asm.BroadcastFloat16x8AVX2(uint16(a3k))
				bRowStart := k * blockDim
				vB0 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vB1 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j+lanes:][0]))
				acc00 = vA0.MulAdd(vB0, acc00)
				acc01 = vA0.MulAdd(vB1, acc01)
				acc10 = vA1.MulAdd(vB0, acc10)
				acc11 = vA1.MulAdd(vB1, acc11)
				acc20 = vA2.MulAdd(vB0, acc20)
				acc21 = vA2.MulAdd(vB1, acc21)
				acc30 = vA3.MulAdd(vB0, acc30)
				acc31 = vA3.MulAdd(vB1, acc31)
			}
			vC := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j:][0]))
			vC = vC.Add(acc00)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j:]))), len(c[cRow0+j:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j+lanes:][0]))
			vC = vC.Add(acc01)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j+lanes:]))), len(c[cRow0+j+lanes:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j:][0]))
			vC = vC.Add(acc10)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j:]))), len(c[cRow1+j:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j+lanes:][0]))
			vC = vC.Add(acc11)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j+lanes:]))), len(c[cRow1+j+lanes:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j:][0]))
			vC = vC.Add(acc20)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j:]))), len(c[cRow2+j:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j+lanes:][0]))
			vC = vC.Add(acc21)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j+lanes:]))), len(c[cRow2+j+lanes:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j:][0]))
			vC = vC.Add(acc30)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j:]))), len(c[cRow3+j:])))
			vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j+lanes:][0]))
			vC = vC.Add(acc31)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j+lanes:]))), len(c[cRow3+j+lanes:])))
		}
		for ; j < blockDim; j += lanes {
			acc0 := asm.ZeroFloat16x8AVX2()
			acc1 := asm.ZeroFloat16x8AVX2()
			acc2 := asm.ZeroFloat16x8AVX2()
			acc3 := asm.ZeroFloat16x8AVX2()
			remaining := blockDim - j
			if remaining >= lanes {
				for k := range blockDim {
					aTRowK := k * blockDim
					vA0 := asm.BroadcastFloat16x8AVX2(uint16(aT[aTRowK+i]))
					vA1 := asm.BroadcastFloat16x8AVX2(uint16(aT[aTRowK+i+1]))
					vA2 := asm.BroadcastFloat16x8AVX2(uint16(aT[aTRowK+i+2]))
					vA3 := asm.BroadcastFloat16x8AVX2(uint16(aT[aTRowK+i+3]))
					vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[k*blockDim+j:][0]))
					acc0 = vA0.MulAdd(vB, acc0)
					acc1 = vA1.MulAdd(vB, acc1)
					acc2 = vA2.MulAdd(vB, acc2)
					acc3 = vA3.MulAdd(vB, acc3)
				}
				vC := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j:][0]))
				vC = vC.Add(acc0)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j:]))), len(c[cRow0+j:])))
				vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j:][0]))
				vC = vC.Add(acc1)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j:]))), len(c[cRow1+j:])))
				vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j:][0]))
				vC = vC.Add(acc2)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j:]))), len(c[cRow2+j:])))
				vC = asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j:][0]))
				vC = vC.Add(acc3)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j:]))), len(c[cRow3+j:])))
			} else {
				for jj := j; jj < blockDim; jj++ {
					for k := range blockDim {
						aTRowK := k * blockDim
						bkj := b[k*blockDim+jj]
						c[cRow0+jj] = hwy.Float32ToFloat16(c[cRow0+jj].Float32() + aT[aTRowK+i].Float32()*bkj.Float32())
						c[cRow1+jj] = hwy.Float32ToFloat16(c[cRow1+jj].Float32() + aT[aTRowK+i+1].Float32()*bkj.Float32())
						c[cRow2+jj] = hwy.Float32ToFloat16(c[cRow2+jj].Float32() + aT[aTRowK+i+2].Float32()*bkj.Float32())
						c[cRow3+jj] = hwy.Float32ToFloat16(c[cRow3+jj].Float32() + aT[aTRowK+i+3].Float32()*bkj.Float32())
					}
				}
				break
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAddRegBlocked_avx2_BFloat16(aT []hwy.BFloat16, b []hwy.BFloat16, c []hwy.BFloat16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: C slice too short")
	}
	lanes := 8
	mr := 4
	nr := lanes * 2
	var i int
	for i = 0; i+mr <= blockDim; i += mr {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		var j int
		for j = 0; j+nr <= blockDim; j += nr {
			acc00 := asm.ZeroBFloat16x8AVX2()
			acc01 := asm.ZeroBFloat16x8AVX2()
			acc10 := asm.ZeroBFloat16x8AVX2()
			acc11 := asm.ZeroBFloat16x8AVX2()
			acc20 := asm.ZeroBFloat16x8AVX2()
			acc21 := asm.ZeroBFloat16x8AVX2()
			acc30 := asm.ZeroBFloat16x8AVX2()
			acc31 := asm.ZeroBFloat16x8AVX2()
			for k := range blockDim {
				aTRowK := k * blockDim
				a0k := aT[aTRowK+i]
				a1k := aT[aTRowK+i+1]
				a2k := aT[aTRowK+i+2]
				a3k := aT[aTRowK+i+3]
				vA0 := asm.BroadcastBFloat16x8AVX2(uint16(a0k))
				vA1 := asm.BroadcastBFloat16x8AVX2(uint16(a1k))
				vA2 := asm.BroadcastBFloat16x8AVX2(uint16(a2k))
				vA3 := asm.BroadcastBFloat16x8AVX2(uint16(a3k))
				bRowStart := k * blockDim
				vB0 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vB1 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j+lanes:][0]))
				acc00 = vA0.MulAdd(vB0, acc00)
				acc01 = vA0.MulAdd(vB1, acc01)
				acc10 = vA1.MulAdd(vB0, acc10)
				acc11 = vA1.MulAdd(vB1, acc11)
				acc20 = vA2.MulAdd(vB0, acc20)
				acc21 = vA2.MulAdd(vB1, acc21)
				acc30 = vA3.MulAdd(vB0, acc30)
				acc31 = vA3.MulAdd(vB1, acc31)
			}
			vC := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j:][0]))
			vC = vC.Add(acc00)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j:]))), len(c[cRow0+j:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j+lanes:][0]))
			vC = vC.Add(acc01)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j+lanes:]))), len(c[cRow0+j+lanes:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j:][0]))
			vC = vC.Add(acc10)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j:]))), len(c[cRow1+j:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j+lanes:][0]))
			vC = vC.Add(acc11)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j+lanes:]))), len(c[cRow1+j+lanes:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j:][0]))
			vC = vC.Add(acc20)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j:]))), len(c[cRow2+j:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j+lanes:][0]))
			vC = vC.Add(acc21)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j+lanes:]))), len(c[cRow2+j+lanes:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j:][0]))
			vC = vC.Add(acc30)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j:]))), len(c[cRow3+j:])))
			vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j+lanes:][0]))
			vC = vC.Add(acc31)
			vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j+lanes:]))), len(c[cRow3+j+lanes:])))
		}
		for ; j < blockDim; j += lanes {
			acc0 := asm.ZeroBFloat16x8AVX2()
			acc1 := asm.ZeroBFloat16x8AVX2()
			acc2 := asm.ZeroBFloat16x8AVX2()
			acc3 := asm.ZeroBFloat16x8AVX2()
			remaining := blockDim - j
			if remaining >= lanes {
				for k := range blockDim {
					aTRowK := k * blockDim
					vA0 := asm.BroadcastBFloat16x8AVX2(uint16(aT[aTRowK+i]))
					vA1 := asm.BroadcastBFloat16x8AVX2(uint16(aT[aTRowK+i+1]))
					vA2 := asm.BroadcastBFloat16x8AVX2(uint16(aT[aTRowK+i+2]))
					vA3 := asm.BroadcastBFloat16x8AVX2(uint16(aT[aTRowK+i+3]))
					vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[k*blockDim+j:][0]))
					acc0 = vA0.MulAdd(vB, acc0)
					acc1 = vA1.MulAdd(vB, acc1)
					acc2 = vA2.MulAdd(vB, acc2)
					acc3 = vA3.MulAdd(vB, acc3)
				}
				vC := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j:][0]))
				vC = vC.Add(acc0)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j:]))), len(c[cRow0+j:])))
				vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j:][0]))
				vC = vC.Add(acc1)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j:]))), len(c[cRow1+j:])))
				vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j:][0]))
				vC = vC.Add(acc2)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j:]))), len(c[cRow2+j:])))
				vC = asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j:][0]))
				vC = vC.Add(acc3)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j:]))), len(c[cRow3+j:])))
			} else {
				for jj := j; jj < blockDim; jj++ {
					for k := range blockDim {
						aTRowK := k * blockDim
						bkj := b[k*blockDim+jj]
						c[cRow0+jj] = hwy.Float32ToBFloat16(c[cRow0+jj].Float32() + aT[aTRowK+i].Float32()*bkj.Float32())
						c[cRow1+jj] = hwy.Float32ToBFloat16(c[cRow1+jj].Float32() + aT[aTRowK+i+1].Float32()*bkj.Float32())
						c[cRow2+jj] = hwy.Float32ToBFloat16(c[cRow2+jj].Float32() + aT[aTRowK+i+2].Float32()*bkj.Float32())
						c[cRow3+jj] = hwy.Float32ToBFloat16(c[cRow3+jj].Float32() + aT[aTRowK+i+3].Float32()*bkj.Float32())
					}
				}
				break
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastBFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToBFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAddRegBlocked_avx2(aT []float32, b []float32, c []float32, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: C slice too short")
	}
	lanes := 8
	mr := 4
	nr := lanes * 2
	var i int
	for i = 0; i+mr <= blockDim; i += mr {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		var j int
		for j = 0; j+nr <= blockDim; j += nr {
			acc00 := archsimd.BroadcastFloat32x8(0)
			acc01 := archsimd.BroadcastFloat32x8(0)
			acc10 := archsimd.BroadcastFloat32x8(0)
			acc11 := archsimd.BroadcastFloat32x8(0)
			acc20 := archsimd.BroadcastFloat32x8(0)
			acc21 := archsimd.BroadcastFloat32x8(0)
			acc30 := archsimd.BroadcastFloat32x8(0)
			acc31 := archsimd.BroadcastFloat32x8(0)
			for k := range blockDim {
				aTRowK := k * blockDim
				a0k := aT[aTRowK+i]
				a1k := aT[aTRowK+i+1]
				a2k := aT[aTRowK+i+2]
				a3k := aT[aTRowK+i+3]
				vA0 := archsimd.BroadcastFloat32x8(a0k)
				vA1 := archsimd.BroadcastFloat32x8(a1k)
				vA2 := archsimd.BroadcastFloat32x8(a2k)
				vA3 := archsimd.BroadcastFloat32x8(a3k)
				bRowStart := k * blockDim
				vB0 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vB1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j+lanes])))
				acc00 = vA0.MulAdd(vB0, acc00)
				acc01 = vA0.MulAdd(vB1, acc01)
				acc10 = vA1.MulAdd(vB0, acc10)
				acc11 = vA1.MulAdd(vB1, acc11)
				acc20 = vA2.MulAdd(vB0, acc20)
				acc21 = vA2.MulAdd(vB1, acc21)
				acc30 = vA3.MulAdd(vB0, acc30)
				acc31 = vA3.MulAdd(vB1, acc31)
			}
			vC := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow0+j])))
			vC = vC.Add(acc00)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow0+j])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow0+j+lanes])))
			vC = vC.Add(acc01)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow0+j+lanes])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow1+j])))
			vC = vC.Add(acc10)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow1+j])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow1+j+lanes])))
			vC = vC.Add(acc11)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow1+j+lanes])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow2+j])))
			vC = vC.Add(acc20)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow2+j])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow2+j+lanes])))
			vC = vC.Add(acc21)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow2+j+lanes])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow3+j])))
			vC = vC.Add(acc30)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow3+j])))
			vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow3+j+lanes])))
			vC = vC.Add(acc31)
			vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow3+j+lanes])))
		}
		for ; j < blockDim; j += lanes {
			acc0 := archsimd.BroadcastFloat32x8(0)
			acc1 := archsimd.BroadcastFloat32x8(0)
			acc2 := archsimd.BroadcastFloat32x8(0)
			acc3 := archsimd.BroadcastFloat32x8(0)
			remaining := blockDim - j
			if remaining >= lanes {
				for k := range blockDim {
					aTRowK := k * blockDim
					vA0 := archsimd.BroadcastFloat32x8(aT[aTRowK+i])
					vA1 := archsimd.BroadcastFloat32x8(aT[aTRowK+i+1])
					vA2 := archsimd.BroadcastFloat32x8(aT[aTRowK+i+2])
					vA3 := archsimd.BroadcastFloat32x8(aT[aTRowK+i+3])
					vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[k*blockDim+j])))
					acc0 = vA0.MulAdd(vB, acc0)
					acc1 = vA1.MulAdd(vB, acc1)
					acc2 = vA2.MulAdd(vB, acc2)
					acc3 = vA3.MulAdd(vB, acc3)
				}
				vC := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow0+j])))
				vC = vC.Add(acc0)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow0+j])))
				vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow1+j])))
				vC = vC.Add(acc1)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow1+j])))
				vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow2+j])))
				vC = vC.Add(acc2)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow2+j])))
				vC = archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow3+j])))
				vC = vC.Add(acc3)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRow3+j])))
			} else {
				for jj := j; jj < blockDim; jj++ {
					for k := range blockDim {
						aTRowK := k * blockDim
						bkj := b[k*blockDim+jj]
						c[cRow0+jj] += aT[aTRowK+i] * bkj
						c[cRow1+jj] += aT[aTRowK+i+1] * bkj
						c[cRow2+jj] += aT[aTRowK+i+2] * bkj
						c[cRow3+jj] += aT[aTRowK+i+3] * bkj
					}
				}
				break
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat32x8(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAddRegBlocked_avx2_Float64(aT []float64, b []float64, c []float64, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAddRegBlocked: C slice too short")
	}
	lanes := 4
	mr := 4
	nr := lanes * 2
	var i int
	for i = 0; i+mr <= blockDim; i += mr {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		var j int
		for j = 0; j+nr <= blockDim; j += nr {
			acc00 := archsimd.BroadcastFloat64x4(0)
			acc01 := archsimd.BroadcastFloat64x4(0)
			acc10 := archsimd.BroadcastFloat64x4(0)
			acc11 := archsimd.BroadcastFloat64x4(0)
			acc20 := archsimd.BroadcastFloat64x4(0)
			acc21 := archsimd.BroadcastFloat64x4(0)
			acc30 := archsimd.BroadcastFloat64x4(0)
			acc31 := archsimd.BroadcastFloat64x4(0)
			for k := range blockDim {
				aTRowK := k * blockDim
				a0k := aT[aTRowK+i]
				a1k := aT[aTRowK+i+1]
				a2k := aT[aTRowK+i+2]
				a3k := aT[aTRowK+i+3]
				vA0 := archsimd.BroadcastFloat64x4(a0k)
				vA1 := archsimd.BroadcastFloat64x4(a1k)
				vA2 := archsimd.BroadcastFloat64x4(a2k)
				vA3 := archsimd.BroadcastFloat64x4(a3k)
				bRowStart := k * blockDim
				vB0 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vB1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j+lanes])))
				acc00 = vA0.MulAdd(vB0, acc00)
				acc01 = vA0.MulAdd(vB1, acc01)
				acc10 = vA1.MulAdd(vB0, acc10)
				acc11 = vA1.MulAdd(vB1, acc11)
				acc20 = vA2.MulAdd(vB0, acc20)
				acc21 = vA2.MulAdd(vB1, acc21)
				acc30 = vA3.MulAdd(vB0, acc30)
				acc31 = vA3.MulAdd(vB1, acc31)
			}
			vC := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow0+j])))
			vC = vC.Add(acc00)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow0+j])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow0+j+lanes])))
			vC = vC.Add(acc01)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow0+j+lanes])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow1+j])))
			vC = vC.Add(acc10)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow1+j])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow1+j+lanes])))
			vC = vC.Add(acc11)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow1+j+lanes])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow2+j])))
			vC = vC.Add(acc20)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow2+j])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow2+j+lanes])))
			vC = vC.Add(acc21)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow2+j+lanes])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow3+j])))
			vC = vC.Add(acc30)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow3+j])))
			vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow3+j+lanes])))
			vC = vC.Add(acc31)
			vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow3+j+lanes])))
		}
		for ; j < blockDim; j += lanes {
			acc0 := archsimd.BroadcastFloat64x4(0)
			acc1 := archsimd.BroadcastFloat64x4(0)
			acc2 := archsimd.BroadcastFloat64x4(0)
			acc3 := archsimd.BroadcastFloat64x4(0)
			remaining := blockDim - j
			if remaining >= lanes {
				for k := range blockDim {
					aTRowK := k * blockDim
					vA0 := archsimd.BroadcastFloat64x4(aT[aTRowK+i])
					vA1 := archsimd.BroadcastFloat64x4(aT[aTRowK+i+1])
					vA2 := archsimd.BroadcastFloat64x4(aT[aTRowK+i+2])
					vA3 := archsimd.BroadcastFloat64x4(aT[aTRowK+i+3])
					vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[k*blockDim+j])))
					acc0 = vA0.MulAdd(vB, acc0)
					acc1 = vA1.MulAdd(vB, acc1)
					acc2 = vA2.MulAdd(vB, acc2)
					acc3 = vA3.MulAdd(vB, acc3)
				}
				vC := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow0+j])))
				vC = vC.Add(acc0)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow0+j])))
				vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow1+j])))
				vC = vC.Add(acc1)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow1+j])))
				vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow2+j])))
				vC = vC.Add(acc2)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow2+j])))
				vC = archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow3+j])))
				vC = vC.Add(acc3)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRow3+j])))
			} else {
				for jj := j; jj < blockDim; jj++ {
					for k := range blockDim {
						aTRowK := k * blockDim
						bkj := b[k*blockDim+jj]
						c[cRow0+jj] += aT[aTRowK+i] * bkj
						c[cRow1+jj] += aT[aTRowK+i+1] * bkj
						c[cRow2+jj] += aT[aTRowK+i+2] * bkj
						c[cRow3+jj] += aT[aTRowK+i+3] * bkj
					}
				}
				break
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat64x4(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAdd4_avx2_Float16(aT []hwy.Float16, b []hwy.Float16, c []hwy.Float16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd4: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd4: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd4: C slice too short")
	}
	lanes := 8
	var i int
	for i = 0; i+3 < blockDim; i += 4 {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		for k := range blockDim {
			aTRowK := k * blockDim
			a0k := aT[aTRowK+i]
			a1k := aT[aTRowK+i+1]
			a2k := aT[aTRowK+i+2]
			a3k := aT[aTRowK+i+3]
			vA0 := asm.BroadcastFloat16x8AVX2(uint16(a0k))
			vA1 := asm.BroadcastFloat16x8AVX2(uint16(a1k))
			vA2 := asm.BroadcastFloat16x8AVX2(uint16(a2k))
			vA3 := asm.BroadcastFloat16x8AVX2(uint16(a3k))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC0 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j:][0]))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j:]))), len(c[cRow0+j:])))
				vC1 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j:][0]))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j:]))), len(c[cRow1+j:])))
				vC2 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j:][0]))
				vC2 = vA2.MulAdd(vB, vC2)
				vC2.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j:]))), len(c[cRow2+j:])))
				vC3 := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j:][0]))
				vC3 = vA3.MulAdd(vB, vC3)
				vC3.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j:]))), len(c[cRow3+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRow0+j] = hwy.Float32ToFloat16(c[cRow0+j].Float32() + a0k.Float32()*b[bRowStart+j].Float32())
				c[cRow1+j] = hwy.Float32ToFloat16(c[cRow1+j].Float32() + a1k.Float32()*b[bRowStart+j].Float32())
				c[cRow2+j] = hwy.Float32ToFloat16(c[cRow2+j].Float32() + a2k.Float32()*b[bRowStart+j].Float32())
				c[cRow3+j] = hwy.Float32ToFloat16(c[cRow3+j].Float32() + a3k.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAdd4_avx2_BFloat16(aT []hwy.BFloat16, b []hwy.BFloat16, c []hwy.BFloat16, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd4: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd4: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd4: C slice too short")
	}
	lanes := 8
	var i int
	for i = 0; i+3 < blockDim; i += 4 {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		for k := range blockDim {
			aTRowK := k * blockDim
			a0k := aT[aTRowK+i]
			a1k := aT[aTRowK+i+1]
			a2k := aT[aTRowK+i+2]
			a3k := aT[aTRowK+i+3]
			vA0 := asm.BroadcastBFloat16x8AVX2(uint16(a0k))
			vA1 := asm.BroadcastBFloat16x8AVX2(uint16(a1k))
			vA2 := asm.BroadcastBFloat16x8AVX2(uint16(a2k))
			vA3 := asm.BroadcastBFloat16x8AVX2(uint16(a3k))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC0 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow0+j:][0]))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow0+j:]))), len(c[cRow0+j:])))
				vC1 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow1+j:][0]))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow1+j:]))), len(c[cRow1+j:])))
				vC2 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow2+j:][0]))
				vC2 = vA2.MulAdd(vB, vC2)
				vC2.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow2+j:]))), len(c[cRow2+j:])))
				vC3 := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRow3+j:][0]))
				vC3 = vA3.MulAdd(vB, vC3)
				vC3.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRow3+j:]))), len(c[cRow3+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRow0+j] = hwy.Float32ToBFloat16(c[cRow0+j].Float32() + a0k.Float32()*b[bRowStart+j].Float32())
				c[cRow1+j] = hwy.Float32ToBFloat16(c[cRow1+j].Float32() + a1k.Float32()*b[bRowStart+j].Float32())
				c[cRow2+j] = hwy.Float32ToBFloat16(c[cRow2+j].Float32() + a2k.Float32()*b[bRowStart+j].Float32())
				c[cRow3+j] = hwy.Float32ToBFloat16(c[cRow3+j].Float32() + a3k.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := asm.BroadcastBFloat16x8AVX2(uint16(aik))
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&b[bRowStart+j:][0]))
				vC := asm.LoadBFloat16x8AVX2Ptr(unsafe.Pointer(&c[cRowStart+j:][0]))
				vC = vA.MulAdd(vB, vC)
				vC.StoreSlice(unsafe.Slice((*uint16)(unsafe.Pointer(unsafe.SliceData(c[cRowStart+j:]))), len(c[cRowStart+j:])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] = hwy.Float32ToBFloat16(c[cRowStart+j].Float32() + aik.Float32()*b[bRowStart+j].Float32())
			}
		}
	}
}

func BaseBlockMulAdd4_avx2(aT []float32, b []float32, c []float32, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd4: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd4: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd4: C slice too short")
	}
	lanes := 8
	var i int
	for i = 0; i+3 < blockDim; i += 4 {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		for k := range blockDim {
			aTRowK := k * blockDim
			a0k := aT[aTRowK+i]
			a1k := aT[aTRowK+i+1]
			a2k := aT[aTRowK+i+2]
			a3k := aT[aTRowK+i+3]
			vA0 := archsimd.BroadcastFloat32x8(a0k)
			vA1 := archsimd.BroadcastFloat32x8(a1k)
			vA2 := archsimd.BroadcastFloat32x8(a2k)
			vA3 := archsimd.BroadcastFloat32x8(a3k)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vC0 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow0+j])))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.Store((*[8]float32)(unsafe.Pointer(&c[cRow0+j])))
				vC1 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow1+j])))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.Store((*[8]float32)(unsafe.Pointer(&c[cRow1+j])))
				vC2 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow2+j])))
				vC2 = vA2.MulAdd(vB, vC2)
				vC2.Store((*[8]float32)(unsafe.Pointer(&c[cRow2+j])))
				vC3 := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRow3+j])))
				vC3 = vA3.MulAdd(vB, vC3)
				vC3.Store((*[8]float32)(unsafe.Pointer(&c[cRow3+j])))
			}
			for ; j < blockDim; j++ {
				c[cRow0+j] += a0k * b[bRowStart+j]
				c[cRow1+j] += a1k * b[bRowStart+j]
				c[cRow2+j] += a2k * b[bRowStart+j]
				c[cRow3+j] += a3k * b[bRowStart+j]
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat32x8(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat32x8((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[8]float32)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}

func BaseBlockMulAdd4_avx2_Float64(aT []float64, b []float64, c []float64, blockDim int) {
	if len(aT) < blockDim*blockDim {
		panic("BlockMulAdd4: aT slice too short")
	}
	if len(b) < blockDim*blockDim {
		panic("BlockMulAdd4: B slice too short")
	}
	if len(c) < blockDim*blockDim {
		panic("BlockMulAdd4: C slice too short")
	}
	lanes := 4
	var i int
	for i = 0; i+3 < blockDim; i += 4 {
		cRow0 := i * blockDim
		cRow1 := (i + 1) * blockDim
		cRow2 := (i + 2) * blockDim
		cRow3 := (i + 3) * blockDim
		for k := range blockDim {
			aTRowK := k * blockDim
			a0k := aT[aTRowK+i]
			a1k := aT[aTRowK+i+1]
			a2k := aT[aTRowK+i+2]
			a3k := aT[aTRowK+i+3]
			vA0 := archsimd.BroadcastFloat64x4(a0k)
			vA1 := archsimd.BroadcastFloat64x4(a1k)
			vA2 := archsimd.BroadcastFloat64x4(a2k)
			vA3 := archsimd.BroadcastFloat64x4(a3k)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vC0 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow0+j])))
				vC0 = vA0.MulAdd(vB, vC0)
				vC0.Store((*[4]float64)(unsafe.Pointer(&c[cRow0+j])))
				vC1 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow1+j])))
				vC1 = vA1.MulAdd(vB, vC1)
				vC1.Store((*[4]float64)(unsafe.Pointer(&c[cRow1+j])))
				vC2 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow2+j])))
				vC2 = vA2.MulAdd(vB, vC2)
				vC2.Store((*[4]float64)(unsafe.Pointer(&c[cRow2+j])))
				vC3 := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRow3+j])))
				vC3 = vA3.MulAdd(vB, vC3)
				vC3.Store((*[4]float64)(unsafe.Pointer(&c[cRow3+j])))
			}
			for ; j < blockDim; j++ {
				c[cRow0+j] += a0k * b[bRowStart+j]
				c[cRow1+j] += a1k * b[bRowStart+j]
				c[cRow2+j] += a2k * b[bRowStart+j]
				c[cRow3+j] += a3k * b[bRowStart+j]
			}
		}
	}
	for ; i < blockDim; i++ {
		cRowStart := i * blockDim
		for k := range blockDim {
			aik := aT[k*blockDim+i]
			vA := archsimd.BroadcastFloat64x4(aik)
			bRowStart := k * blockDim
			var j int
			for j = 0; j+lanes <= blockDim; j += lanes {
				vB := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&b[bRowStart+j])))
				vC := archsimd.LoadFloat64x4((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
				vC = vA.MulAdd(vB, vC)
				vC.Store((*[4]float64)(unsafe.Pointer(&c[cRowStart+j])))
			}
			for ; j < blockDim; j++ {
				c[cRowStart+j] += aik * b[bRowStart+j]
			}
		}
	}
}
