// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build amd64 && goexperiment.simd

package matmul

import (
	stdmath "math"
	"simd/archsimd"
	"sync"
	"unsafe"

	"github.com/ajroetker/go-highway/hwy/contrib/math"
)

// Hoisted constants - lazily initialized on first use to avoid init-time crashes
var (
	BaseFusedInt4MatMulGELUApprox_AVX512_coeff_f32 archsimd.Float32x16
	BaseFusedInt4MatMulGELU_AVX512_half_f32        archsimd.Float32x16
	BaseFusedInt4MatMulGELU_AVX512_invSqrt2_f32    archsimd.Float32x16
	BaseFusedInt4MatMulGELU_AVX512_one_f32         archsimd.Float32x16
	BaseFusedNF4MatMulGELUApprox_AVX512_coeff_f32  archsimd.Float32x16
	BaseFusedNF4MatMulGELU_AVX512_half_f32         archsimd.Float32x16
	BaseFusedNF4MatMulGELU_AVX512_invSqrt2_f32     archsimd.Float32x16
	BaseFusedNF4MatMulGELU_AVX512_one_f32          archsimd.Float32x16
	_matmulFusedNf4ActHoistOnce                    sync.Once
)

func _matmulFusedNf4ActInitHoistedConstants() {
	_matmulFusedNf4ActHoistOnce.Do(func() {
		BaseFusedInt4MatMulGELUApprox_AVX512_coeff_f32 = archsimd.BroadcastFloat32x16(float32(1.702))
		BaseFusedInt4MatMulGELU_AVX512_half_f32 = archsimd.BroadcastFloat32x16(float32(0.5))
		BaseFusedInt4MatMulGELU_AVX512_invSqrt2_f32 = archsimd.BroadcastFloat32x16(float32(0.7071067811865476))
		BaseFusedInt4MatMulGELU_AVX512_one_f32 = archsimd.BroadcastFloat32x16(float32(1.0))
		BaseFusedNF4MatMulGELUApprox_AVX512_coeff_f32 = archsimd.BroadcastFloat32x16(float32(1.702))
		BaseFusedNF4MatMulGELU_AVX512_half_f32 = archsimd.BroadcastFloat32x16(float32(0.5))
		BaseFusedNF4MatMulGELU_AVX512_invSqrt2_f32 = archsimd.BroadcastFloat32x16(float32(0.7071067811865476))
		BaseFusedNF4MatMulGELU_AVX512_one_f32 = archsimd.BroadcastFloat32x16(float32(1.0))
	})
}

func BaseFusedNF4MatMulSiLU_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var quantIdx int
					if weightIdx%2 == 0 {
						quantIdx = int(packed[packedIdx] & 0x0F)
					} else {
						quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = nf4LookupTable[quantIdx] * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			sig := math.BaseSigmoidVec_avx512(acc)
			acc = acc.Mul(sig)
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var quantIdx int
				if weightIdx%2 == 0 {
					quantIdx = int(packed[packedIdx] & 0x0F)
				} else {
					quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := nf4LookupTable[quantIdx] * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = sum / (1.0 + float32(stdmath.Exp(float64(-sum))))
		}
	}
}

func BaseFusedNF4MatMulGELU_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var quantIdx int
					if weightIdx%2 == 0 {
						quantIdx = int(packed[packedIdx] & 0x0F)
					} else {
						quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = nf4LookupTable[quantIdx] * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			invSqrt2 := BaseFusedNF4MatMulGELU_AVX512_invSqrt2_f32
			half := BaseFusedNF4MatMulGELU_AVX512_half_f32
			one := BaseFusedNF4MatMulGELU_AVX512_one_f32
			scaled := acc.Mul(invSqrt2)
			erfVal := math.BaseErfVec_avx512(scaled)
			acc = acc.Mul(half.Mul(one.Add(erfVal)))
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var quantIdx int
				if weightIdx%2 == 0 {
					quantIdx = int(packed[packedIdx] & 0x0F)
				} else {
					quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := nf4LookupTable[quantIdx] * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = sum * 0.5 * (1.0 + float32(stdmath.Erf(float64(sum)*0.7071067811865476)))
		}
	}
}

func BaseFusedNF4MatMulGELUApprox_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var quantIdx int
					if weightIdx%2 == 0 {
						quantIdx = int(packed[packedIdx] & 0x0F)
					} else {
						quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = nf4LookupTable[quantIdx] * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			coeff := BaseFusedNF4MatMulGELUApprox_AVX512_coeff_f32
			scaled := acc.Mul(coeff)
			sig := math.BaseSigmoidVec_avx512(scaled)
			acc = acc.Mul(sig)
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var quantIdx int
				if weightIdx%2 == 0 {
					quantIdx = int(packed[packedIdx] & 0x0F)
				} else {
					quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := nf4LookupTable[quantIdx] * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = sum / (1.0 + float32(stdmath.Exp(float64(-1.702*sum))))
		}
	}
}

func BaseFusedNF4MatMulReLU_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var quantIdx int
					if weightIdx%2 == 0 {
						quantIdx = int(packed[packedIdx] & 0x0F)
					} else {
						quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = nf4LookupTable[quantIdx] * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			acc = acc.Max(archsimd.BroadcastFloat32x16(0))
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var quantIdx int
				if weightIdx%2 == 0 {
					quantIdx = int(packed[packedIdx] & 0x0F)
				} else {
					quantIdx = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := nf4LookupTable[quantIdx] * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = float32(stdmath.Max(0, float64(sum)))
		}
	}
}

func BaseFusedInt4MatMulSiLU_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var unsignedVal int
					if weightIdx%2 == 0 {
						unsignedVal = int(packed[packedIdx] & 0x0F)
					} else {
						unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = float32(unsignedVal-8) * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			sig := math.BaseSigmoidVec_avx512(acc)
			acc = acc.Mul(sig)
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var unsignedVal int
				if weightIdx%2 == 0 {
					unsignedVal = int(packed[packedIdx] & 0x0F)
				} else {
					unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := float32(unsignedVal-8) * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = sum / (1.0 + float32(stdmath.Exp(float64(-sum))))
		}
	}
}

func BaseFusedInt4MatMulGELU_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var unsignedVal int
					if weightIdx%2 == 0 {
						unsignedVal = int(packed[packedIdx] & 0x0F)
					} else {
						unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = float32(unsignedVal-8) * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			invSqrt2 := BaseFusedInt4MatMulGELU_AVX512_invSqrt2_f32
			half := BaseFusedInt4MatMulGELU_AVX512_half_f32
			one := BaseFusedInt4MatMulGELU_AVX512_one_f32
			scaled := acc.Mul(invSqrt2)
			erfVal := math.BaseErfVec_avx512(scaled)
			acc = acc.Mul(half.Mul(one.Add(erfVal)))
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var unsignedVal int
				if weightIdx%2 == 0 {
					unsignedVal = int(packed[packedIdx] & 0x0F)
				} else {
					unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := float32(unsignedVal-8) * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = sum * 0.5 * (1.0 + float32(stdmath.Erf(float64(sum)*0.7071067811865476)))
		}
	}
}

func BaseFusedInt4MatMulGELUApprox_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var unsignedVal int
					if weightIdx%2 == 0 {
						unsignedVal = int(packed[packedIdx] & 0x0F)
					} else {
						unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = float32(unsignedVal-8) * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			coeff := BaseFusedInt4MatMulGELUApprox_AVX512_coeff_f32
			scaled := acc.Mul(coeff)
			sig := math.BaseSigmoidVec_avx512(scaled)
			acc = acc.Mul(sig)
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var unsignedVal int
				if weightIdx%2 == 0 {
					unsignedVal = int(packed[packedIdx] & 0x0F)
				} else {
					unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := float32(unsignedVal-8) * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = sum / (1.0 + float32(stdmath.Exp(float64(-1.702*sum))))
		}
	}
}

func BaseFusedInt4MatMulReLU_avx512(input []float32, packed []uint8, scales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	dequantBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			acc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					var unsignedVal int
					if weightIdx%2 == 0 {
						unsignedVal = int(packed[packedIdx] & 0x0F)
					} else {
						unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
					}
					groupIdx := colIdx / groupSize
					scale := scales[scaleBase+groupIdx]
					dequantBuf[lane] = float32(unsignedVal-8) * scale
				}
				weights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&dequantBuf[0])))
				acc = inputVal.MulAdd(weights, acc)
			}
			acc = acc.Max(archsimd.BroadcastFloat32x16(0))
			acc.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			sum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var unsignedVal int
				if weightIdx%2 == 0 {
					unsignedVal = int(packed[packedIdx] & 0x0F)
				} else {
					unsignedVal = int((packed[packedIdx] >> 4) & 0x0F)
				}
				scale := scales[k*numGroups+groupIdx]
				weight := float32(unsignedVal-8) * scale
				sum += inputRow[k] * weight
			}
			outputRow[n] = float32(stdmath.Max(0, float64(sum)))
		}
	}
}

func BaseFusedNF4MatMulSwiGLU_avx512(input []float32, gatePacked []uint8, gateScales []float32, upPacked []uint8, upScales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	gateBuf := [16]float32{}
	upBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			gateAcc := archsimd.BroadcastFloat32x16(0)
			upAcc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					groupIdx := colIdx / groupSize
					var gateQuantIdx int
					if weightIdx%2 == 0 {
						gateQuantIdx = int(gatePacked[packedIdx] & 0x0F)
					} else {
						gateQuantIdx = int((gatePacked[packedIdx] >> 4) & 0x0F)
					}
					gateScale := gateScales[scaleBase+groupIdx]
					gateBuf[lane] = nf4LookupTable[gateQuantIdx] * gateScale
					var upQuantIdx int
					if weightIdx%2 == 0 {
						upQuantIdx = int(upPacked[packedIdx] & 0x0F)
					} else {
						upQuantIdx = int((upPacked[packedIdx] >> 4) & 0x0F)
					}
					upScale := upScales[scaleBase+groupIdx]
					upBuf[lane] = nf4LookupTable[upQuantIdx] * upScale
				}
				gateWeights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&gateBuf[0])))
				upWeights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&upBuf[0])))
				gateAcc = inputVal.MulAdd(gateWeights, gateAcc)
				upAcc = inputVal.MulAdd(upWeights, upAcc)
			}
			gateSilu := gateAcc.Mul(math.BaseSigmoidVec_avx512(gateAcc))
			result := gateSilu.Mul(upAcc)
			result.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			gateSum := float32(0)
			upSum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var gateQuantIdx int
				if weightIdx%2 == 0 {
					gateQuantIdx = int(gatePacked[packedIdx] & 0x0F)
				} else {
					gateQuantIdx = int((gatePacked[packedIdx] >> 4) & 0x0F)
				}
				gateScale := gateScales[k*numGroups+groupIdx]
				gateSum += inputRow[k] * nf4LookupTable[gateQuantIdx] * gateScale
				var upQuantIdx int
				if weightIdx%2 == 0 {
					upQuantIdx = int(upPacked[packedIdx] & 0x0F)
				} else {
					upQuantIdx = int((upPacked[packedIdx] >> 4) & 0x0F)
				}
				upScale := upScales[k*numGroups+groupIdx]
				upSum += inputRow[k] * nf4LookupTable[upQuantIdx] * upScale
			}
			gateSilu := gateSum / (1.0 + float32(stdmath.Exp(float64(-gateSum))))
			outputRow[n] = gateSilu * upSum
		}
	}
}

func BaseFusedInt4MatMulSwiGLU_avx512(input []float32, gatePacked []uint8, gateScales []float32, upPacked []uint8, upScales []float32, output []float32, M int, K int, N int, groupSize int) {
	_matmulFusedNf4ActInitHoistedConstants()
	if M == 0 || K == 0 || N == 0 {
		return
	}
	numGroups := (N + groupSize - 1) / groupSize
	lanes := 16
	gateBuf := [16]float32{}
	upBuf := [16]float32{}
	for m := 0; m < M; m++ {
		inputRow := input[m*K : (m+1)*K]
		outputRow := output[m*N : (m+1)*N]
		var n int
		for n = 0; n+lanes <= N; n += lanes {
			gateAcc := archsimd.BroadcastFloat32x16(0)
			upAcc := archsimd.BroadcastFloat32x16(0)
			for k := 0; k < K; k++ {
				inputVal := archsimd.BroadcastFloat32x16(inputRow[k])
				baseIdx := k * N
				scaleBase := k * numGroups
				for lane := 0; lane < lanes; lane++ {
					colIdx := n + lane
					weightIdx := baseIdx + colIdx
					packedIdx := weightIdx / 2
					groupIdx := colIdx / groupSize
					var gateUnsigned int
					if weightIdx%2 == 0 {
						gateUnsigned = int(gatePacked[packedIdx] & 0x0F)
					} else {
						gateUnsigned = int((gatePacked[packedIdx] >> 4) & 0x0F)
					}
					gateScale := gateScales[scaleBase+groupIdx]
					gateBuf[lane] = float32(gateUnsigned-8) * gateScale
					var upUnsigned int
					if weightIdx%2 == 0 {
						upUnsigned = int(upPacked[packedIdx] & 0x0F)
					} else {
						upUnsigned = int((upPacked[packedIdx] >> 4) & 0x0F)
					}
					upScale := upScales[scaleBase+groupIdx]
					upBuf[lane] = float32(upUnsigned-8) * upScale
				}
				gateWeights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&gateBuf[0])))
				upWeights := archsimd.LoadFloat32x16((*[16]float32)(unsafe.Pointer(&upBuf[0])))
				gateAcc = inputVal.MulAdd(gateWeights, gateAcc)
				upAcc = inputVal.MulAdd(upWeights, upAcc)
			}
			gateSilu := gateAcc.Mul(math.BaseSigmoidVec_avx512(gateAcc))
			result := gateSilu.Mul(upAcc)
			result.Store((*[16]float32)(unsafe.Pointer(&outputRow[n])))
		}
		for ; n < N; n++ {
			groupIdx := n / groupSize
			gateSum := float32(0)
			upSum := float32(0)
			for k := 0; k < K; k++ {
				weightIdx := k*N + n
				packedIdx := weightIdx / 2
				var gateUnsigned int
				if weightIdx%2 == 0 {
					gateUnsigned = int(gatePacked[packedIdx] & 0x0F)
				} else {
					gateUnsigned = int((gatePacked[packedIdx] >> 4) & 0x0F)
				}
				gateScale := gateScales[k*numGroups+groupIdx]
				gateSum += inputRow[k] * float32(gateUnsigned-8) * gateScale
				var upUnsigned int
				if weightIdx%2 == 0 {
					upUnsigned = int(upPacked[packedIdx] & 0x0F)
				} else {
					upUnsigned = int((upPacked[packedIdx] >> 4) & 0x0F)
				}
				upScale := upScales[k*numGroups+groupIdx]
				upSum += inputRow[k] * float32(upUnsigned-8) * upScale
			}
			gateSilu := gateSum / (1.0 + float32(stdmath.Exp(float64(-gateSum))))
			outputRow[n] = gateSilu * upSum
		}
	}
}
