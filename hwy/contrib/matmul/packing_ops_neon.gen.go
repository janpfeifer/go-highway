// Code generated by github.com/ajroetker/go-highway/cmd/hwygen. DO NOT EDIT.

//go:build arm64

package matmul

import (
	"unsafe"

	"github.com/ajroetker/go-highway/hwy"
	"github.com/ajroetker/go-highway/hwy/asm"
)

func BasePackRHSFast_neon_Float16(b []hwy.Float16, packed []hwy.Float16, n int, rowStart int, colStart int, panelK int, panelCols int, nr int) {
	lanes := 8
	dstIdx := 0
	for stripColIdx := 0; stripColIdx < panelCols; stripColIdx += nr {
		validCols := min(nr, panelCols-stripColIdx)
		baseCol := colStart + stripColIdx
		if validCols == nr && nr >= lanes && nr%lanes == 0 {
			for kk := range panelK {
				srcIdx := (rowStart+kk)*n + baseCol
				for c := 0; c < nr; c += lanes {
					v := asm.LoadFloat16x8Ptr(unsafe.Pointer(&b[srcIdx+c:][0]))
					v.StorePtr(unsafe.Pointer(&packed[dstIdx+c:][0]))
				}
				dstIdx += nr
			}
			continue
		}
		for kk := range panelK {
			srcIdx := (rowStart+kk)*n + baseCol
			for c := range validCols {
				packed[dstIdx] = hwy.Float32ToFloat16(b[srcIdx+c].Float32())
				dstIdx++
			}
			for c := validCols; c < nr; c++ {
				packed[dstIdx] = hwy.Float32ToFloat16(0)
				dstIdx++
			}
		}
	}
}

func BasePackRHSFast_neon_BFloat16(b []hwy.BFloat16, packed []hwy.BFloat16, n int, rowStart int, colStart int, panelK int, panelCols int, nr int) {
	lanes := 8
	dstIdx := 0
	for stripColIdx := 0; stripColIdx < panelCols; stripColIdx += nr {
		validCols := min(nr, panelCols-stripColIdx)
		baseCol := colStart + stripColIdx
		if validCols == nr && nr >= lanes && nr%lanes == 0 {
			for kk := range panelK {
				srcIdx := (rowStart+kk)*n + baseCol
				for c := 0; c < nr; c += lanes {
					v := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&b[srcIdx+c:][0]))
					v.StorePtr(unsafe.Pointer(&packed[dstIdx+c:][0]))
				}
				dstIdx += nr
			}
			continue
		}
		for kk := range panelK {
			srcIdx := (rowStart+kk)*n + baseCol
			for c := range validCols {
				packed[dstIdx] = hwy.Float32ToBFloat16(b[srcIdx+c].Float32())
				dstIdx++
			}
			for c := validCols; c < nr; c++ {
				packed[dstIdx] = hwy.Float32ToBFloat16(0)
				dstIdx++
			}
		}
	}
}

func BasePackRHSFast_neon(b []float32, packed []float32, n int, rowStart int, colStart int, panelK int, panelCols int, nr int) {
	lanes := 4
	dstIdx := 0
	for stripColIdx := 0; stripColIdx < panelCols; stripColIdx += nr {
		validCols := min(nr, panelCols-stripColIdx)
		baseCol := colStart + stripColIdx
		if validCols == nr && nr >= lanes && nr%lanes == 0 {
			for kk := range panelK {
				srcIdx := (rowStart+kk)*n + baseCol
				for c := 0; c < nr; c += lanes {
					v := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&b[srcIdx+c])))
					v.Store((*[4]float32)(unsafe.Pointer(&packed[dstIdx+c])))
				}
				dstIdx += nr
			}
			continue
		}
		for kk := range panelK {
			srcIdx := (rowStart+kk)*n + baseCol
			for c := range validCols {
				packed[dstIdx] = b[srcIdx+c]
				dstIdx++
			}
			for c := validCols; c < nr; c++ {
				packed[dstIdx] = 0
				dstIdx++
			}
		}
	}
}

func BasePackRHSFast_neon_Float64(b []float64, packed []float64, n int, rowStart int, colStart int, panelK int, panelCols int, nr int) {
	lanes := 2
	dstIdx := 0
	for stripColIdx := 0; stripColIdx < panelCols; stripColIdx += nr {
		validCols := min(nr, panelCols-stripColIdx)
		baseCol := colStart + stripColIdx
		if validCols == nr && nr >= lanes && nr%lanes == 0 {
			for kk := range panelK {
				srcIdx := (rowStart+kk)*n + baseCol
				for c := 0; c < nr; c += lanes {
					v := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&b[srcIdx+c])))
					v.Store((*[2]float64)(unsafe.Pointer(&packed[dstIdx+c])))
				}
				dstIdx += nr
			}
			continue
		}
		for kk := range panelK {
			srcIdx := (rowStart+kk)*n + baseCol
			for c := range validCols {
				packed[dstIdx] = b[srcIdx+c]
				dstIdx++
			}
			for c := validCols; c < nr; c++ {
				packed[dstIdx] = 0
				dstIdx++
			}
		}
	}
}

func BaseApplyPackedOutput_neon_Float16(packedOutput []hwy.Float16, output []hwy.Float16, alpha hwy.Float16, beta hwy.Float16, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 8
	alphaVec := asm.BroadcastFloat16x8(uint16(alpha))
	betaVec := asm.BroadcastFloat16x8(uint16(beta))
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadFloat16x8Ptr(unsafe.Pointer(&packedOutput[packedIdx+c:][0]))
			outputVal := asm.LoadFloat16x8Ptr(unsafe.Pointer(&output[outputIdx+c:][0]))
			scaledOutput := outputVal.Mul(betaVec)
			newVal := packedVal.MulAdd(alphaVec, scaledOutput)
			newVal.StorePtr(unsafe.Pointer(&output[outputIdx+c:][0]))
		}
		for ; c < width; c++ {
			val := packedOutput[packedIdx+c]
			output[outputIdx+c] = hwy.Float32ToFloat16(beta.Float32()*output[outputIdx+c].Float32() + alpha.Float32()*val.Float32())
		}
	}
}

func BaseApplyPackedOutput_neon_BFloat16(packedOutput []hwy.BFloat16, output []hwy.BFloat16, alpha hwy.BFloat16, beta hwy.BFloat16, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 8
	alphaVec := asm.BroadcastBFloat16x8(uint16(alpha))
	betaVec := asm.BroadcastBFloat16x8(uint16(beta))
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&packedOutput[packedIdx+c:][0]))
			outputVal := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&output[outputIdx+c:][0]))
			scaledOutput := outputVal.Mul(betaVec)
			newVal := packedVal.MulAdd(alphaVec, scaledOutput)
			newVal.StorePtr(unsafe.Pointer(&output[outputIdx+c:][0]))
		}
		for ; c < width; c++ {
			val := packedOutput[packedIdx+c]
			output[outputIdx+c] = hwy.Float32ToBFloat16(beta.Float32()*output[outputIdx+c].Float32() + alpha.Float32()*val.Float32())
		}
	}
}

func BaseApplyPackedOutput_neon(packedOutput []float32, output []float32, alpha float32, beta float32, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 4
	alphaVec := asm.BroadcastFloat32x4(alpha)
	betaVec := asm.BroadcastFloat32x4(beta)
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&packedOutput[packedIdx+c])))
			outputVal := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&output[outputIdx+c])))
			scaledOutput := outputVal.Mul(betaVec)
			newVal := packedVal.MulAdd(alphaVec, scaledOutput)
			newVal.Store((*[4]float32)(unsafe.Pointer(&output[outputIdx+c])))
		}
		for ; c < width; c++ {
			val := packedOutput[packedIdx+c]
			output[outputIdx+c] = beta*output[outputIdx+c] + alpha*val
		}
	}
}

func BaseApplyPackedOutput_neon_Float64(packedOutput []float64, output []float64, alpha float64, beta float64, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 2
	alphaVec := asm.BroadcastFloat64x2(alpha)
	betaVec := asm.BroadcastFloat64x2(beta)
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&packedOutput[packedIdx+c])))
			outputVal := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&output[outputIdx+c])))
			scaledOutput := outputVal.Mul(betaVec)
			newVal := packedVal.MulAdd(alphaVec, scaledOutput)
			newVal.Store((*[2]float64)(unsafe.Pointer(&output[outputIdx+c])))
		}
		for ; c < width; c++ {
			val := packedOutput[packedIdx+c]
			output[outputIdx+c] = beta*output[outputIdx+c] + alpha*val
		}
	}
}

func BaseApplyPackedOutputSimple_neon_Float16(packedOutput []hwy.Float16, output []hwy.Float16, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 8
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			v := asm.LoadFloat16x8Ptr(unsafe.Pointer(&packedOutput[packedIdx+c:][0]))
			v.StorePtr(unsafe.Pointer(&output[outputIdx+c:][0]))
		}
		for ; c < width; c++ {
			output[outputIdx+c] = hwy.Float32ToFloat16(packedOutput[packedIdx+c].Float32())
		}
	}
}

func BaseApplyPackedOutputSimple_neon_BFloat16(packedOutput []hwy.BFloat16, output []hwy.BFloat16, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 8
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			v := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&packedOutput[packedIdx+c:][0]))
			v.StorePtr(unsafe.Pointer(&output[outputIdx+c:][0]))
		}
		for ; c < width; c++ {
			output[outputIdx+c] = hwy.Float32ToBFloat16(packedOutput[packedIdx+c].Float32())
		}
	}
}

func BaseApplyPackedOutputSimple_neon(packedOutput []float32, output []float32, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 4
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			v := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&packedOutput[packedIdx+c])))
			v.Store((*[4]float32)(unsafe.Pointer(&output[outputIdx+c])))
		}
		for ; c < width; c++ {
			output[outputIdx+c] = packedOutput[packedIdx+c]
		}
	}
}

func BaseApplyPackedOutputSimple_neon_Float64(packedOutput []float64, output []float64, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 2
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			v := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&packedOutput[packedIdx+c])))
			v.Store((*[2]float64)(unsafe.Pointer(&output[outputIdx+c])))
		}
		for ; c < width; c++ {
			output[outputIdx+c] = packedOutput[packedIdx+c]
		}
	}
}

func BaseApplyPackedOutputAccum_neon_Float16(packedOutput []hwy.Float16, output []hwy.Float16, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 8
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadFloat16x8Ptr(unsafe.Pointer(&packedOutput[packedIdx+c:][0]))
			outputVal := asm.LoadFloat16x8Ptr(unsafe.Pointer(&output[outputIdx+c:][0]))
			newVal := outputVal.Add(packedVal)
			newVal.StorePtr(unsafe.Pointer(&output[outputIdx+c:][0]))
		}
		for ; c < width; c++ {
			output[outputIdx+c] = hwy.Float32ToFloat16(output[outputIdx+c].Float32() + packedOutput[packedIdx+c].Float32())
		}
	}
}

func BaseApplyPackedOutputAccum_neon_BFloat16(packedOutput []hwy.BFloat16, output []hwy.BFloat16, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 8
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&packedOutput[packedIdx+c:][0]))
			outputVal := asm.LoadBFloat16x8Ptr(unsafe.Pointer(&output[outputIdx+c:][0]))
			newVal := outputVal.Add(packedVal)
			newVal.StorePtr(unsafe.Pointer(&output[outputIdx+c:][0]))
		}
		for ; c < width; c++ {
			output[outputIdx+c] = hwy.Float32ToBFloat16(output[outputIdx+c].Float32() + packedOutput[packedIdx+c].Float32())
		}
	}
}

func BaseApplyPackedOutputAccum_neon(packedOutput []float32, output []float32, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 4
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&packedOutput[packedIdx+c])))
			outputVal := asm.LoadFloat32x4((*[4]float32)(unsafe.Pointer(&output[outputIdx+c])))
			newVal := outputVal.Add(packedVal)
			newVal.Store((*[4]float32)(unsafe.Pointer(&output[outputIdx+c])))
		}
		for ; c < width; c++ {
			output[outputIdx+c] += packedOutput[packedIdx+c]
		}
	}
}

func BaseApplyPackedOutputAccum_neon_Float64(packedOutput []float64, output []float64, packedStride int, outputRowOffset int, outputColOffset int, outputStride int, height int, width int) {
	lanes := 2
	for r := range height {
		packedIdx := r * packedStride
		outputIdx := (outputRowOffset+r)*outputStride + outputColOffset
		c := 0
		for ; c+lanes <= width; c += lanes {
			packedVal := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&packedOutput[packedIdx+c])))
			outputVal := asm.LoadFloat64x2((*[2]float64)(unsafe.Pointer(&output[outputIdx+c])))
			newVal := outputVal.Add(packedVal)
			newVal.Store((*[2]float64)(unsafe.Pointer(&output[outputIdx+c])))
		}
		for ; c < width; c++ {
			output[outputIdx+c] += packedOutput[packedIdx+c]
		}
	}
}
