//go:build amd64 && goexperiment.simd

package hwy

import (
	"simd/archsimd"
)

// This file provides AVX2 SIMD implementations of compress and expand operations.
// These work directly with archsimd vector and mask types.
// Since archsimd doesn't have vcompressps, we use store/scalar/load pattern.
//
// Note: archsimd uses proper Mask types (Mask32x8, Mask64x4) for comparison results.
// These Mask types have ToBits() method to convert to a bitmask integer.

// Compress_AVX2_F32x8 compresses elements where mask is true to the front.
// The mask should be the result of a comparison operation (e.g., Less, Equal).
// Returns compressed vector and count of valid elements.
func Compress_AVX2_F32x8(v archsimd.Float32x8, mask archsimd.Mask32x8) (archsimd.Float32x8, int) {
	var data [8]float32
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [8]float32
	count := 0

	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			result[count] = data[i]
			count++
		}
	}

	return archsimd.LoadFloat32x8Slice(result[:]), count
}

// Compress_AVX2_F64x4 compresses elements where mask is true to the front.
// Returns compressed vector and count of valid elements.
func Compress_AVX2_F64x4(v archsimd.Float64x4, mask archsimd.Mask64x4) (archsimd.Float64x4, int) {
	var data [4]float64
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [4]float64
	count := 0

	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			result[count] = data[i]
			count++
		}
	}

	return archsimd.LoadFloat64x4Slice(result[:]), count
}

// Expand_AVX2_F32x8 expands elements into positions where mask is true.
func Expand_AVX2_F32x8(v archsimd.Float32x8, mask archsimd.Mask32x8) archsimd.Float32x8 {
	var data [8]float32
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [8]float32
	srcIdx := 0

	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = data[srcIdx]
			srcIdx++
		}
	}

	return archsimd.LoadFloat32x8Slice(result[:])
}

// Expand_AVX2_F64x4 expands elements into positions where mask is true.
func Expand_AVX2_F64x4(v archsimd.Float64x4, mask archsimd.Mask64x4) archsimd.Float64x4 {
	var data [4]float64
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [4]float64
	srcIdx := 0

	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = data[srcIdx]
			srcIdx++
		}
	}

	return archsimd.LoadFloat64x4Slice(result[:])
}

// CompressStore_AVX2_F32x8 compresses and stores directly to slice.
// Returns number of elements stored.
func CompressStore_AVX2_F32x8(v archsimd.Float32x8, mask archsimd.Mask32x8, dst []float32) int {
	var data [8]float32
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	count := 0
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			if count < len(dst) {
				dst[count] = data[i]
			}
			count++
		}
	}
	return count
}

// CompressStore_AVX2_F64x4 compresses and stores directly to slice.
// Returns number of elements stored.
func CompressStore_AVX2_F64x4(v archsimd.Float64x4, mask archsimd.Mask64x4, dst []float64) int {
	var data [4]float64
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	count := 0
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			if count < len(dst) {
				dst[count] = data[i]
			}
			count++
		}
	}
	return count
}

// CountTrue_AVX2_F32x8 counts true lanes in mask.
func CountTrue_AVX2_F32x8(mask archsimd.Mask32x8) int {
	bits := mask.ToBits()
	count := 0
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			count++
		}
	}
	return count
}

// CountTrue_AVX2_F64x4 counts true lanes in mask.
func CountTrue_AVX2_F64x4(mask archsimd.Mask64x4) int {
	bits := mask.ToBits()
	count := 0
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			count++
		}
	}
	return count
}

// AllTrue_AVX2_F32x8 returns true if all lanes are true.
func AllTrue_AVX2_F32x8(mask archsimd.Mask32x8) bool {
	return mask.ToBits() == 0xFF
}

// AllTrue_AVX2_F64x4 returns true if all lanes are true.
func AllTrue_AVX2_F64x4(mask archsimd.Mask64x4) bool {
	return mask.ToBits() == 0xF
}

// AllFalse_AVX2_F32x8 returns true if all lanes are false.
func AllFalse_AVX2_F32x8(mask archsimd.Mask32x8) bool {
	return mask.ToBits() == 0
}

// AllFalse_AVX2_F64x4 returns true if all lanes are false.
func AllFalse_AVX2_F64x4(mask archsimd.Mask64x4) bool {
	return mask.ToBits() == 0
}

// FindFirstTrue_AVX2_F32x8 returns index of first true lane, or -1 if none.
func FindFirstTrue_AVX2_F32x8(mask archsimd.Mask32x8) int {
	bits := mask.ToBits()
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			return i
		}
	}
	return -1
}

// FindFirstTrue_AVX2_F64x4 returns index of first true lane, or -1 if none.
func FindFirstTrue_AVX2_F64x4(mask archsimd.Mask64x4) int {
	bits := mask.ToBits()
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			return i
		}
	}
	return -1
}

// FindLastTrue_AVX2_F32x8 returns index of last true lane, or -1 if none.
func FindLastTrue_AVX2_F32x8(mask archsimd.Mask32x8) int {
	bits := mask.ToBits()
	for i := 7; i >= 0; i-- {
		if (bits & (1 << i)) != 0 {
			return i
		}
	}
	return -1
}

// FindLastTrue_AVX2_F64x4 returns index of last true lane, or -1 if none.
func FindLastTrue_AVX2_F64x4(mask archsimd.Mask64x4) int {
	bits := mask.ToBits()
	for i := 3; i >= 0; i-- {
		if (bits & (1 << i)) != 0 {
			return i
		}
	}
	return -1
}

// FirstN_AVX2_F32x8 creates a mask with the first n lanes set to true.
func FirstN_AVX2_F32x8(n int) archsimd.Mask32x8 {
	indices := archsimd.LoadInt32x8Slice([]int32{0, 1, 2, 3, 4, 5, 6, 7})
	threshold := archsimd.BroadcastInt32x8(int32(n))
	return indices.Less(threshold)
}

// FirstN_AVX2_F64x4 creates a mask with the first n lanes set to true.
func FirstN_AVX2_F64x4(n int) archsimd.Mask64x4 {
	indices := archsimd.LoadInt64x4Slice([]int64{0, 1, 2, 3})
	threshold := archsimd.BroadcastInt64x4(int64(n))
	return indices.Less(threshold)
}

// LastN_AVX2_F32x8 creates a mask with the last n lanes set to true.
// For n lanes set, we compute: bits = ((1 << n) - 1) << (8 - n)
// e.g., LastN(3) = 0b11100000 = 0xE0
func LastN_AVX2_F32x8(n int) archsimd.Mask32x8 {
	if n <= 0 {
		return archsimd.Mask32x8FromBits(0)
	}
	if n >= 8 {
		return archsimd.Mask32x8FromBits(0xFF)
	}
	bits := uint8(((1 << n) - 1) << (8 - n))
	return archsimd.Mask32x8FromBits(bits)
}

// LastN_AVX2_F64x4 creates a mask with the last n lanes set to true.
func LastN_AVX2_F64x4(n int) archsimd.Mask64x4 {
	if n <= 0 {
		return archsimd.Mask64x4FromBits(0)
	}
	if n >= 4 {
		return archsimd.Mask64x4FromBits(0xF)
	}
	bits := uint8(((1 << n) - 1) << (4 - n))
	return archsimd.Mask64x4FromBits(bits)
}

// MaskFromBits_AVX2_F32x8 creates a mask from a bitmask integer.
func MaskFromBits_AVX2_F32x8(bits uint64) archsimd.Mask32x8 {
	var vals [8]int32
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			vals[i] = 1
		}
	}
	vec := archsimd.LoadInt32x8Slice(vals[:])
	zero := archsimd.BroadcastInt32x8(0)
	return vec.Greater(zero)
}

// MaskFromBits_AVX2_F64x4 creates a mask from a bitmask integer.
func MaskFromBits_AVX2_F64x4(bits uint64) archsimd.Mask64x4 {
	var vals [4]int64
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			vals[i] = 1
		}
	}
	vec := archsimd.LoadInt64x4Slice(vals[:])
	zero := archsimd.BroadcastInt64x4(0)
	return vec.Greater(zero)
}

// BitsFromMask_AVX2_F32x8 converts mask to bitmask integer.
func BitsFromMask_AVX2_F32x8(mask archsimd.Mask32x8) uint64 {
	return uint64(mask.ToBits())
}

// BitsFromMask_AVX2_F64x4 converts mask to bitmask integer.
func BitsFromMask_AVX2_F64x4(mask archsimd.Mask64x4) uint64 {
	return uint64(mask.ToBits())
}

// ============================================================================
// Integer type variants (I32x8, I64x4)
// ============================================================================

// Compress_AVX2_I32x8 compresses elements where mask is true to the front.
func Compress_AVX2_I32x8(v archsimd.Int32x8, mask archsimd.Mask32x8) (archsimd.Int32x8, int) {
	var data [8]int32
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [8]int32
	count := 0

	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			result[count] = data[i]
			count++
		}
	}

	return archsimd.LoadInt32x8Slice(result[:]), count
}

// Compress_AVX2_I64x4 compresses elements where mask is true to the front.
func Compress_AVX2_I64x4(v archsimd.Int64x4, mask archsimd.Mask64x4) (archsimd.Int64x4, int) {
	var data [4]int64
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [4]int64
	count := 0

	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			result[count] = data[i]
			count++
		}
	}

	return archsimd.LoadInt64x4Slice(result[:]), count
}

// Expand_AVX2_I32x8 expands elements into positions where mask is true.
func Expand_AVX2_I32x8(v archsimd.Int32x8, mask archsimd.Mask32x8) archsimd.Int32x8 {
	var data [8]int32
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [8]int32
	srcIdx := 0

	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = data[srcIdx]
			srcIdx++
		}
	}

	return archsimd.LoadInt32x8Slice(result[:])
}

// Expand_AVX2_I64x4 expands elements into positions where mask is true.
func Expand_AVX2_I64x4(v archsimd.Int64x4, mask archsimd.Mask64x4) archsimd.Int64x4 {
	var data [4]int64
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	var result [4]int64
	srcIdx := 0

	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = data[srcIdx]
			srcIdx++
		}
	}

	return archsimd.LoadInt64x4Slice(result[:])
}

// CompressStore_AVX2_I32x8 compresses and stores directly to slice.
func CompressStore_AVX2_I32x8(v archsimd.Int32x8, mask archsimd.Mask32x8, dst []int32) int {
	var data [8]int32
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	count := 0
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			if count < len(dst) {
				dst[count] = data[i]
			}
			count++
		}
	}
	return count
}

// CompressStore_AVX2_I64x4 compresses and stores directly to slice.
func CompressStore_AVX2_I64x4(v archsimd.Int64x4, mask archsimd.Mask64x4, dst []int64) int {
	var data [4]int64
	v.StoreSlice(data[:])

	bits := mask.ToBits()
	count := 0
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			if count < len(dst) {
				dst[count] = data[i]
			}
			count++
		}
	}
	return count
}

// CountTrue_AVX2_I32x8 counts true lanes in mask.
func CountTrue_AVX2_I32x8(mask archsimd.Mask32x8) int {
	return CountTrue_AVX2_F32x8(mask)
}

// CountTrue_AVX2_I64x4 counts true lanes in mask.
func CountTrue_AVX2_I64x4(mask archsimd.Mask64x4) int {
	return CountTrue_AVX2_F64x4(mask)
}

// FirstN_AVX2_I32x8 creates a mask with the first n lanes set to true.
func FirstN_AVX2_I32x8(n int) archsimd.Mask32x8 {
	return FirstN_AVX2_F32x8(n)
}

// FirstN_AVX2_I64x4 creates a mask with the first n lanes set to true.
func FirstN_AVX2_I64x4(n int) archsimd.Mask64x4 {
	return FirstN_AVX2_F64x4(n)
}

// LastN_AVX2_I32x8 creates a mask with the last n lanes set to true.
func LastN_AVX2_I32x8(n int) archsimd.Mask32x8 {
	return LastN_AVX2_F32x8(n)
}

// LastN_AVX2_I64x4 creates a mask with the last n lanes set to true.
func LastN_AVX2_I64x4(n int) archsimd.Mask64x4 {
	return LastN_AVX2_F64x4(n)
}

// AllTrue_AVX2_I32x8 returns true if all lanes are true.
func AllTrue_AVX2_I32x8(mask archsimd.Mask32x8) bool {
	return AllTrue_AVX2_F32x8(mask)
}

// AllTrue_AVX2_I64x4 returns true if all lanes are true.
func AllTrue_AVX2_I64x4(mask archsimd.Mask64x4) bool {
	return AllTrue_AVX2_F64x4(mask)
}

// AllFalse_AVX2_I32x8 returns true if all lanes are false.
func AllFalse_AVX2_I32x8(mask archsimd.Mask32x8) bool {
	return AllFalse_AVX2_F32x8(mask)
}

// AllFalse_AVX2_I64x4 returns true if all lanes are false.
func AllFalse_AVX2_I64x4(mask archsimd.Mask64x4) bool {
	return AllFalse_AVX2_F64x4(mask)
}

// FindFirstTrue_AVX2_I32x8 returns index of first true lane, or -1 if none.
func FindFirstTrue_AVX2_I32x8(mask archsimd.Mask32x8) int {
	return FindFirstTrue_AVX2_F32x8(mask)
}

// FindFirstTrue_AVX2_I64x4 returns index of first true lane, or -1 if none.
func FindFirstTrue_AVX2_I64x4(mask archsimd.Mask64x4) int {
	return FindFirstTrue_AVX2_F64x4(mask)
}

// FindLastTrue_AVX2_I32x8 returns index of last true lane, or -1 if none.
func FindLastTrue_AVX2_I32x8(mask archsimd.Mask32x8) int {
	return FindLastTrue_AVX2_F32x8(mask)
}

// FindLastTrue_AVX2_I64x4 returns index of last true lane, or -1 if none.
func FindLastTrue_AVX2_I64x4(mask archsimd.Mask64x4) int {
	return FindLastTrue_AVX2_F64x4(mask)
}

// ============================================================================
// IfThenElse wrappers
// ============================================================================

// IfThenElse_AVX2_F32x8 selects elements from a where mask is true, else from b.
func IfThenElse_AVX2_F32x8(mask archsimd.Mask32x8, a, b archsimd.Float32x8) archsimd.Float32x8 {
	var aBuf, bBuf [8]float32
	a.StoreSlice(aBuf[:])
	b.StoreSlice(bBuf[:])

	bits := mask.ToBits()
	var result [8]float32
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = aBuf[i]
		} else {
			result[i] = bBuf[i]
		}
	}
	return archsimd.LoadFloat32x8Slice(result[:])
}

// IfThenElse_AVX2_F64x4 selects elements from a where mask is true, else from b.
func IfThenElse_AVX2_F64x4(mask archsimd.Mask64x4, a, b archsimd.Float64x4) archsimd.Float64x4 {
	var aBuf, bBuf [4]float64
	a.StoreSlice(aBuf[:])
	b.StoreSlice(bBuf[:])

	bits := mask.ToBits()
	var result [4]float64
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = aBuf[i]
		} else {
			result[i] = bBuf[i]
		}
	}
	return archsimd.LoadFloat64x4Slice(result[:])
}

// IfThenElse_AVX2_I32x8 selects elements from a where mask is true, else from b.
func IfThenElse_AVX2_I32x8(mask archsimd.Mask32x8, a, b archsimd.Int32x8) archsimd.Int32x8 {
	var aBuf, bBuf [8]int32
	a.StoreSlice(aBuf[:])
	b.StoreSlice(bBuf[:])

	bits := mask.ToBits()
	var result [8]int32
	for i := 0; i < 8; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = aBuf[i]
		} else {
			result[i] = bBuf[i]
		}
	}
	return archsimd.LoadInt32x8Slice(result[:])
}

// IfThenElse_AVX2_I64x4 selects elements from a where mask is true, else from b.
func IfThenElse_AVX2_I64x4(mask archsimd.Mask64x4, a, b archsimd.Int64x4) archsimd.Int64x4 {
	var aBuf, bBuf [4]int64
	a.StoreSlice(aBuf[:])
	b.StoreSlice(bBuf[:])

	bits := mask.ToBits()
	var result [4]int64
	for i := 0; i < 4; i++ {
		if (bits & (1 << i)) != 0 {
			result[i] = aBuf[i]
		} else {
			result[i] = bBuf[i]
		}
	}
	return archsimd.LoadInt64x4Slice(result[:])
}

// MaskAnd_AVX2_F32x8 combines two masks with AND operation.
func MaskAnd_AVX2_F32x8(a, b archsimd.Mask32x8) archsimd.Mask32x8 {
	return a.And(b)
}

// MaskAnd_AVX2_F64x4 combines two masks with AND operation.
func MaskAnd_AVX2_F64x4(a, b archsimd.Mask64x4) archsimd.Mask64x4 {
	return a.And(b)
}

// MaskOr_AVX2_F32x8 combines two masks with OR operation.
func MaskOr_AVX2_F32x8(a, b archsimd.Mask32x8) archsimd.Mask32x8 {
	return a.Or(b)
}

// MaskOr_AVX2_F64x4 combines two masks with OR operation.
func MaskOr_AVX2_F64x4(a, b archsimd.Mask64x4) archsimd.Mask64x4 {
	return a.Or(b)
}

// ============================================================================
// Bitwise operations for float types
// archsimd doesn't have Xor/Not on float types, so we cast to int and back
// ============================================================================

// SignBit_AVX2_F32x8 returns a vector with the sign bit set in all lanes.
func SignBit_AVX2_F32x8() archsimd.Float32x8 {
	// 0x80000000 is the sign bit for float32
	signBit := archsimd.BroadcastInt32x8(int32(-0x80000000))
	return signBit.AsFloat32x8()
}

// SignBit_AVX2_F64x4 returns a vector with the sign bit set in all lanes.
func SignBit_AVX2_F64x4() archsimd.Float64x4 {
	// 0x8000000000000000 is the sign bit for float64
	signBit := archsimd.BroadcastInt64x4(int64(-0x8000000000000000))
	return signBit.AsFloat64x4()
}

// Not_AVX2_F32x8 returns bitwise NOT of the vector.
func Not_AVX2_F32x8(v archsimd.Float32x8) archsimd.Float32x8 {
	// XOR with all 1s
	allOnes := archsimd.BroadcastInt32x8(-1)
	return v.AsInt32x8().Xor(allOnes).AsFloat32x8()
}

// Not_AVX2_F64x4 returns bitwise NOT of the vector.
func Not_AVX2_F64x4(v archsimd.Float64x4) archsimd.Float64x4 {
	// XOR with all 1s
	allOnes := archsimd.BroadcastInt64x4(-1)
	return v.AsInt64x4().Xor(allOnes).AsFloat64x4()
}

// Xor_AVX2_F32x8 returns bitwise XOR of two vectors.
func Xor_AVX2_F32x8(a, b archsimd.Float32x8) archsimd.Float32x8 {
	return a.AsInt32x8().Xor(b.AsInt32x8()).AsFloat32x8()
}

// Xor_AVX2_F64x4 returns bitwise XOR of two vectors.
func Xor_AVX2_F64x4(a, b archsimd.Float64x4) archsimd.Float64x4 {
	return a.AsInt64x4().Xor(b.AsInt64x4()).AsFloat64x4()
}

// And_AVX2_F32x8 returns bitwise AND of two vectors.
func And_AVX2_F32x8(a, b archsimd.Float32x8) archsimd.Float32x8 {
	return a.AsInt32x8().And(b.AsInt32x8()).AsFloat32x8()
}

// And_AVX2_F64x4 returns bitwise AND of two vectors.
func And_AVX2_F64x4(a, b archsimd.Float64x4) archsimd.Float64x4 {
	return a.AsInt64x4().And(b.AsInt64x4()).AsFloat64x4()
}
